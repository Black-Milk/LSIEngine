de Gruyter Textbook

Hans-Otto Georgii
Stochastics

Hans-Otto Georgii
Stochastics
Introduction to Probability and Statistics

Translated by
Marcel Ortgiese, Ellen Baake and the author

≥ Walter de Gruyter

Berlin · New York

Prof. Dr. Hans-Otto Georgii
Mathematical Institute
Ludwig-Maximilians-Universität Munich
Theresienstr. 39
80333 Munich
Germany

Mathematics Subject Classification 2000: 60-01, 62-01

Translated from the third German edition:
Hans-Otto Georgii: Stochastik, Einführung in die Wahrscheinlichkeitstheorie und
Statistik. Walter de Gruyter, Berlin · New York, 2007.

앪앝 Printed on acid-free paper which falls within the guidelines
of the ANSI to ensure permanence and durability.

Bibliographic information published by the Deutsche Nationalbibliothek
The Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliografie;
detailed bibliographic data are available in the Internet at http://dnb.d-nb.de.

ISBN 978-3-11-019145-5

쑔 Copyright 2008 by Walter de Gruyter GmbH & Co. KG, 10785 Berlin, Germany.
All rights reserved, including those of translation into foreign languages. No part of this book
may be reproduced in any form or by any means, electronic or mechanical, including photocopy,
recording, or any information storage and retrieval system, without permission in writing from
the publisher.
Printed in Germany.
Coverdesign: Martin Zech, Bremen.
Printing and binding: AZ Druck und Datentechnik GmbH, Kempten.

Preface

Chance – or what appears to us as such – is ubiquitous. Not only in the games of chance
such as lottery or roulette where risk is played with, but also in substantial parts of
everyday life. Every time an insurance company uses the claim frequencies to calculate
the future premium, or a fund manager the most recent stock charts to rearrange his
portfolio, every time cars are jamming at a trafﬁc node or data packages at an internet
router, every time an infection spreads out or a bacterium turns into a resistant mutant,
every time pollutant concentrations are measured or political decisions are based on
opinion polls – in all such cases a considerable amount of randomness comes into play,
and there is a need to analyse the random situation and to reach at rational conclusions
in spite of the inherent uncertainty. Precisely this is the objective of the ﬁeld of
stochastics, the ‘mathematics of chance’. Stochastics is therefore a highly applied
science, which tries to solve concrete demands of many disciplines. At the same time,
it is genuine mathematics – with sound systematics, clear-cut concepts, deep theorems
and sometimes surprising cross-connections. This interplay between applicability on
theonesideandmathematicalprecisionandeleganceontheothermakesupthespeciﬁc
appeal of stochastics, and a variety of natural questions determines its lively and broad
development.

This book offers an introduction to the typical way of thinking, as well as the basic
methods and results of stochastics. It grew out of a two-semester course which I gave
repeatedlyattheUniversityofMunich. Itisaddressedtostudentsofmathematicsinthe
second year, and also to scientists and computer scientists who intend not only to apply
stochastics, but also to understand its mathematical side. The two parts of stochastics –
probabilitytheoryandstatistics–arepresentedintwoseparatepartsofthebookbecause
of their own scopes and methods, but are united under the same cover on purpose. For,
the statistics is built on the concepts and methods of probability theory, whereas the
latter needs the former as a bridge to reality. In the choice of the material I conﬁned
myself deliberately to the central subjects belonging to the standard curriculum of the
corresponding mathematical courses. (It is thus unavoidable that some readers will
miss their favourite subjects, e.g., the resampling methods of statistics.) The standard
themes, however, are discussed with all necessary details. Rather than starting with
discrete models I preferred to present (and motivate) the general measure theoretic
framework right from the beginning, and some theoretical issues are also treated later
as the case arises. In general, however, the measure theoretic apparatus is conﬁned to
what is absolutely necessary, and the emphasis is on the development of a stochastic
intuition.

vi

Preface

This text comprises a little more material than can be presented in a four-hour
course over two semesters. The reader may thus want to make a selection. Several
possibilities present themselves. For a ﬁrst overview, the reader may concentrate on
concepts, theorems, and examples and skip all proofs. In particular, this is a practicable
route for non-mathematicians. A deeper understanding, of course, requires the study
of a representative selection of proofs. On the other hand, a reader mainly interested
in the theory and familiar with some applications may skip a portion of examples. For
a short route through Part I leading directly to statistics, one can restrict oneself to
the essentials of the ﬁrst chapters up to Section 3.4, as well as Sections 4.1 and 4.3,
and 5.1.1, 5.1.3, and 5.2. The core of Part II consists of Sections 7.1–7.5, 8.1–8.2,
9.2, Chapter 10, as well as 11.2 and 12.1. Depending on the speciﬁc interests, it will
facilitate orientation to browse through some portions of the text and return to them
later when needed. A list of notational conventions can be found on page 359.
At the end of each chapter there is a collection of problems offering applications,
additions, orsupplementstothetext. Theirdifﬁcultyvaries,butisnotindicatedbecause
the reader should follow only his or her interests. The main point is to try for oneself.
For this reason, solutions are not included (nor offered on the internet).
Aseverytextbook, thisonegrewoutofmoresourcesthancanpossiblybeidentiﬁed.
Evidently, however, I received a lot of inspiration from the classical German texts of
U. Krengel [37] and K. Krickeberg and H. Ziezold [38], which had strong inﬂuence on
theintroductorycoursesinstochasticsalloverGermany. Ialsogotmanyimpulsesfrom
my Munich stochastics colleagues Peter Gänßler and Helmut Pruscha as well as all
those responsible for the problem classes of my lectures during the last twenty years:
Peter Imkeller, Andreas Schief, Franz Strobl, Karin Münch-Berndl, Klaus Ziegler,
Bernhard Emmer, and Stefan Adams. I am very grateful to all of them. My thanks also
go to the publisher, the Walter de Gruyter Company, for the very efﬁcient and pleasant
cooperation.
Munich, February 2002

Hans-Otto Georgii

Preface to the English Edition
ThistextisbasicallyanEnglishtranslationofthethirdGermanedition, whichappeared
in July 2007. Luckily, Marcel Ortgiese accepted to lay the foundation by preparing
the initial English version, so that I could concentrate on details and cosmetic changes.
The project would have been impossible without him. As another piece of luck, Ellen
Baake took pleasure in giving a ﬁnal polish to the English and suggesting numerous
clariﬁcations. I am grateful to both of them.
Munich, January 2008

Hans-Otto Georgii

Contents

Preface
Mathematics and Chance

I Probability Theory
1 Principles of Modelling Chance

.

1.1 Probability Spaces .
1.2 Properties and Construction of Probability Measures .
1.3 Random Variables .
Problems .
.
.

. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . .
. . . . . . . .

.
.

.

.

.

.

.

.

2 Stochastic Standard Models

. . . . . . . . . . . . . . . . . . . . . . .
2.1 The Uniform Distributions
. . . . . . . . . . . . . . . . . . . . .
2.2 Urn Models with Replacement
. . . . . . . . . . . . . . . . . .
2.3 Urn Models without Replacement
2.4 The Poisson Distribution . . . . . . . . . . . . . . . .
. . . . . . . .
2.5 Waiting Time Distributions . . . . . . . . . . . . . . . . . . . . . . .
2.6 The Normal Distributions . . . . . . . . . . . . . . . . . . . . . . . .
Problems .
. . . . . . . .

. . . . . . . . . . . . . . . . . .

.

.

.

.

.

.

.

.

.

.

3 Conditional Probabilities and Independence

.

Independence .

3.1 Conditional Probabilities . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Multi-Stage Models .
. . . . . . . .
3.3
.
.
. . . . . . . . . . . . . . . . . .
3.4 Existence of Independent Random Variables, Product Measures .
.
.
. . . . . . . . . . . . . . . . . . . . . . . . . .
3.5 The Poisson Process .
. . . . . . . . . . . . . . . . . . . . . . . . . .
3.6 Simulation Methods .
. . . . . . . . . . . . . . . . . . . . . . . . . .
.
.
3.7 Tail Events .
Problems .
.
.
.
.
. . . . . . . . . . . . . . . . . .
. . . . . . . .

.
.

.
.

.
.

.

.

.

v
1

5
7
7
14
19
23
26
26
29
34
37
39
44
46
50
50
56
63
69
73
78
82
84

viii

Contents

.

.

.

.

.

.

.

4 Expectation and Variance

5 The Law of Large Numbers and the Central Limit Theorem

. . . . . . . . . . . . . . . . . . . .

90
4.1 The Expectation .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
4.2 Waiting Time Paradox and Fair Price of an Option . . . . . . . . . . .
98
4.3 Variance and Covariance . . . . . . . . . . . . . . . . . . . . . . . . 105
4.4 Generating Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 108
Problems .
. . . . . . . . 112
117
5.1 The Law of Large Numbers . . . . . . . . . . . . . . .
. . . . . . . . 117
5.2 Normal Approximation of Binomial Distributions . . . . . . . . . . . 129
5.3 The Central Limit Theorem . . . . . . . . . . . . . . . . . . . . . . . 136
5.4 Normal versus Poisson Approximation . . . . . . . . . . . . . . . . . 141
Problems .
. . . . . . . . 143
149
6.1 The Markov Property . . . . . . . . . . . . . . . . . . . . . . . . . . 149
6.2 Absorption Probabilities
. . . . . . . . . . . . . . . . . . . . . . . . 152
6.3 Asymptotic Stationarity . . . . . . . . . . . . . . . . . . . . . . . . . 157
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
6.4 Recurrence
Problems .
.
. . . . . . . . . . . . . . . . . . . .
. . . . . . . . 177

. . . . . . . . . . . . . . . . . . . .

.
.
6 Markov Chains

.
.

.
.

.
.

.

.

.

.

.

.

.

.

II Statistics
7 Estimation

185
187
7.1 The Approach of Statistics
. . . . . . . . . . . . . . . . . . . . . . . 187
7.2 Facing the Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
7.3 The Maximum Likelihood Principle . . . . . . . . . . . . . . . . . . 195
7.4 Bias and Mean Squared Error . . . . . . . . . . . . . . . . . . . . . . 201
7.5 Best Estimators .
. . . . . . . . 203
7.6 Consistent Estimators . . . . . . . . . . . . . . . . . . . . . . . . . . 209
7.7 Bayes Estimators
. . . . . . . . 213
. . . . . . . . 217
.
Problems .
222
8.1 Deﬁnition and Construction . . . . . . . . . . . . . . . . . . . . . . . 222
. . . . . . . . . . . . . . 228
8.2 Conﬁdence Intervals in the Binomial Model
. . . . . . . . 234
8.3 Order Intervals
Problems .
.
. . . . . . . . 238

. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . .

.
8 Conﬁdence Regions

.
.

.

.

.

.

.

.

.

.

.

.

Contents

ix

9 Around the Normal Distributions

.
.
10 Hypothesis Testing

.

.

.

12 Regression Models and Analysis of Variance

11 Asymptotic Tests and Rank Tests

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

. . . . . . . . . . . . . . . .

11.1 Normal Approximation of Multinomial Distributions
11.2 The Chi-Square Test of Goodness of Fit
11.3 The Chi-Square Test of Independence
11.4 Order and Rank Tests .
Problems .
.
.

241
9.1 The Multivariate Normal Distributions . . . . . . . . .
. . . . . . . . 241
9.2 The χ2-, F- and t-Distributions . . . . . . . . . . . . . . . . . . . . . 244
. . . . . . . . 251
. . . . . . . . . . . . . . . .
Problems .
255
. . . . . . . . . . . . . . . . . . . . . . . . . . 255
10.1 Decision Problems
. . . . . . . . . . . . . . . . . . . . . . . . 261
10.2 Neyman–Pearson Tests .
10.3 Most Powerful One-Sided Tests . . . . . . . . . . . . . . . . . . . . . 266
10.4 Parameter Tests in the Gaussian Product Model
. . . . . . . . . . . . 269
Problems .
. . . . . . . . 278
283
. . . . . . . . . 283
. . . . . . . . . . . . . . . . 290
. . . . . . . . 297
. . . . . . . . .
. . . . . . . . 303
. . . . . . . . . . . . . . . .
. . . . . . . . 313
. . . . . . . . . . . . . . . .
318
12.1 Simple Linear Regression . . . . . . . . . . . . . . . . . . . . . . . . 318
.
12.2 The Linear Model .
. . . . . . . . 322
.
12.3 The Gaussian Linear Model . . . . . . . . . . . . . . . . . . . . . . . 326
. . . . . . . . . . . . . . . . . . . . . . . . . . 334
12.4 Analysis of Variance
Problems .
. . . . . . . . 342
.
.
.
349
355
359
363

. . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . .

.
.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

Tables
References
List of Notation
Index

Mathematics and Chance

What is stochastics1? In dictionaries of classical Greek one ﬁnds

σ τ ´oχoς
σ τoχ ασ τ ικ ´oς
σ τoχ ´αζoµαι

(stóchos)
(stochastikós)
(stocházomai)

goal, aim, guess, conjecture
skilful in aiming at, able to hit
I aim at, guess at, infer, explore

Its current usage is captured by the sentence

Stochastics is the science of the rules of chance.

At ﬁrst sight, this statement seems to be a contradiction in itself, since, in everyday
life, one speaks of chance when no rules are apparent. A little thought, however,
reveals that chance does indeed follow some rules. For example, if you ﬂip a coin very
often, you will have no doubt that heads will come up approximately half of the time.
Obviously, this is a law of chance, and is generally accepted as such. Nevertheless, it
is a widespread belief that such laws are too vague to be made precise, let alone to be
formalised mathematically. Intriguingly, the opposite is true: Mathematics offers an
exact language even for such seemingly disordered phenomena; a language that allows
to state, and prove, a variety of laws obeyed by chance. The experience mentioned
above, namelythatheadsshowsupinaboutonehalfofalargenumberofcoinﬂips, thus
turns into a mathematical theorem, the law of large numbers. Stochastics is the part
of mathematics that develops an appropriate formalism for describing the principles
of randomness, for detecting rules where they seem to be absent, and for using them.
This book presents the basic ideas and central results.

∗

But what is chance? This is a philosophical question, and a satisfactory answer is
still missing. Whether ‘god plays dice with the universe’ or, in fact, he does not (as
was postulated by Albert Einstein in his famous dictum), whether randomness is only
ﬁctitious and merely a consequence of our incomplete knowledge or, on the contrary,
is inherent to nature – these questions are still unresolved.
As a matter of fact, however, we may refrain from trying to understand the nature of
‘chance per se’, by good reasons. We will never be able to investigate the universe as a
1So far, the noun ‘stochastics’ is not a well-established English word, in contrast to the adjective ‘stochas-
tic’. But since there is a need for a term comprising both probability theory and statistics, its use is spreading,
and is expected to become standard, as it did in other languages. So we use it in this book.

2

Mathematics and Chance

whole. Rather, we will always have to focus on quite a special, restricted phenomenon,
and we will restrict attention to the nature of this small part of reality. Even if the
phenomenon considered could be explained in parts by its general circumstances (as
we could, for instance, anticipate the number shown by a die if we only knew in
sufﬁcient detail how it is thrown) – even then, it is much more practicable, and better
adapted to our human perspective, if we adopt the viewpoint that the phenomenon
is governed by chance. This kind of chance then comprises both, an indeterminacy
possiblyinherenttonature, andour(perhapsunavoidable)ignoranceofthedetermining
factors.

How does mathematics then come into play? As soon as a deﬁnite part of the real
world is selected for investigation, one can try and collect all its relevant aspects into

∗

real world

part considered

abstraction,
idealisation

prediction,
comparison
and revision

✻

❄
model

a mathematical model. Typically, this is done

◃ by abstracting from ‘dirty’ details that might distract from the essentials of the
problem at hand, that is, by ‘smoothing away’ all features that seem irrelevant;
and, on the other hand,
◃ by mathematical idealisation, i.e., by widening the scope using mental or for-
mal limiting procedures that allow for a clear-cut description of the relevant
phenomena.

The model thus obtained can then be investigated mathematically, and the resulting
predictions have to be checked against reality. If necessary, the model must be revised.
In general, ﬁnding an appropriate model is a delicate process. It requires much ﬂair and
fallsbeyondmathematics. Thereare, however, somebasicprinciplesandmathematical
structures; these will be discussed in this text.

Stochastics is composed of two equal parts: probability theory and statistics. The
objective of probability theory is the description and investigation of speciﬁc random

∗

Mathematics and Chance

3

phenomena. Statistics seeks for methods of drawing rational conclusions from un-
certain random observations. This, of course, requires and builds on the models of
probability theory. The other way round, probability theory needs the validation ob-
tained by comparing model and reality, which is made possible by statistics. Part I of
this text offers an introduction to the basic concepts and results of probability theory.
Part II then presents an introduction into theory and methods of mathematical statistics.

Stochastics

 

❅

❅❅

  

Probability Theory

description of

random phenomena,
investigation of models

Statistics

handling of uncertainty,
from random observations

rational inference

Part I

Probability Theory

1 Principles of Modelling Chance

This chapter develops the fundamentals of modelling chance. The primary questions
read: How can one describe a speciﬁc random phenomenon mathematically? What
are the general properties of the stochastic model so obtained? How can one extract
a particular aspect from a given model? In answering these questions, we will be led
to the fundamental notions of ‘probability space’ and ‘random variable’. We will also
be faced with a few technical questions, which might be somewhat unpleasant to deal
with at the beginning, but will enable us to concentrate on the principal ideas later on.

1.1 Probability Spaces
To build a mathematical model for a speciﬁc scenario of chance, one proceeds in three
stages as follows.

1.1.1 Determining the Sample Space
If one aims at describing the effects of chance, the ﬁrst question is: What can happen
in the given situation? And which part of this is relevant? The possibilities that
seem natural to distinguish are then collected into a set . This is best understood by
examples.
(1.1) Example. Rolling a die once. If we roll a die on a table, it can stop in inﬁnitely
many positions. We are not interested in its exact ﬁnal position, and even less in
the precise hand movement when throwing the die, but only in the number that is
showing. The interesting outcomes are thus captured by the set  = {1, . . . ,6}. With
the restriction to this , we fade out the irrelevant part of reality.
(1.2) Example. Rolling a die several times. If the die is thrown n times and we are
interested in the sequence of numbers shown, then the relevant outcomes are those in
the product space  = {1, . . . ,6}n; for ω = (ω1, . . . , ωn) ∈  and 1 ≤ i ≤ n, ωi
represents the number showing at the ith throw.
On the other hand, if we are not interested in the exact sequence of numbers, but
only in how often each number appears, it is more natural to choose

! ="(k1, . . . , k6) ∈ Z6

+ :

6#a=1

ka = n$

8
1 Principles of Modelling Chance
as the set of all possible outcomes. Here Z+ = {0,1,2, . . .} is the set of all non-
negative integers, and ka stands for the number of throws the die shows a.
(1.3) Example. Tossing a coin inﬁnitely often. When we toss a coin n times, the
appropriate set of outcomes is  = {0,1}n, in analogy with the previous example
(provided we are interested in the sequence of outcomes). If we decide to ﬂip the coin
once more, do we have to consider a new ? This would not be very practical; thus our
model should not be limited to a ﬁxed number of tosses. Moreover, we are especially
interested in patterns that only appear for large n, that is in the limit as n → ∞.
Therefore it is often convenient to choose an idealised model, which admits an inﬁnite
number of tosses. (As an analogy, think of the mathematically natural transition from
ﬁnite to inﬁnite decimal fractions.) The set of all possible outcomes is then

 = {0,1}N =%ω = (ωi )i∈N : ωi ∈ {0,1}& ,

the set of all inﬁnite sequences of zeros and ones.

As the examples demonstrate, the ﬁrst step in the process of setting up a model for
a random phenomenon is to decide which possibilities we would like to distinguish
and observe, and which idealising assumptions might be useful. Considering this, one
determines a set  of relevant outcomes. This  is called the set of outcomes or the
sample space.

1.1.2 Determining a σ-Algebra of Events
In general we are not interested in the detailed outcome of a random experiment, but
only in the occurrence of an event that consists of a certain selection of outcomes. Such
events correspond to subsets of .
(1.4) Example. Events as sets of outcomes. The event ‘In n coin ﬂips, heads shows at
least k times’ corresponds to the subset

n#i=1

ωi ≥ k$

A ="ω = (ω1, . . . , ωn) ∈  :

of the sample space  = {0,1}n.
Our aim is to set up a system F of events, such that we can consistently assign to
each event A ∈ F a probability P(A) for A to occur.
Why so cautious? Why not assign a probability to every subset of , in other words,
why not simply take F to be the power set P() (i.e., the set of all subsets of )?
Indeed, this is perfectly possible as long as  is countable. However, it is impossible
in general, as the following ‘no-go theorem’ shows.

P’(i≥1

Ai) =*i≥1

P(Ai ) .

(The probabilities of countably many incompatible events can be added up.)
(I) Flip invariance: For all A ⊂  and n ≥ 1 one has P(Tn A) = P(A); here

Tn : ω = (ω1, ω2, . . . ) → (ω1, . . . , ωn−1,1 − ωn, ωn+1, . . . )

1.1 Probability Spaces

9
(1.5) Theorem. The power set is too large, Vitali 1905.
Let  = {0,1}N be the
sample space for inﬁnite coin tossing. Then there is no mapping P : P() → [0,1]
with the properties
(N) Normalisation: P() = 1.
(A) σ-Additivity: If A1, A2, . . . ⊂  are pairwise disjoint, then

is the mapping from  onto itself that inverts the result of the nth toss, and
Tn A = {Tn(ω) : ω ∈ A} is the image of A under Tn. (This expresses the fairness
of the coin and the independence of the tosses.)
At ﬁrst reading, only this result is important, and its proof may be skipped.

Proof. We deﬁne an equivalence relation ∼ on  as follows. Say ω ∼ ω′ if and only if ωn = ω′n
for all sufﬁciently large n. By the axiom of choice, there is a set A ⊂  that contains exactly
one element from each equivalence class.
Let S = {S ⊂ N : |S| < ∞} be the set of all ﬁnite subsets of N. As S is the union
of the countably many ﬁnite sets {S ⊂ N : max S = m} for m ∈ N, it is countable. For
S = {n1, . . . , nk} ∈ S let TS :=+n∈S Tn = Tn1 ◦ ··· ◦ Tnk be the ﬂip at all times contained
in S. Then we have:
◃  =,S∈ S TS A , since for every ω ∈  there exists an ω′ ∈ A such that ω ∼ ω′, and
thus an S ∈ S with ω = TSω′ ∈ TS A.
◃ The sets (TS A)S∈ S are pairwise disjoint. For, suppose that TS A ∩ TS′ A ̸= ∅ for some
S, S′ ∈ S . Then there exist ω, ω′ ∈ A such that TSω = TS′ ω′ and so ω ∼ TSω =
TS′ ω′ ∼ ω′. By the choice of A, this means that ω = ω′ and thus S = S′.

Applying successively the properties (N), (A) and (I) of P we thus ﬁnd

1 = P() = *S∈S

P(TS A) = *S∈S

P(A) .

This is impossible, since the inﬁnite sum of the same number is either 0 or ∞. ✸
How to proceed after this negative result? We have to insist on the properties (N),
(A) and (I), since (N) and (A) are indispensable and elementary (just ﬁnite additivity
is not sufﬁcient, as we will see shortly), and (I) is characteristic of the coin tossing
model. But the above proof has shown that the problems only arise for rather unusual,
‘abnormal’ sets A ⊂ . A natural way out is therefore to restrict the deﬁnition of
probabilities to an appropriate subsystem F ⊂ P(), which excludes the ‘abnormal’

10

1 Principles of Modelling Chance

sets. Fortunately, it turns out that this sufﬁces both in theory and in practice.
In
particular, we will see in Example (3.29) that a function P satisfying (N), (A) and (I)
can indeed be deﬁned on a suitable, sufﬁciently large F.

What are sensible properties we should ask of the system F ? The minimal re-

(F contains the ‘certain event’)

quirements are apparently those in the following
Deﬁnition. Suppose  ̸= ∅. A system F ⊂ P() satisfying
(a)  ∈ F
(b) A ∈ F ⇒ Ac :=  \ A ∈ F
(c) A1, A2, . . . ∈ F ⇒ ,i≥1 Ai ∈ F
(F allows the countable logical ‘or’)
is called a σ-algebra (or σ-ﬁeld) on . The pair (, F ) is then called an event space
or a measurable space.

(F allows the logical negation)

These three properties can be combined to obtain some further properties of a σ-
algebra F. By (a) and (b), the ‘impossible event’ ∅ belongs to F. Together with (c)
this gives, for A, B ∈ F, that A∪B = A∪B∪∅∪··· ∈ F, A∩B = (Ac∪Bc)c ∈ F,
and A \ B = A ∩ Bc ∈ F. Similarly, the countable intersection of sets in F also
belongs to F.
The σ in the name σ-algebra has become convention as a reminder of the fact that,
in (c), we consider countably inﬁnite (instead of only ﬁnite) unions (σ like ‘sums’).
Finite unions are not sufﬁcient, because we also need to consider so-called tail events,
such as ‘coin falls heads for inﬁnitely many tosses’ or ‘the relative frequency of heads
tends to 1/2, if the number of tosses tends to ∞’. Such events can not be captured by
ﬁnite unions, but require countably inﬁnite unions (and intersections).
At this point, let us pause for a moment to distinguish between the three set-theoretic levels
we are moving on; see Figure 1.1. The base level consists of the set  containing all outcomes
ω. Above this there is the event level P(); its elements are subsets of the base level . This
structure repeats itself once more: σ-algebras are subsets of P(), so they are elements of the
top level P(P()).

P(P())

F

systems of events

P()



-

ω

./
0F

A

-

events

outcomes

Figure 1.1. The three conceptual levels of stochastics.

A

./

0

1.1 Probability Spaces

11

How can one determine a σ-algebra in ? One starts from a system G of ‘good’,
that is, especially simple or natural sets, whose probability one can easily guess or
determine. Then this system is enlarged just as much as necessary to obtain a σ-
algebra. More precisely, the following construction principle can be used.
(1.6) Remark and Deﬁnition. Generating σ-algebras. If  ̸= ∅ and G ⊂ P()
is arbitrary, then there is a unique smallest σ-algebra F = σ (G ) on  such that
F ⊃ G . This F is called the σ-algebra generated by G , and G is called a generator
of F.
Proof. Let Σ be the system of all σ-algebras A in  satisfying A ⊃ G . (So Σ is
a subset of the top level in Figure 1.1.) Σ is non-empty, since P() ∈ Σ. Hence,
we can set F := 1A ∈Σ
A . As each A ∈ Σ is a σ-algebra, so is F, as is easily
checked by spelling out the deﬁning properties (a) to (c). F thus belongs to Σ, and is
obviously its unique smallest element. This proves the claim. ✸

Here are three standard examples of this construction.

(1.7) Example. The power set. Suppose  is countable and G =%{ω} : ω ∈ & the
system containing the singleton sets of . Then, σ (G ) = P(). Indeed, since every
A ∈ P() is countable, it follows from axiom (c) that A =,ω∈A{ω} ∈ σ (G ).
(1.8) Example and Deﬁnition: The Borel σ-algebra. Let  = Rn and

G =" n2i=1[ai , bi] : ai < bi , ai , bi ∈ Q$

be the system consisting of all compact rectangular boxes in Rn with rational vertices
and edges parallel to the axes. In honour of Émile Borel (1871–1956), the system
Bn := σ (G ) is called the Borel σ-algebra on Rn, and every A ∈ Bn a Borel set; in
the case n = 1, we simply write B instead of B1. The Borel σ-algebra is much larger
than one might expect at ﬁrst sight. Namely, we have:
(a) Every open set A ⊂ Rn is Borel. To see this, it is sufﬁcient to note that every
ω ∈ A has a neighbourhood Q ∈ G with Q ⊂ A, so that A =,Q∈G , Q⊂A Q ,
a union of countably many sets. Our claim thus follows from property (c) of a
σ-algebra.
(b) Every closed A ⊂ Rn is Borel, since Ac is open and hence by (a) Borel.
(c) It is impossible to describe Bn constructively. It does not only consist of count-
able unions of boxes and their complements; rather, the procedure of taking
complements and countable unions has to be repeated as many times as there
are countable ordinal numbers, hence uncountably often; see [32], p.139, or [6],
pp.24, 29. But this does not cause problems. It sufﬁces to know that Bn is large
enough to contain all sets in Rn that may occur in practice, but still smaller than
P(R). In fact, the existence of non-Borel sets follows from Theorem (1.5) and
the proof of Theorem (3.12).

12

1 Principles of Modelling Chance

We will also need the following facts:
(d) Besides the system G of compact intervals, the Borel σ-algebra B = B 1 on R

also admits the generator

G ′ =%]−∞, c] : c ∈ R& ,

the system of all left-inﬁnite closed half-lines. For, assertion (b) shows that
G ′ ⊂ B and thus, by the minimality of σ (G ′), σ (G ′) ⊂ B. Conversely, σ (G ′)
contains all half-open intervals ]a, b] = ]−∞, b]\ ]−∞,a], and so all compact
intervals [a, b] = 1n≥1]a−
1
n , b], hence also the σ-algebra B generated by
them.
Likewise, B can also be generated by the left-inﬁnite open half-lines, and also
by the open or closed right-inﬁnite half-lines.

(e) For ∅ ̸=  ⊂ Rn, the system B n
is called the Borel σ-algebra on .

 = {A ∩  : A ∈ Bn} is a σ-algebra on ; it

(1.9) Example and Deﬁnition: Product σ-algebra. Let  be the Cartesian product
of arbitrary sets Ei, i.e.,  =+i∈I Ei for an index set I ̸= ∅. Let Ei be a σ-algebra
on Ei , Xi
:  → Ei the projection mapping onto the ith coordinate, and G =
{X−1
i Ai : i ∈ I, Ai ∈ Ei} the system of all sets in  which are speciﬁed by an event
in a single coordinate. Then,3i∈I Ei := σ (G ) is called the product σ-algebra of the
Ei on . If Ei = E and Ei = E for all i, we write E ⊗I instead of3i∈I Ei. For
example, the Borel σ-algebra Bn on Rn is exactly the n-fold product σ-algebra of the
Borel σ-algebra B = B1 on R, meaning that Bn = B⊗n ; cf. Problem 1.3.
The second step in the process of building a model can now be summarised as fol-
lows. Theorem (1.5) forces us to introduce a σ-algebra F of events in . Fortunately,
in most cases the choice of F is canonical. In this book, only the following three
standard cases will appear:

◃ Discrete case:
◃ Real case: For  ⊂ Rn, the natural choice is F = B n
.
◃ Product case:
one takes F =3i∈I Ei.

If  is at most countable, one can set F = P().
If  =+i∈I Ei and every Ei is equipped with a σ-algebra Ei,
Once a σ-algebra F is ﬁxed, every A ∈ F is called an event or a measurable set.
1.1.3 Assigning Probabilities to Events
The decisive point in the process of building a stochastic model is the next step: For
each A ∈ F we need to deﬁne a value P(A) ∈ [0,1] that indicates the probability
of A. Sensibly, this should be done so that the following holds:

P(Ai ) .

P’(i≥1

Ai) =*i≥1
(Pairwise disjoint means that Ai ∩ Aj = ∅ for i ̸= j.)
Deﬁnition. Let (, F ) be an event space. A function P : F → [0,1] satisfying the
properties (N) and (A) is called a probability measure or a probability distribution, in
short a distribution (or, a little old-fashioned, a probability law) on (, F ). Then, the
triple (, F , P) is called a probability space.

Properties (N) and (A), together with the non-negativity of the probability measure, are also
known as Kolmogorov’s axioms, since it was Andrej N. Kolmogorov (1903–1987) who in 1933
emphasised the signiﬁcance of measures for the mathematical foundation of probability theory,
and thus gave a decisive input for the development of modern probability theory.

Let us summarise: To describe a particular scenario of chance mathematically, one
has to choose an appropriate probability space. Typically, the most delicate point is the
choice of the probability measure P, since this contains all the relevant information
about the kind of randomness. In Chapter 2, as well as in many examples later on,
we will show how this can be done. At this point let us only mention the elementary,
but degenerate, example of a probability measure that describes a situation without
randomness.
(1.10) Example and Deﬁnition: Deterministic case. If (, F ) is an arbitrary event
space and ξ ∈ , then

δξ (A) =4 1

0

if ξ ∈ A ,
otherwise

1.1 Probability Spaces
(N) Normalisation: P() = 1.
(A) σ-Additivity: For pairwise disjoint events A1, A2, . . . ∈ F one has

13

deﬁnes a probability measure δξ on (, F ). It describes an experiment with the certain
outcome ξ and is called the Dirac distribution or the unit mass at the point ξ.

We close this section with some remarks on the

Interpretation of probability measures. The concept of a probability space does not
give an answer to the philosophical question what probability really is. The following
are common answers:

(a) The naive interpretation. ‘Nature’ is uncertain about what it is doing, and P(A)

represents the degree of certainty of its decision to let A happen.

(b) Thefrequencyinterpretation. P(A)istherelativefrequencywithwhich Aoccurs

under some speciﬁed conditions.

(c) The subjective interpretation. P(A) isthe degreeofcertaintywithwhichIwould
be willing to bet on the occurrence of A according to my personal evaluation of
the situation.

14

1 Principles of Modelling Chance

(The interpretations (a) and (c) are dual concepts, the uncertainty moves from nature
to the observer.)
In general, we cannot say which interpretation is to be preferred, since this de-
pends on the nature of the problem at hand. If a random experiment can be repeated
independently, the interpretations (a) and (b) may seem most natural. The American
weather forecast (with forecast probabilities) is obviously based on (b), and so are the
probabilities used in the insurance industry. The question that was asked before March
23 in 2001, namely ‘What is the probability that humans will be injured by the crash
of the space station “Mir”?’, used the subjective interpretation (c), since it dealt with
a singular event. A comprehensive and very stimulating historical and philosophical
discussion of the notion of probability can be found in Gigerenzer et al. [23].
Fortunately, the validity of the mathematical statements about a probability model
does not depend on its interpretation. The value of mathematics is not limited by
the narrowness of human thought. This, however, should not to be misunderstood to
mean that mathematics can take place in an ‘ivory tower’. Stochastics thrives on the
interaction with the real world.
1.2 Properties and Construction of Probability Measures
Letusdwellforamomentonthe σ-additivityassumption(A).Thenexttheoremcollects
some immediate consequences of σ-additivity.
(1.11) Theorem. Probability rules. Every probability measure P on an event space
(, F ) has the following properties, for arbitrary events A, B, A1, A2, . . . ∈ F.
(a) P(∅) = 0.
(b) Finite additivity. P(A∪ B)+ P(A∩ B) = P(A)+ P(B), and so in particular
P(A) + P(Ac) = 1.
(c) Monotonicity.
If A ⊂ B then P(A) ≤ P(B).
(d) σ-Subadditivity. P5,i≥1 Ai6 ≤#i≥1 P(Ai ).
If either An ↑ A or An ↓ A (i.e., the An are either increasing
with union A, or decreasing with intersection A), then P(An) −→n→∞
Proof. (a) Since the empty set is disjoint to itself, the sequence ∅, ∅, . . . consists of
pairwise disjoint events. In this extreme case, σ-additivity (A) thus gives

(e) σ-Continuity.

P(A).

P(∅) = P(∅ ∪ ∅ ∪ ··· ) =

P(∅) .

∞#i=1

But this is only possible when P(∅) = 0.
(b) Suppose ﬁrst that A and B are disjoint. Since property (A) requires an inﬁnite
sequence, we append the empty set inﬁnitely often to the sets A and B. Hence we
obtain from (A) and statement (a)

P(A ∪ B) = P(A ∪ B ∪ ∅ ∪ ∅ ∪ ··· ) = P(A) + P(B) + 0 + 0 + ··· .

1.2 Properties and Construction of Probability Measures

15

So the probability is additive when an event is split into ﬁnitely many disjoint parts. In
the general case, it thus follows that

P(A ∪ B) + P(A ∩ B) = P(A \ B) + P(B \ A) + 2P(A ∩ B)

= P(A) + P(B) .

The second assertion follows from the normalisation axiom (N) by taking B = Ac.
(c) For B ⊃ A we conclude from (b) that P(B) = P(A) + P(B \ A) ≥ P(A)
because probabilities are non-negative.
(d) Any union,i≥1 Ai can actually be represented as a union of disjoint sets, by
removing from Ai the part of Ai that is already contained in a ‘previous’ Aj. This
procedure is known as the ‘ﬁrst entrance trick’. So we can write, using assumption (A)
and statement (c),

Aj) ≤*i≥1

P(Ai ) .

Ai) = P’(i≥1

P’(i≥1
(e) If An ↑ A, the σ-additivity (A) and the ﬁnite additivity (b) give, with A0 := ∅,

P’Ai \,j <i

Aj )) =*i≥1

(Ai \,j <i
P(A) = P’(i≥1
(Ai \ Ai−1)) =*i≥1
n*i=1
= limn→∞
P(Ai \ Ai−1) = limn→∞

P(Ai \ Ai−1)

P(An) .

The case An ↓ A follows by taking complements and using (b). ✸
A less obvious, but equally important consequence of σ-additivity is the fact that
each probability measure is already determined by its restriction to a suitable generator
of the σ-algebra.
(1.12) Theorem. Uniqueness theorem. Let (, F , P) be a probability space, and
suppose that F = σ (G ) for a generator G ⊂ P(). If G is intersection-stable, in
the sense that A, B ∈ G implies A ∩ B ∈ G , then P is uniquely determined by its
restriction P|G to G .
Although we will apply the uniqueness theorem repeatedly, its proof should be skipped at
ﬁrst reading, since this kind of reasoning will not be used later on.
Proof. Let Q be an arbitrary probability measure on (, F ) such that P|G = Q|G . The system
D = {A ∈ F : P(A) = Q(A)} then exhibits the following properties.
(a)  ∈ D
(b) If A, B ∈ D and A ⊂ B, then B \ A ∈ D
(c) If A1, A2, . . . ∈ D are pairwise disjoint, then,i≥1 Ai ∈ D

16

1 Principles of Modelling Chance

Indeed, (a) follows from (N), (c) from (A), and (b) is immediate because P(B \ A) = P(B) −
P(A) for A ⊂ B. A system D satisfying (a) to (c) is called a Dynkin system (after the Russian
mathematician E.B. Dynkin, *1924). By assumption we have D ⊃ G . Thus D also contains
the Dynkin system d(G ) generated by G . As in Remark (1.6), d(G ) is deﬁned to be the smallest
Dynkin system containing G ; the existence of such a smallest Dynkin system is proved in exactly
the same way as indicated there. The following lemma will show that d(G ) = σ (G ) = F. As
a consequence, we have that D = F and hence P = Q. ✸
To complete the proof, we need the following lemma.

(1.13) Lemma. Generated Dynkin system. For an intersection-stable system G , the identity
d(G ) = σ (G ) holds.
Proof. Since σ (G ) is a σ-algebra, it is also a Dynkin system, and since d(G ) is minimal, we
have σ (G ) ⊃ d(G ). Conversely, we will show that d(G ) is a σ-algebra. For, this implies that
σ (G ) ⊂ d(G ) by the minimality of σ (G ).
Step 1. d(G ) is intersection-stable. Indeed, D1 :={A ⊂  : A ∩ B ∈ d(G ) for allB ∈ G}
is obviously a Dynkin system, and since G is intersection-stable, we have D1 ⊃ G . By the
minimality of d(G ), it then follows that D1 ⊃ d(G ), i.e., we have A ∩ B ∈ d(G ) for all
A ∈ d(G ) and B ∈ G .
Similarly, D2 := {A ⊂  : A ∩ B ∈ d(G ) for all B ∈ d(G )} is also a Dynkin system,
and, by the above, D2 ⊃ G . Hence, we also have D2 ⊃ d(G ), i.e., A ∩ B ∈ d(G ) for all
A, B ∈ d(G ).

Step 2. d(G ) is a σ-algebra. For, let A1, A2, . . . ∈ d(G ). By Step 1, the sets

Bi := Ai \(j <i

Aj = Ai ∩7j <i

 \ Aj

then also belong to d(G ) and are pairwise disjoint. Hence,i≥1 Ai =,i≥1 Bi ∈ d(G ). ✸

Our next question is: How can one construct a probability measure on a σ-algebra?
In view of the uniqueness theorem, we can reformulate this question as follows: Under
which conditions can we extend a function P deﬁned on a suitable system G to a
probability measure deﬁned on the generated σ-algebra σ (G )?
A satisfactory answer is given by a theorem from measure theory, namely
Carathéodory’s extension theorem, see for example [4, 6, 12, 15, 16]; here we will
not discuss this further. However, to guarantee the existence of non-trivial probability
measures on non-discrete sample spaces, we will have to take the existence of the
Lebesgue integral for granted. We will make use of the following
(1.14) Fact. Lebesgue integral. For every function f : Rn → [0,∞] that satisﬁes the
measurability criterion
(1.15)
(which will be discussed further in Example (1.26) below), one can deﬁne the Lebesgue

{x ∈ Rn : f (x) ≤ c} ∈ Bn

for all c > 0

integral8 f (x) dx ∈ [0,∞] in such a way that the following holds.

1.2 Properties and Construction of Probability Measures

17

(a) For every Riemann-integrable function f , 8 f (x) dx coincides with the Rie-

(b) For every sequence f1, f2, . . . of non-negative measurable functions as above,

mann integral of f .

we have

9 *n≥1

fn(x) dx =*n≥19 fn(x) dx .

0

A proof of these statements can be found in numerous textbooks on analysis, such as [52, 53].
As property (a) shows, in concrete computations it often sufﬁces to know the Riemann integral.
However, the Riemann integral does not satisfy the σ-additivity property (b), which is essential
forourpurposes; itisequivalenttothemonotoneconvergence theorem, seealsoTheorem(4.11c)
later on.

9A

In particular, the Lebesgue integral yields a sensible notion of volume for Borel

sets in Rn. Namely, let
(1.16)
denote the indicator function of a set A. The integral over A ∈ Bn is then deﬁned as

if x ∈ A ,
otherwise

1A(x) =4 1
f (x) dx :=9 1A(x) f (x) dx .

In the special case f ≡ 1, property (1.14b) then gives us the following result.
(1.17) Remark and Deﬁnition. Lebesgue measure. The mapping λn : Bn →[0,∞]
that assigns to each A ∈ Bn its n-dimensional volume
λn(A) :=9 1A(x) dx
 of λn to Bn

satisﬁes the σ-additivity property (A), and we have λn(∅) = 0. Consequently, λn is
a ‘measure’ on (Rn, Bn). It is called the (n-dimensional) Lebesgue measure on Rn.
For  ∈ Bn, the restriction λn
We will see repeatedly that the existence of many interesting probability measures
can be deduced from the existence of the Lebesgue measure. Here, we will use the
Lebesgue measure for constructing probability measures on Rn (or subsets thereof) by
means of density functions, a procedure which is obvious for discrete spaces.
(1.18) Theorem. Construction of probability measures via densities.

 is called the Lebesgue measure on .

(a) Discrete case: For countable , the relations

ϱ(ω)

for A ∈ P() , ϱ(ω) = P({ω})

P(A) =*ω∈A
establish a one-to-one correspondence between the probability measures P
on (, P()) and the sequences ϱ = (ϱ(ω))ω∈ in [0,1] such that
#ω∈ ϱ(ω) = 1.

for ω ∈ 

18

(b) Continuous case:

satisfying the properties
(i) {x ∈  : ϱ(x) ≤ c} ∈ B n
(ii) 8 ϱ(x) dx = 1

1 Principles of Modelling Chance
If  ⊂ Rn is Borel, then every function ϱ :  → [0,∞[

 for all c > 0 (cf. (1.15))

determines a unique probability measure P on (, B n
ϱ(x) dx for A ∈ B n

P(A) =9A

(but not every P is of this form).

) via



Proof. The discrete case is obvious. In the continuous case, the claim follows im-
disjoint. ✸

mediately from Fact (1.14b), since 1,i≥1 Ai = #i≥1 1Ai when the Ai are pairwise

Discrete case

ϱ(ω)

Continuous case

ω1 ω2 ω3

···

P(A)

A



Figure 1.2. On the left: bar chart of a discrete density. On the right: Lebesgue density;
its integral over an event A yields the probability P(A).

Deﬁnition. A sequence or function ϱ as in Theorem (1.18) above is called a density (of
P) or, more explicitly (to emphasise normalisation), a probability density (function),
often abbreviated as pdf. If a distinction between the discrete and continuous case is
required, a sequence ϱ = (ϱ(ω))ω∈ as in case (a) is called a discrete density, and a
function ϱ :  → [0,∞[ as in case (b) a Lebesgue density.
A basic class of probability measures deﬁned by densities is given by the uniform
distributions, which will be discussed in more detail in Section 2.1.
(1.19) Example and Deﬁnition: The uniform distributions. If  is ﬁnite, the proba-
bility measure having the constant discrete density ϱ(ω) = 1/|| (so that all ω ∈ 
occur with the same probability) is called the (discrete) uniform distribution on  and
is denoted by U.
Likewise, if  ⊂ Rn is a Borel set with volume 0 < λn() < ∞, the probability
measure on (, B) with the constant Lebesgue density ϱ(x) = 1/λn() is called
the (continuous) uniform distribution on ; it is also denoted by U.

1.3 Random Variables

19

P(A) =

1
3 δ−1/2(A) +

2
3 U]0,1/2[(A) , A ∈ B,

Obviously, we can combine discrete and continuous probability measures. For

Probability measures on subsets of Rn can also be interpreted as probability mea-
sures on all of Rn. More precisely, if  ⊂ Rn is a Borel set and P a probability measure
) with Lebesgue density ϱ, we can clearly identify P with the probability
on (, B n
measure ¯P on (Rn, Bn) with density ¯ϱ, where ¯ϱ(x) = ϱ(x) for x ∈  and ¯ϱ(x) = 0
. We will
otherwise; indeed, we have ¯P(Rn \ ) = 0, and ¯P and P coincide on B n
often carry out this identiﬁcation without mentioning it explicitly. There is also an
analogue in the discrete case: If  ⊂ Rn is countable and P a probability measure on
(, P()) with discrete density ϱ, we can identify P with the probability measure
#ω∈ ϱ(ω) δω, which is deﬁned on (Rn, Bn), or in fact even on (Rn, P(Rn)); here
δω is the Dirac measure introduced in (1.10).
example,
(1.20)
deﬁnes a probability measure on (R, B ), which for two thirds is ‘blurred uniformly’
over the interval ]0,1/2[ and assigns the extra probability 1/3 to the point −1/2.
1.3 Random Variables
Let us return for a moment to the ﬁrst step of setting up a model, as described in
Section 1.1.1. The choice of the sample space  is not unique, but depends on how
many details of the random phenomenon should be included into the model, and is
therefore a matter of the appropriate observation depth.
(1.21) Example. Tossing a coin n times. On the one hand, one can record the result
of every single toss; then  = {0,1}n is the appropriate sample space. Alternatively,
one may restrict attention to the number of tosses when heads is showing. Then, the
natural sample space is ′ = {0,1, . . . , n}. The second case corresponds to a lower
observation depth. The process of reducing the observation depth can be described
by the mapping X :  → ′ that assigns to each ω = (ω1, . . . , ωn) ∈  the sum
#n
i=1 ωi ∈ ′, which indicates the ‘number of successes’.
The example shows: The transition from a given event space (, F ) to a coarser
model (′, F ′) providing less information is captured by a mapping from the detailed
to the coarser sample space, i.e., from  to ′. In the general case, such a mapping
should satisfy the requirement
(1.22)
that is, all events on the coarse level can be traced back to events on the detailed level
via the preimage mapping X−1. The situation is visualised in Figure 1.3.

A′ ∈ F ′ ⇒ X−1A′ ∈ F ,

20

1 Principles of Modelling Chance

X−1A′

X



A′

′

Figure 1.3. For a random variable, the preimage of an event in ′ is an event in .

Deﬁnition. Let (, F ) and (′, F ′) be two event spaces. Then every mapping
X :  → ′ satisfying property (1.22) is called a random variable from (, F ) to
(′, F ′), or a random element of ′. Alternatively (in the terminology of measure
theory), X is said to be measurable relative to F and F ′.

Due to (1.22), preimages will occur frequently in the following. In stochastics, it

is common to use for them the suggestive notation
(1.23)

{X ∈ A′} := {ω ∈  : X (ω) ∈ A′} = X−1A′ .

Let us note ﬁrst that condition (1.22) holds automatically in the discrete case.

(1.24) Example. Random variables on discrete spaces. If F = P(), then every
mapping X :  → ′ is a random variable.

In the general case, the following criterion is crucial.

:= {A′ ⊂ ′

(1.25) Remark. Measurability criterion.
In the set-up of the previous deﬁnition,
suppose that F ′ is generated by a system G ′, in that F ′ = σ (G ′). Then X :  → ′
is already a random variable when X−1A′ ∈ F for all A′ ∈ G ′ only.
: X−1A′ ∈ F} is a σ-algebra, which by
Proof. The system A ′
assumption contains G ′. Since F ′ is by deﬁnition the smallest such σ-algebra, we also
have A ′ ⊃ F ′, which means that X satisﬁes condition (1.22). ✸
(1.26) Example. Real random variables. Let (′, F ′) = (R, B ). For a real function
X :  → R to be a random variable, it is sufﬁcient that all sets of the form {X ≤ c} :=
X−1 ]−∞, c ] belong to F. (Alternatively, one can replace ‘≤’ by ‘<’, ‘≥’ or ‘>’.)
This follows immediately from Remark (1.25) and Fact (1.8d).
It is often convenient to consider so-called extended real functions taking values in
¯R = [−∞,∞]. ¯R is equipped with the σ-algebra generated by the intervals [−∞, c],
c ∈ R. (Think about how this relates to the Borel σ-algebra on R.) Consequently, an
extended real function X :  → ¯R is a random variable if and only if {X ≤ c} ∈ F
for all c ∈ R.

1.3 Random Variables
(1.27) Example. Continuous functions. Let  ⊂ Rn and F = B n
continuous function X :  → R is a random variable.
{X ≤ c} is closed in , so by Example (1.8be) it belongs to B n
follows from Example (1.26).

21
. Then every
Indeed, for every c ∈ R,
. Thus the claim

The next theorem describes an important principle for constructing new probability

measures, which will be used repeatedly.
(1.28) Theorem. Distribution of a random variable. If X is a random variable from a
probability space (, F , P) to an event space (′, F ′), then the prescription

P′(A′) := P(X−1A′) = P({X ∈ A′}) for A′ ∈ F ′

deﬁnes a probability measure P′ on (′, F ′).

To simplify the notation, we will omit the braces in expressions like P({X ∈ A′}), and
simply write P(X ∈ A′) in the future.
Proof. By (1.22) the deﬁnition of P′ makes sense. Furthermore, P′ satisﬁes the con-
ditions (N) and (A). For, P′(′) = P(X ∈ ′) = P() = 1, and if A′1, A′2, . . . ∈ F ′
are pairwise disjoint, so are their preimages X−1A′1, X−1A′2, . . ., whence

P′(,i≥1

A′i ) = P(X−1,i≥1
=*i≥1

A′i ) = P(,i≥1
P(X−1A′i ) = *i≥1

X−1A′i )
P′(A′i ) .

Hence P′ is a probability measure. ✸
Deﬁnition. (a) The probability measure P′ in Theorem (1.28) is called the distribution
of X under P, or the image of P under X, and is denoted by P ◦ X−1.
(In the
literature, one also ﬁnds the notations PX or L (X;P). The letter L stands for the
more traditional term law, or loi in French.)
(b) Two random variables are said to be identically distributed if they have the same
distribution.

At this point, we need to point out that the term ‘distribution’ is used in an inﬂa-
tionary way in stochastics. Apart from the meaning that we have just introduced, it is
also generally used as a synonym for probability measure. (In fact, every probability
measure is the distribution of a random variable, namely the identity function of the
underlying .) This has to be distinguished from two further notions, namely ‘distri-
bution function’ and ‘distribution density’, which refer to the real event space (R, B )
and will be introduced now.
Each probability measure P on (R, B ) is already uniquely determined by the
function FP (c):= P(]−∞, c]) for c ∈ R. Likewise, the distribution of a real-valued
random variable X on a probability space (, F , P) is uniquely determined by the
function FX : c → P(X ≤ c) on R. This is because any two probability measures

22
1 Principles of Modelling Chance
on (R, B ) coincide if and only if they agree on all intervals of the form ]−∞, c],
by statement (1.8d) and the uniqueness theorem (1.12). This motivates the following
concepts.
Deﬁnition. For a probability measure P on the real line (R, B ), the function FP :
c → P(]−∞, c]) from R to [0,1] is called the (cumulative) distribution function
of P. Likewise, for a real random variable X on a probability space (, F , P), the
distribution function FX (c) := FP◦X−1 (c) = P(X ≤ c) of its distribution is called the
(cumulative) distribution function of X.
Every distribution function F = FX is increasing and right-continuous and has the

asymptotic behaviour
(1.29)
ThisfollowsimmediatelyfromTheorem(1.11); seeProblem1.15. Figure1.4showsan
example. Remarkably, every function with these properties is the distribution function
of a random variable on the unit interval (equipped with the uniform distribution from
Example (1.19)). The term ‘quantile’ occurring in the name of these random variables
will play an important role in statistics, i.e., in Part II; see the deﬁnition on p.226.

F(c) = 0 and

limc→+∞

F(c) = 1 .

limc→−∞

1

1/2

-1/2

1/2

-1/2

F

X

1

Figure 1.4. Distribution function F (bold) and quantile transformation X (dashed) of the
probability measure 1
2
3 U]0,1/2[ from (1.20). The dotted lines illustrate that X
is obtained from F by reﬂection at the diagonal. The values at the discontinuities are
marked by bullets.

3 δ−1/2 +

(1.30) Proposition. Quantile transformation. For every increasing right-continuous
function F on R with limit behaviour (1.29), there exists a real random variable X
on the probability space (]0,1[, B]0,1[, U]0,1[) such that FX = F. This X is given
explicitly by

X (u) = inf{c ∈ R : F(c) ≥ u} , u ∈ ]0,1[ ,

and is called the ‘quantile transformation’.

23
Problems
Proof. By (1.29) we have −∞ < X (u) < ∞ for all 0 < u < 1. In fact, X is a
left-continuous inverse of F; compare Figure 1.4. Indeed, X (u) ≤ c holds if and only
if u ≤ F(c); this is because, by the right-continuity of F, the inﬁmum in the deﬁnition
of X is in fact a minimum. In particular, {X ≤ c} = ]0, F(c)] ∩ ]0,1[ ∈ B]0,1[.
Together with Example (1.26) this shows that X is a random variable. Furthermore,
the set {X ≤ c} has Lebesgue measure F(c). Hence F is the distribution function of
X. ✸
Since every probability measure P on (R, B ) is uniquely determined by its distri-
bution function, we can rephrase the proposition as follows: Every P on (R, B ) is the
distribution of a random variable on the probability space (]0,1[, B]0,1[, U]0,1[). This
fact will repeatedly be useful.
The connection between distribution functions and probability densities is made by
the notion of a distribution density.
(1.31) Remark and Deﬁnition. Existence of a distribution density. Let X be a real
random variable on a probability space (, F , P). Its distribution P ◦ X−1 admits a
Lebesgue density ϱ if and only if

FX (c) =9 c

−∞

ϱ(x) dx for all c ∈ R.

In particular, P ◦ X−1 admits a
Such a ϱ is called the distribution density of X.
continuous density ϱ if and only if FX is continuously differentiable, and then ϱ = F′X.
This follows directly from (1.8d) and the uniqueness theorem (1.12).

Problems
1.1. Let (, F ) be an event space, A1, A2, . . . ∈ F and

A = {ω ∈  : ω ∈ An for inﬁnitely many n}.
1An .

(b) 1A = lim supn→∞

Show that (a) A =1N≥1,n≥N An,
1.2. Let  be uncountable and G = {{ω} : ω ∈ } the system of the singleton subsets of .
Show that σ (G ) = {A ⊂  : A or Ac is countable}.
1.3. Show that the Borel σ-algebra B n on Rn coincides with B ⊗n, the n-fold product of the
Borel σ-algebra B on R.
1.4. Let  ⊂ Rn be at most countable. Show that B n
1.5. Let Ei, i ∈ N, be countable sets and  =+i≥1 Ei their Cartesian product. Denote by
Xi :  → Ei the projection onto the ith coordinate. Show that the system
G =%{X1 = x1, . . . , Xk = xk} : k ≥ 1, xi ∈ Ei& ∪%∅&
is an intersection-stable generator of the product σ-algebra3i≥1 P(Ei ).

 = P().

24

1 Principles of Modelling Chance

Inclusion–exclusion principle. Let (, F , P) be a probability space and Ai ∈ F, i ∈ I =

1.6.
{1, . . . , n}. For J ⊂ I let

by convention, an intersection over an empty index set is equal to . Show the following:
(a) For all K ⊂ I,

BJ = 7j∈J

P51k∈K

Ac
j ;

Aj ∩ 7j∈I\J
Ak6 = *K⊂J⊂I

P(BJ ).

P(BJ ) = *J⊂K⊂I

(−1)|K\J|P51k∈K

Ak6.

(b) For all J ⊂ I,

1.7. Bonferroni inequality. Let A1, . . . , An be any events in a probability space (, F , P).
Show that

What does this imply for J = ∅?
n*i=1

P’ n(i=1

Ai) ≥

P(Ai ) − *1≤i <j≤n

P(Ai ∩ Aj ) .

1.8. A certain Chevalier de Méré, who has become famous in the history of probability theory
for his gambling problems and their solutions by Pascal, once mentioned to Pascal how surprised
he was that when throwing three dice he observed the total sum of 11 more often than the sum of
12, although 11 could be obtained by the combinations 6-4-1, 6-3-2, 5-5-1, 5-4-2, 5-3-3, 4-4-3,
and the sum of 12 by as many combinations (which ones?). Can we consider his observation
as caused by ‘chance’ or is there an error in his argument? To solve the problem, introduce a
suitable probability space.
1.9.
In a pack of six chocolate drinks every carton is supposed to have a straw, but it is missing
with probability 1/3, with probability 1/3 it is broken and only with probability 1/3 it is in
perfect condition. Let A be the event ‘at least one straw is missing and at least one is in perfect
condition’. Exhibit a suitable probability space, formulate the event A set-theoretically, and
determine its probability.
1.10. Alice and Bob agree to play a fair game over 7 rounds. Each of them pays e5 as an
initial stake, and the winner gets the total of e10. At the score of 2:3 they have to stop the
game. Alice suggests to split the winnings in this ratio. Should Bob accept the offer? Set up an
appropriate model and calculate the probability of winning for Bob.
1.11. The birthday paradox. Let pn be the probability that in a class of n children at least
two have their birthday on the same day. For simplicity, we assume here that no birthday is on
February29th, andallotherbirthdaysareequallylikely. Show(usingtheinequality1−x ≤ e−x)
that
and determine the smallest n such that pn ≥ 1/2.
1.12. The rencontre problem. Alice and Bob agree to play the following game: From two
completely new, identical sets of playing cards, one is well shufﬂed. Both piles are put next to
each other face down, and then revealed card by card simultaneously. Bob bets (for a stake of
e10) that in this procedure at least two identical cards will be revealed at the same time. Alice,

pn ≥ 1 − exp (−n(n − 1)/730) ,

Problems

25

however, is convinced that this is ‘completely unlikely’ and so bets the opposite way. Who do
you think is more likely to win? Set up an appropriate model and calculate the probability of
winning for Alice. Hint: Use Problem 1.6(b); the sum that appears can be approximated by the
corresponding inﬁnite series.
1.13. Let X, Y, X1, X2, . . . be real random variables on an event space (, F ). Prove the
following statements.
(X, Y ) :  → R2 is a random variable.
(a)
(b) X + Y and XY are random variables.
supn∈N Xn and lim supn→∞
(c)
(d)
{X = Y} ∈ F, {limn→∞ Xn exists} ∈ F, {X = limn→∞ Xn} ∈ F.
1.14. Let (, F ) = (R, B) and X :  → R be an arbitrary real function. Verify the
following:
(a)
If X is piecewise monotone (i.e., R may be decomposed into at most countably many
intervals, on each of which X is either increasing or decreasing), then X is a random
variable.
If X is differentiable with (not necessarily continuous) derivative X′, then X′ is a random
variable.

Xn are random variables (taking values in ¯R).

(b)

1.15. Properties of distribution functions. Let P be a probability measure on (R, B) and
F(c) = P(]−∞, c]), for c ∈ R, its distribution function. Show that F is monotone increasing
and right-continuous, and (1.29) holds.
1.16. Consider the two cases
(a)  = [0,∞[, ϱ(ω) = e−ω, X (ω) = (ω/α)1/β for ω ∈  and α, β > 0,
(b)  = ]−π/2, π/2[, ϱ(ω) = 1/π, X (ω) = sin2 ω for ω ∈ .
In each case, show that ϱ is a probability density and X a random variable on (, B), and
calculate the distribution density of X with respect to the probability measure P with density ϱ.
(The distribution of X in case (a) is called the Weibull distribution with parameters α, β, in case
(b) the arcsine distribution.)
1.17. Transformation to uniformity. Prove the following converse to Proposition (1.30): If
X is a real random variable with a continuous distribution function FX = F, then the random
variable F(X ) is uniformly distributed on [0,1].

2 Stochastic Standard Models

Having described the general structure of stochastic models, we will now discuss
how to ﬁnd suitable models for concrete random phenomena.
In general, this can
be quite delicate, and requires the right balance between being close to reality yet
mathematically tractable. At this stage, however, we conﬁne ourselves to several
classical examples, for which the appropriate model is quite obvious. This gives us the
opportunity to introduce some fundamental probability distributions along with typical
applications. These distributions can be used as building blocks of more complex
models, as we will see later on.

2.1 The Uniform Distributions
There are two different types of uniform distributions: the discrete ones on ﬁnite sets,
and the continuous uniform distributions on Borel subsets of Rn.
2.1.1 Discrete Uniform Distributions
Let us start with the simplest case of a random experiment with only ﬁnitely many
possible outcomes, i.e., an experiment with a ﬁnite sample space . For example,
we can think of tossing a coin or rolling a die several times. In these and many other
examples, symmetry suggests the assumption that all single outcomes ω ∈  are
equally likely. By Theorem (1.18a) this means that the probability measure P should
have the constant density ϱ(ω) = 1/|| (for ω ∈ ). This leads to the approach
P = U, where
(2.1)

number of ‘favourable’ outcomes
number of possible outcomes

U(A) = |A|
|| =

for all A ⊂  .

Deﬁnition. For a ﬁnite set , the probability measure U on (, P()) deﬁned
by (2.1) is called the (discrete) uniform distribution on . Sometimes (, P(), U)
is also called a Laplace space (in honour of Pierre Simon Laplace, 1749–1827).

Classical examples in which the uniform distribution shows up are tossing a coin or
rolling a die (once or several times), the lottery, playing cards, and many more. Several
of these examples will be discussed soon, in particular in Sections 2.2 and 2.3. A less
obvious example is the following.

2.1 The Uniform Distributions

27

,

kN

+ :

(2.2) Example. The Bose–Einstein distribution (1924). Consider a system of n in-
distinguishable particles that are distributed over N different ‘cells’; the cells are of
the same type, but distinguishable. For example, one can imagine the seeds in the
pits of the Syrian game Kalah, or – and this was Bose’s and Einstein’s motivation –
physical particles, whose phase space is partitioned into ﬁnitely many cells. A (macro)
state of the system is determined by specifying how many particles populate each cell.
Hence,

n
uniquely characterized by a sequence of the form

N"j=1
kj = n# .
 =!(k1, . . . , kN ) ∈ ZN
This sample space has cardinality || = $n+N−1
%, since each (k1, . . . , kN ) ∈  is
&’()

where the blocks of k1, . . . , kN balls are separated from each other by a total of N − 1
vertical bars. To determine a state, we only have to place the n balls (resp. the N − 1
vertical bars) into the n + N − 1 available positions. Hence, the uniform distribution
U on  is given by U({ω}) = 1/$n+N−1
%, ω ∈ . The assumption of a uniform
distribution agrees with the experimental results in the case of so-called bosons (i.e.,
particles with integer spin, such as photons and mesons).

•···•

&’()k1

|•···•

&’()k2

|···|•···•

Physicists often speak of Bose–Einstein ‘statistics’. In this traditional terminology, statistics
means the same as ‘probability distribution’ and has nothing in common with statistics in today’s
mathematical sense.
2.1.2 Continuous Uniform Distributions
Let us begin with a motivating example.
(2.3) Example. Random choice of a direction. Imagine we spin a roulette wheel. After
the wheel has stopped, into which direction is the zero facing? The angle it forms rela-
tive to a ﬁxed direction is a number in the interval  = [0,2π[, which is equipped with
the Borel σ-algebra F := B. Which probability measure P describes the situation?
For every n ≥ 1,  can be partitioned in the n disjoint intervals [ k
n 2π[ with
0 ≤ k < n. By symmetry, each of these should receive the same probability, which is
then necessarily equal to 1/n. That is, we should have

n 2π, k+1

n

P*+k
n 2π,

k + 1
n
for 0 ≤ k < n and, by additivity,
P*+k
n2π,

2π+, =
n2π+, =- l

l

n 2π
k
n 2π

1
2π

dx

n 2π

1

n =- k+1

k
n 2π

1
2π

dx

28
2 Stochastic Standard Models
for 0 ≤ k < l ≤ n. By Theorems (1.12) and (1.18), there exists only one probability
measure P with this property, namely the one with the constant Lebesgue density 1/2π
on [0,2π[. This P reﬂects the idea that all possible directions are equally likely.
Deﬁnition. Let  ⊂ Rn be a Borel set with n-dimensional volume 0 < λn() <∞;
cf. (1.17). The probability measure U on (, B n
) with constant Lebesgue density
ϱ(x) = 1/λn(), which is given by
U(A) =-A
1

λn(A)
λn()
is called the (continuous) uniform distribution on .

dx =

, A ∈ B n

 ,

λn()

Note that, depending on the context, U can either stand for a discrete or a con-
tinuous distribution. But both cases are completely analogous. The favourable resp.
possible outcomes are simply counted in the discrete case (2.1), whereas in the contin-
uous case they are measured with the Lebesgue measure. The following application of
continuous uniform distributions is an example of historical interest, and also a little
taster from so-called stochastic geometry.
(2.4) Example. Bertrand’s paradox. Given a circle with radius r > 0, a chord is
chosen ‘at random’. What is the probability that it is longer than the sides of an
inscribed equilateral triangle? (This problem appeared in 1889 in a textbook of the
French mathematician J.L.F. Bertrand, 1822–1900.)

Figure 2.1. The geometry of Bertrand’s paradox. The incircle of the inscribed equilateral
triangle has half the radius.
The answer depends on what one considers a ‘random choice’ or, in other words,

it depends on the method the chord is chosen.

First approach. The chord is uniquely determined by its midpoint (as long as it
is not the centre of the circle; this case can be neglected). Hence, a possible sample
space is 1 = {x ∈ R2 : |x| < r}, and it seems reasonable to interpret ‘choosing at
random’ by taking the uniform distribution U1 as the underlying probability measure.
The event ‘the chord is longer than the sides of the inscribed equilateral triangle’ is
then described by the set A1 = {x ∈ 1 : |x| < r/2}, cf. Figure 2.1. Consequently,

U1 (A1) =

π (r/2)2

πr2 =

1
4 .

2.2 Urn Models with Replacement

29

Second approach. The chord is uniquely determined by the angle under which
it is seen from the centre of the circle, and the direction of its perpendicular bisector;
the latter is irrelevant by the rotational symmetry of the problem. The angle falls into
2 = ]0, π]. The relevant event is A2 = ]2π /3, π]. If we again use the uniform
distribution, it follows that

U2 (A2) =

π/3
π =

1
3 .

Thirdapproach. Thechordisalsouniquelydeterminedbyitsdistanceanddirection
from the centre; the latter can again be ignored. Hence, we can also take the sample
space 3 = [0,r[. Then A3 = [0,r/2[ is the event we are interested in, and we obtain
U3 (A3) = 1/2.
In Bertrand’s times, this apparent paradox cast doubt on the legitimacy of non-
discrete probability spaces. Today it is clear that the three versions describe different
methods of choosing the chord ‘at random’, and it is all but surprising that the proba-
bility we are looking for depends on the choice of the method.

Some readers may consider this way of resolving the paradox as a cheap way out, because
they think that there must be a unique ‘natural’ interpretation of ‘choosing at random’. In fact
the latter is true, but only if we reformulate the problem by requiring that the object chosen ‘at
random’ is not a chord, but a straight line that intersects the circle. Such a random straight line
is best described by the third approach, since one can show that this is the only case in which the
probability that a random straight line hits a set A is invariant under rotations and translations
of A.

This example demonstrates that the choice of a suitable model can be non-trivial,
even in a simple case like this, which only involves uniform distributions. This is a
main problem in all applications.

2.2 Urn Models with Replacement
The so-called urn models form a simple class of stochastic models with ﬁnite sample
space. Their signiﬁcance comes from the observation that many random experiments
can be thought of as picking balls of different colours at random from a container,
which is traditionally called an ‘urn’. In this section we consider the case that the
balls are replaced after being drawn. The case without replacement follows in the next
section.

2.2.1 Ordered Samples
We begin with two examples.
(2.5) Example. Investigation of a ﬁsh pond. Consider a ﬁsh pond inhabited by several
species of ﬁsh, and let E be the set of species. Suppose the pond contains Na ﬁsh of

species a ∈ E, so the total population size is"a∈E Na = N. We repeat the following

30

2 Stochastic Standard Models

procedure n times. A ﬁsh is caught, examined for parasites, say, and then thrown
back into the pond. What is the probability that a random sample exhibits a speciﬁc
sequence of species?
(2.6) Example. A survey. A local radio station interviews passers-by on the high street
concerning a question of local interest, for instance the construction of a new football
stadium. Let E be the set of viewpoints expressed (possible location, rejection on
principle, …). The station interviews n people. What is the probability that a given
sequence of views is observed?

Such problems, where samples are picked randomly from a given pool, are often
formulated in an abstract way as urn models. An urn contains a certain number of
colouredbutotherwiseidenticalballs. Let E bethesetofcolours, where2 ≤ |E| < ∞.
A sample of size n is taken from the urn with replacement, meaning that n times a ball
is drawn at random and returned immediately. We are interested in the colour of each
ball we take out. Thus, the sample space is  = En, equipped with the σ-algebra
F = P(). Which probability measure P describes the situation adequately?
To ﬁnd out, we proceed as follows. We imagine that the balls are labelled with
the numbers 1, . . . , N; the labels of the balls with colour a ∈ E are collected in a
class Ca ⊂ {1, . . . , N}. Thus |Ca| = Na. If we could observe the labels, we would
describe our experiment by the sample space  = {1, . . . , N}n (with the σ-algebra
F = P()), and since all balls are identical (up to their colour), we would choose
our probability measure to be the uniform distribution ¯P = U. So, using the trick
of increasing the observation depth artiﬁcially by labelling the balls, we arrive at a
plausible stochastic model.
We now return to the true sample space  = En. As we have seen in Section 1.3,
this transition can be described by constructing a suitable random variable X :  → .
The colour of the ith draw is speciﬁed by the random variable

Xi :  → E,

¯ω = ( ¯ω1, . . . , ¯ωn) → a if

¯ωi ∈ Ca .

The sequence of colours in our sample is then given by the n-step random variable
X = (X1, . . . , Xn) :  → .

What is the distribution of X? For every ω = (ω1, . . . , ωn) ∈ En we have

{X = ω} = Cω1 × ··· × Cωn

and thus

¯P ◦ X−1({ω}) = ¯P(X = ω) = |Cω1| . . .|Cωn|

n.i=1
where ϱ(a) = |Ca|/N = Na/N is the proportion of balls of colour a.

||

=

ϱ(ωi ) ,

2.2 Urn Models with Replacement

31

Deﬁnition. For every density ϱ on E, the (discrete) density

ϱ⊗n(ω) =

ϱ(ωi )

n.i=1

on En is called the n-fold product density of ϱ, and the corresponding probability
measure P on En is the n-fold product measure of ϱ. (We will not introduce any extra
notation for P, but instead we will use the notation ϱ⊗n for P as well.)
In the special case when E = {0,1} and ϱ(1) = p ∈ [0,1], one obtains the product
density

ϱ⊗n(ω) = p"n

i=1 ωi (1 − p)"n

i=1(1−ωi )

on {0,1}n, and P is called the Bernoulli measure or the Bernoulli distribution for n
trials with ‘success probability’ p. (The name refers to Jakob Bernoulli, 1654–1705.)
2.2.2 Unordered Samples
In the urn model, one is usually not interested in the (temporal) order in which the
colours were selected, but only in how many balls of each colour were drawn. (In
particular, this applies to the situations of Examples (2.5) and (2.6).) This corresponds
to a lower observation depth, and leads to the sample space

/ =!⃗k = (ka)a∈E ∈ ZE
+, "a∈E

ka = n# ,

which consists of the integral grid points in the simplex spanned by the |E| vertices
(nδa,b)b∈E, a ∈ E; cf. Figure 2.3 on p.36. The transition to/ is described by the
random variable
S :  →/, ω = (ω1, . . . , ωn) →$Sa(ω)%a∈E ;
(2.7)
where Sa(ω) = "n
i=1 1{a}(ωi ) is the number of occurrences of colour a in sample
point ω ∈ En. S(ω) is called the histogram of ω. It can be visualised by plotting a
rectangle of width 1 and height Sa(ω) for every a ∈ E. Notice that the total area of all
rectangles is n.
Now, for P = ϱ⊗n and ⃗k = (ka)a∈E ∈/, we ﬁnd
⃗k2.a∈E
ϱ(ωi ) =1n
if "a∈E ka = n ,

n.i=1
P(S = ⃗k) = 0ω∈: S(ω)=⃗k
Here, we write
⃗k2 =3 n!45a∈E ka!
1n
(2.8)
for the multinomial coefﬁcient, which speciﬁes the cardinality of the set {S = ⃗k}; in
the case E = {0,1} and ⃗k = (n−k, k),$n
⃗k% coincides with the binomial coefﬁcient$n
k%.

otherwise,

ϱ(a)ka .

0

32

2 Stochastic Standard Models

ϱ(a)ka ,

with density

⃗k2.a∈E

Mn,ϱ({⃗k}) =1n

Deﬁnition. For every density ϱ on E, the probability measure Mn,ϱ on (/, P(/))
iscalledthe multinomial distributionfor n trialswithsuccessprobabilities ϱ(a), a ∈ E.
For |E| = 3, the multinomial distribution is illustrated in Figure 2.3 on p.36.
The case E = {0,1} is particularly simple. This is because/ can then be replaced
by the sample space {0, . . . , n} by identifying every k ∈ {0, . . . , n} with the pair
(n − k, k) ∈/. Setting p = ϱ(1) ∈ [0,1], we ﬁnd that the multinomial distribution
Mn,ϱ is reduced to the binomial distribution Bn,p on {0, . . . , n} with density

⃗k ∈/,

Bn,p({k}) =1n

k2pk (1 − p)n−k ,

k ∈ {0, . . . , n}.

The above reasoning is not restricted to the case of probability densities ϱ with
rational values, as it did in the urn example in Section 2.2.1. As a summary of this
section we thus obtain the following.
(2.9) Theorem. Multinomial distribution of the sampling histogram. Suppose E is a
ﬁnite set with |E| ≥ 2, ϱ a discrete density on E and P = ϱ⊗n the associated n-fold
product measure on  = En. The random variable S :  →/ deﬁned by (2.7) then
has the multinomial distribution P ◦ S−1 = Mn,ϱ.
If E = {0,1} and ϱ(1) = p ∈ [0,1], this means the following: Relative to the
Bernoulli distribution with parameter p, the random variable
n"i=1

has the binomial distribution Bn,p.
(2.10) Example. Children’s birthday party. At a birthday party 12 children come
together, where 3 are from village A, 4 from village B and 5 from village C. They play
a game of luck ﬁve times. The probability that one child from village A wins and two
children from village B and village C each is given by

S : {0,1}n → {0, . . . , n}, ω →

(‘number of successes’)

ωi

M5;

12 , 4
3

12 , 5
12

({(1,2,2)}) =

5!1!2!2

3

121 4

12221 5
1222

125
864 ≈ 0.14 .

=

(2.11) Example. The Maxwell–Boltzmann distribution. Let us return to the frame-
work of Example (2.2), where n indistinguishable particles must be allocated to N
cells. We assume that the cells belong to ﬁnitely many energy levels from a set E, in
that the particles are indistinguishable only due to the lack of experimental technology,
but ‘in reality’ can be labelled 1, . . . , n, we can assign to each particle its position by

such way that there are Na cells of level a ∈ E. Hence, N ="a∈E Na. If we suppose

2.2 Urn Models with Replacement

33

taking an ordered sample of size n – with replacement – from an urn containing N tick-
ets for the different cells; Na of these point to a cell with energy level a. The similarity
of particles resp. cells justiﬁes the assumption that the ‘microstates’ in the auxiliary
sample space  = {1, . . . , N}n are equally likely. As a matter of fact, however, we can
only observe the respective macrostate in/, which speciﬁes the number of particles
on each energy level a ∈ E. Now, Theorem (2.9) states that this macrostate has the
multinomial distribution Mn,ϱ with ϱ(a) = Na/N. This is a classical assumption in
statistical physics, which dates back to J.C. Maxwell (1831–1879) and L. Boltzmann
(1844–1906), but is not applicable if quantum effects have to be taken into account,
see Examples (2.2) and (2.15).

As the last example shows, sampling with replacement from an urn containing
coloured but otherwise identical balls is equivalent to distributing objects onto different
positions which can, in part, be distinguished by certain characteristics and are open
for multiple allocations.

The signiﬁcance of the binomial distribution as the distribution of the number of successes in
a Bernoulli experiment can be illustrated physically, in the case p = 1/2, by the Galton board,
see Figure 2.2. A ball is dropped at the top of the board and passes n rows of pins, at which
it is deﬂected either to the right or to the left, each with probability 1/2. The probability that
it takes the right option k times is given by Bn,1/2({k}), 0 ≤ k ≤ n. In this case it ends up in
compartment k. If the compartments are big enough to accommodate a large number of balls,
the relative frequency of the balls in compartment k is close to Bn,1/2({k}), by the law of large
numbers (Theorem (5.6)).

1

1

1

1

2

1

1

3

3

1

1

4

6

4

1

1

5

10

10

5

1

1

6

15

20

15

6

1

1

7

21

35

35

21

7

1

k = 0

1

2

3

4

5

6

7

Figure 2.2. The Galton board for n = 7. The arrows mark a possible path for the ball.
The numbers indicate the total number of paths leading to the respective position. Note
that they form Pascal’s triangle for the binomial coefﬁcients. In the compartments at the
bottom, the bar chart for B7,1/2 is indicated in grey.

2 Stochastic Standard Models

34
2.3 Urn Models without Replacement
2.3.1 Labelled Balls
Suppose an urn contains N labelled, but otherwise indistinguishable balls. We remove
n ballssuccessivelyfromtheurn, without replacingthemaftereachdraw. Ifweobserve
the order in which their labels appear, the appropriate sample space is

̸= =6 ¯ω ∈ {1, . . . , N}n : ¯ωi ̸= ¯ωj for i ̸= j7 .

By the similarity of the balls, it is natural to equip ̸= with the uniform distribution
¯P̸= = U̸=
In most applications, however, the order in the sample is not relevant, and we only
observe the set of all labels drawn; think for instance of the lottery. In this case,

.

8 =6 ˜ω ⊂ {1, . . . , N} : | ˜ω| = n7

which transforms an n-tuple into the corresponding (unordered) set. In accordance

Y : ̸= →8, Y ( ¯ω1, . . . , ¯ωn) = { ¯ω1, . . . , ¯ωn} ,

is the space of outcomes. Does it make sense to equip8 with the uniform distribution
as well? The transition from ̸= to8 is captured by the random variable
with intuition, its distribution ¯P̸= ◦ Y −1 is indeed the uniform distribution on8, since
for all ω ∈ 8. In other words, when a sample is taken without replacement and its

order is disregarded, it does not matter whether the balls are picked successively, or all
at the same time with a single grip.

¯P̸=(Y = ω) = |{Y = ω}|
|̸=| =

n% =
$N

1

|8|

n(n − 1) . . .1

N (N − 1) . . . (N − n + 1) =

1

2.3.2 Coloured Balls
Now we return to the assumption that the balls have different colours taken from a set
E, and we only observe the colour of the balls but not their labels. We also ignore
the order in which the colours appear. As in Section 2.2.2, this leads us to the sample
space

/ =!⃗k = (ka)a∈E ∈ ZE

+ : "a∈E

ka = n# .

necessary. But this does not matter because we can simply assign the probability 0
appropriately?

(Here we omit the condition ka ≤ Na, so that the sample space / is larger than
to the impossible outcomes.) Which probability measure on/ describes the situation

2.3 Urn Models without Replacement

35

random variable

,

As we have seen in the previous Section 2.3.1, we can imagine that the balls are

.a∈E{ ˜ωa ⊂ Fa : | ˜ωa| = ka} ,

T :8 →/, T ( ˜ω) := (| ˜ω ∩ Ca| )a∈E ,

drawn all together with a single grip. The transition from8 to/ is described by the
where Ca ⊂ {1, . . . , N} again denotes the family of (labels of) balls of colour a. For
every ⃗k ∈/, the set {T = ⃗k} contains as many elements as the product set
since the mapping ˜ω → ( ˜ω ∩ Fa)a∈E is a bijection between these sets. Consequently,
we deduce that P(T = ⃗k) =+5a∈E$Naka%9:$N
n%.
Deﬁnition. Let E be a ﬁnite set (with at least two elements), ⃗N = (Na)a∈E ∈ ZE
+
N ="a∈E Na, and n ≥ 1. Then the probability measure Hn, ⃗N on (/, P(/)) with
density
is called the (general) hypergeometric distribution with parameters n and ⃗N.
In the special case E = {0,1},/ can be identiﬁed with {0, . . . , n}, as shown in
Section 2.2.2. The (classical) hypergeometric distribution then takes the form

Hn, ⃗N ({⃗k}) = 5a∈E$Naka%
$N
n%

k ∈ {0, . . . , n} .

Hn;N1,N0 ({k}) = $N1k%$ N0n−k%
$N1+N0n
% ,
So, if an urn contains Na balls of colour a ∈ E, and if n balls are randomly selected
(either successively without replacement, or all simultaneously), then the histogram of
colours has the hypergeometric distribution Hn, ⃗N.
(2.12) Example. Lottery. In the ‘6 out of 49’ lottery, the probability for exactly four
correct numbers is H6;6,43({4}) =$6
4%$43
2%/$49

(2.13)Example. Representationofinterestgroups. Acommitteeof12personsconsists
of 3 representatives of group A, 4 of group B and 5 of group C. By drawing lots, a
subcommittee of 5 people is chosen. The probability that this subcommittee consists
of exactly one member of group A and two members of groups B and C each is

6% ≈ 9.686 × 10−4.

,

⃗k ∈/,

1%$4
2%$5
2%
H5,(3,4,5)${(1,2,2)}% = $3
5% =
$12

5
22 ≈ 0.23 .

This probability is (obviously) not the same as in Example (2.10), where the same
sample was taken from the same urn, but with replacement. Figure 2.3 gives a graphical

36

2 Stochastic Standard Models

kC

kA

kB

Figure2.3. Comparisonofthemultinomialandthehypergeometricdistributionfortheurn
in Examples (2.10) and (2.13). For every ⃗k ∈/, the area of the left (darker) semicircle
with centre ⃗k is proportional to M5;3/12,4/12,5/12({⃗k}), whereas the right semicircle
corresponds to H5,(3,4,5)({⃗k}). Sampling without replacement gives a disadvantage to
the ‘vertex regions’ of/.

comparison of both distributions. However, if the number N of balls is large enough,
it should hardly make any difference whether the balls are being replaced, or not. This
intuition is conﬁrmed by the following result.

(2.14) Theorem. Multinomial approximation of hypergeometric distributions. Let
E be ﬁnite with |E| ≥ 2, ϱ a discrete density on E, and n ≥ 1. Then, in the limit as
N → ∞, Na → ∞, and Na/N → ϱ(a) for all a ∈ E, Hn, ⃗N converges (pointwise)
to Mn,ϱ.
Proof. Fix any ⃗k ∈/. Obviously,

Na(Na − 1) . . . (Na − ka + 1)
Nkaa
Na% . . .$1 −
Na%$1 −
1$1 −
Hereweusethenotation‘a(ℓ) ∼ b(ℓ)as ℓ → ∞’forasymptoticequivalence, meaning
that a(ℓ)/b(ℓ) → 1 as ℓ → ∞. Hence, it follows that

ka2 =
1Na

Nkaa
ka!
Nkaa
ka!

=

ka − 1
Na

% ∼Na→∞

Nkaa
ka!

.

1

2

2.4 The Poisson Distribution

37

Hn, ⃗N ({⃗k}) =;.a∈E1Na
ka2<=1N
N 2ka
⃗k2.a∈E1 Na
=1n

n2 ∼ ;.a∈E
→ Mn,ϱ({⃗k}) ,

Nkaa

ka!<= Nn
n!

as claimed. ✸
(2.15) Example. The Fermi–Dirac distribution (1926). For a third time, we consider
the particle situation of Examples (2.2) and (2.11), where n indistinguishable particles
are to be distributed across N cells, which belong to certain levels of energy. Assume
that there are Na cells of level a ∈ E. We now impose ‘Pauli’s exclusion principle’,
which says that each cell can contain at most one particle; so, in particular, N ≥ n
is required. This is a sensible assumption for the so-called fermions (particles with
half-integer spin), which include the electrons, protons and neutrons. Then the cell
arrangement of all particles corresponds to a sample taken without replacement from
an urn containing N distinct seat reservations, of which Na refer to seats of level a. In
this case the above reasoning shows that the macrostate of the system, which for each a
gives the number of particles of energy level a, is Hn, ⃗N-distributed with ⃗N = (Na)a∈E.
Moreover, Theorem (2.14) shows that Pauli’s exclusion principle becomes irrelevant
when each energy level offers much more cells than necessary to accommodate all
particles.

A

B

C

Figure 2.4. Equivalence of drawing without replacement and distributing objects without
multiple allocations. The situation corresponds to the urn in Example (2.13). The places
that have been taken are coloured in black (and marked at the beginning of the row, since
the places in each row are equivalent).

In particular, the last example shows that sampling without replacement from balls
that differ in colour but are otherwise indistinguishable corresponds to distributing ob-
jects across boxes that carry different labels but are otherwise treated equally, provided
multiple allocations are not allowed. This correspondence is illustrated in Figure 2.4.

2.4 The Poisson Distribution
Let us begin with an example from everyday life.
(2.16) Example. Insurance claims. How many claims does an insurance company
receive in a ﬁxed time interval ]0, t], t > 0? Obviously, the number of claims is
random, and the sample space is  = Z+. But which P describes the situation? In

38
2 Stochastic Standard Models
order to ﬁnd out, we develop a heuristic argument. We partition the interval ]0, t] into
n subintervals of length t/n. If n is large (and so the subintervals small), we can assume
that in each subinterval the company receives at most one claim. The probability for
suchaclaimshouldbeproportionaltothelengthoftheinterval; soweassumeitisequal
to αt/n for some proportionality constant α > 0. Moreover, it is plausible that the
appearance of a claim in one subinterval does not depend on whether a claim appears
in another subinterval. So we can pretend that the claims in the n subintervals are
sampled by drawing n times with replacement from an urn that contains a proportion
αt/n of ‘liability balls’. Hence, if n is large, we can conclude from Theorem (2.9)
that the probability of k claims during the time interval ]0, t] is approximately equal
to Bn,αt/n({k}). This leads us to the tentative assumption that
k ∈ Z+ ,

Bn,αt/n({k}) ,

P({k}) := limn→∞

for the probability measure P we are interested in. And indeed, this limit does exist.
(2.17) Theorem. Poisson approximation of binomial distributions. Let λ > 0 and
(pn)n≥1 a sequence in [0,1] with npn → λ. Then for every k ≥ 0 the limit

limn→∞

Bn,pn ({k}) = e−λ λk
k!

nk
k!
λk
k!

pk
n (1 − pn)n−k ∼
λk
(1 −
k!

npn
n )n →

λk
k!
e−λ .

exists.
Proof. Exactly as in the proof of Theorem (2.14), we obtain for each k ∈ Z+ in the
limit n → ∞
1n
k2 pk

(1 − pn)n

n (1 − pn)n−k ∼
=

In the second step we used that (1 − pn)k → 1; the last convergence follows from the
well-known approximation formula for the exponential function. ✸
Figure 2.5 illustrates the Poisson convergence; in Theorem (5.32) we will see that
the deviation from the limit is of order 1/n. The series expansion of the exponential
function shows that the limit in Theorem (2.17) sums up to 1, and thus deﬁnes a discrete
density on Z+. The corresponding probability measure is one of the fundamental
distributions in stochastics.
Deﬁnition. For λ > 0, the probability measure Pλ on (Z+, P(Z+)) deﬁned by
Pλ({k}) = e−λλk/k! is called the Poisson distribution with parameter λ (in honour of
Siméon-Denis Poisson, 1781–1840).
As a result of this subsection, we conclude that the family of Poisson distributions
Pλ on Z+ provides natural models for the number of random time points in a ﬁxed time

2.5 Waiting Time Distributions

39

0

1

2

3

4

5

6

7

k

Figure 2.5. The Poisson approximation for λ = 2. For k ∈ Z+, the bars show Bn,2/n({k})
for n = 4,8,16,32 (from light grey to dark grey), and the limit P2({k}) (black).

interval. Typical applications, apart from the insurance claims, include the number of
phone calls arriving at a telephone switchboard, the number of emails sent via a mail
server, the number of particles emitted by a radioactive substance, the number of cars
passing a check-point, and so on. In Section 3.5 we will discuss this situation in more
detail.

2.5 Waiting Time Distributions
2.5.1 The Negative Binomial Distributions
Consider a Bernoulli experiment as discussed in Section 2.2.1. An urn contains red
and white balls, where the proportion of red balls is 0 < p < 1. The balls are drawn
with replacement. What is the distribution of the waiting time until the rth success,
i.e., until we draw the rth red ball? Here, r ∈ N is a ﬁxed number. Since we must draw
at least r times, we consider the remaining waiting time after r draws, or equivalently,
the number of failures before therth success; then the sample space is  = Z+. Which
P describes the situation?

On the inﬁnite product space {0,1}N we could deﬁne the random variables

k"i=1

ωi = r# − r

Tr (ω) = min!k :

and obtain P as the distribution of Tr. However, the existence of an inﬁnite Bernoulli
measure will only be shown later in Example (3.29). We therefore proceed in a more
heuristic way here. For every k, P({k}) is to be deﬁned as the probability of the rth
success on the (r+k)th draw, in other words the probability of a success at time r+k
% possible
and exactly k failures at some earlier times. Since there are exactly$r+k−1

k

40
2 Stochastic Standard Models
choices for these k failure times, the Bernoulli measure on {0,1}r+k assigns to this
event the probability

k

k

k!

Here,

(2.18)

k 2 pr (p − 1)k .

P({k}) :=1r + k − 1

2 pr (1 − p)k =1−r
(−r )(−r − 1) . . . (−r − k + 1)
is the general binomial coefﬁcient, and we have used the identity

k 2 =
1−r
2 = (r + k − 1) . . . (r + 1)r
k!1r + k − 1
= (−1)k (−r )(−r − 1) . . . (−r − k + 1) .
Theexpressionfor P thusobtaineddoesdeﬁneaprobabilitymeasureon Z+, evenwhen
r is an arbitrary positive real number. Indeed, for r > 0 it is clear that$−r
k%(−1)k ≥ 0
k% pr (p−1)k =
for all k ∈ Z+, and the general binomial theorem implies that"k≥0$−r
pr (1 + p − 1)−r = 1.
Deﬁnition. For r >0 and 0 < p < 1, the probability measure Br,p on (Z+, P(Z+))
with density

Br,p({k}) =1−r

k 2 pr (p − 1)k ,

k ∈ Z+,

is called the negative binomial distribution or the Pascal distribution with parameters
r and p (after Blaise Pascal, 1623–1662).
In particular, Gp({k}) = B1,p({k}) =
p(1 − p)k is called the geometric distribution with parameter p.
To summarise, we have seen that Br,p is the distribution of the waiting time (afterr)
fortherthsuccessinaBernoulliexperimentwithparameter p. Inparticular,thewaiting
time for the ﬁrst success has the geometric distribution Gp. (In the terminology of some
authors, the geometric distribution is not Gp, but the distribution on N = {1,2, . . .}
that is obtained by shifting Gp one unit to the right.) Figure 2.6 shows the shape of
Br,p for some values of r.
2.5.2 The Gamma Distributions
We now turn to continuous time. As in Section 2.4, we consider random time points in
the interval ]0,∞[; we may again think of incoming claims in an insurance company,
or of phone calls arriving at a telephone switchboard. The heuristic reasoning in
Example (2.16) led to the conclusion that, for every t > 0, the number of points in
]0, t] is Poisson distributed with parameter αt, where α > 0 represents the average
number of points per time. In analogy with the previous subsection, we look for a

2.5 Waiting Time Distributions

41

0

10

20

k

Figure 2.6. Bar charts of the negative binomial distributions Br,p for p = 0.2 and
r = 1, 2, 3, 4 (from light to darker shades of grey), as well as the densities γ1,r of the
gamma distributions (on an adjusted scale). The connection between negative binomial
and gamma distributions is discussed in Problem 2.13.

model of the rth random time point. (In Example (2.16) this would correspond to the
instant at which the rth claim comes in.) Obviously, (, F ) = (]0,∞[, B[0,∞[) is
an appropriate event space. Which probability measure P describes the distribution
of the rth random point? For this P, the number P(]0, t]) is the probability that the
rth claim arrives no later than t, in other words the probability of at least r claims in
]0, t]. In view of our Poisson assumption on the number of claims, we are thus led to
the formula

(2.19)

P(]0, t]) = 1 − Pαt ({0, . . . ,r − 1})
k! = - t

= 1 − e−αt

(αt)k

r−10k=0

αr
(r − 1)!

xr−1e−αx dx ;

0

the last equality is obtained by differentiating with respect to t. Hence, Remark (1.31)
tells us that the P we are looking for is exactly the probability measure on ]0,∞[ with
the Lebesgue density γα,r (x) = αrxr−1 e−αx /(r − 1)!.
To check that γα,r is indeed a probability density, one can use Euler’s gamma
function

(r ) =- ∞

0

yr−1e−y dy ,

r > 0.

Clearly, (1) = 1, and by partial integration one obtains the well-known recursive
formula (r + 1) = r (r ).
In particular, for r ∈ N one ﬁnds (r ) = (r − 1)!.
By the substitution αx = y, it follows that> ∞0 γα,r (x) dx = 1. An analogous density
function can be obtained for arbitrary real r > 0.

42
2 Stochastic Standard Models
Deﬁnition. For every α, r > 0, the probability measure Γα,r on (]0,∞[, B]0,∞[) with
Lebesgue density

(2.20)

γα,r (x) =

αr
(r )

xr−1e−αx ,

x ≥ 0,

is called the gamma distribution with scale parameter α and shape parameter r. In
particular, the probability measure Eα = Γα,1 with the density γα,1(x) = αe−αx is
called the exponential distribution with parameter α.
Summarising, we see that for r ∈ N the distribution Γα,r describes the distribution
of the rth point in a Poisson model of random points on the positive axis. In particular,
the ﬁrst point is exponentially distributed with parameter α. We will come back to this
in Section 3.5. The gamma densities for some selected parameter values are plotted in
Figures 2.6 and 9.2 (on p.246).
2.5.3 The Beta Distributions
We will now take a different approach to the problem of choosing random time points
and determining the waiting time for the rth point. Let us suppose that the number
of points in a given time interval is not random, but ﬁxed. Think for example of a
supermarket which receives deliveries from n suppliers. At what time does the rth
delivery arrive?
We choose the unit of time in such a way that the n deliveries arrive in the open
unit interval ]0,1[. If we label the suppliers with the numbers 1, . . . , n, we obtain the
sample space  = ]0,1[n, which is equipped with the Borel σ-algebra B n
 as usual.
For every 1 ≤ i ≤ n and ω = (ω1, . . . , ωn) ∈ , we write Ti (ω) := ωi for the
instant at which the ith supplier arrives. Assuming that there is no prior information
about the delivery times, it is natural to choose the uniform distribution P = U as the
underlying probability measure.
How long does it typically take until the supermarket has received the rth delivery?
To answer this, we must ﬁrst order the n arrival times. This is possible because no two
deliveries arrive at the same time, at least with probability 1. More precisely,

P*?i̸=j{Ti = Tj}, = 0 ,

since this event is a ﬁnite union of hyperplanes in  and has thus n-dimensional volume
0. Hence, the following quantities are well-deﬁned with probability 1.
Deﬁnition. The order statistics T1:n, . . . , Tn:n of the random variables T1, . . . , Tn are
deﬁned by the properties

T1:n < T2:n < ··· < Tn:n ,

{T1:n, . . . , Tn:n} = {T1, . . . , Tn} .

In other words, Tr:n is the rth-smallest of the times T1, . . . , Tn.

2.5 Waiting Time Distributions

43
Let us now determine the distribution of Tr:n for ﬁxed r, n ∈ N. Distinguishing
the n! possible orderings of the values of T1, . . . , Tn, we ﬁnd that all give the same
contributionbecausetheorderofintegrationcanbeinterchangedarbitrarilybyFubini’s
theorem (see e.g. [52]). This means that for every 0 < c ≤ 1

where

and

Altogether, we ﬁnd

s

dtn 1{t1<t2<···<tn} 1]0,c](tr )

0

0

0

0

dt1 . . .- 1
dtr a(r − 1, tr ) a(n − r,1 − tr ) ,

P(Tr:n ≤ c) = n!- 1
= n!- c
dt1 . . .- s
dtr+1 . . .- 1
(r − 1)! (n − r )!- c
n!
sa−1(1 − s)b−1 ds , a, b > 0,

dtr−1 1{t1<t2<···<tr−1<s} =
dtn 1{s<tr+1<···<tn} =

a(r − 1, s) =- s
a(n − r,1 − s) =- 1
P(Tr:n ≤ c) =

0

s

ds sr−1 (1 − s)n−r .

0

sr−1
(r − 1)!
(1 − s)n−r
(n − r )!

.

0

B(a, b) =- 1

Setting c = 1, it follows in particular that (r −1)! (n−r )!/n! = B(r, n−r +1), where
(2.21)
is Euler’s beta function. By Remark (1.31) we conclude that Tr:n has density
βr,n−r+1(s) = B(r, n − r + 1)−1sr−1 (1 − s)n−r on ]0,1[. Density functions of this
kind are also interesting for non-integer r and n.
Deﬁnition. For a, b > 0, the probability measure βa,b on ]0,1[ with density
(2.22)
is called the beta distribution with parameters a, b.
We thus have seen that, for r, n ∈ N, βr,n−r+1 is the distribution of the rth-
smallest among n randomly chosen points in the unit interval. In particular, β1,n(s) =
n(1−s)n−1 is the distribution density of the ﬁrst point, and β1,1 = U]0,1[. Figure 2.7
shows the densities of beta distributions for various parameters; the reader should ﬁg-
ure out which parameter values correspond to which graph. The distribution β1/2,1/2
is called the arcsine distribution, cf. Problem 1.16.
For later purposes, we conclude this subsection with a characteristic property of the
beta function. For a, b > 0 one can write

βa,b(s) = B(a, b)−1 sa−1(1 − s)b−1 , 0 < s < 1,

a$B(a, b) − B(a + 1, b)% =- 1
=- 1

0

0

asa−1 (1 − s)b ds
sa b(1 − s)b−1 ds = b B(a + 1, b) ,

44

2 Stochastic Standard Models

5

4

3

2

1

0.2

0.4

0.6

0.8

1

Figure 2.7. βa,b for (a, b) = (1/2,1/2), (3/2,1/2), (3/2,7/4), (2,4), (20,5).

where the second equality follows by partial integration. This implies the recursion
formula
(2.23)

So one might suspect that the beta function is closely related to the gamma function.
This is indeed the case, see (9.8) below. The recursion can also be used to deduce the
expression already derived in the line before (2.21) for the beta function with integer
parameters.

B(a + 1, b) =

a
a + b B(a, b) .

2.6 The Normal Distributions
Is there any kind of uniform distribution on an inﬁnite-dimensional ball with inﬁnite
radius? To ﬁnd out, we consider the asymptotics of uniform distributions on large balls
in high dimensions. Speciﬁcally, let v > 0 and
N = {x ∈ RN : |x|

≤ vN}
be the N-dimensional ball with centre 0 and radius √vN. Furthermore, let PN = UN
be the (continuous) uniform distribution on (N , B N
N ) and X1 : N → R, x → x1,
the projection onto the ﬁrst coordinate. We are interested in the asymptotic distribution
of X1 under PN in the limit as N → ∞.
(2.24) Theorem. Normal distribution as a projection of an ‘inﬁnite-dimensional uni-
form distribution’; H. Poincaré 1912, E. Borel 1914. For all a < b, we have

2

lim
N→∞

PN (a ≤ X1 ≤ b) =- b

a

1

√2π v

e−x2/2v dx .

PN (a ≤ X1 ≤ b) = λN (N )−1- . . .- 1

x2

N"i=1
6a ≤ x1 ≤ b,
i ≤ vN7
λN−1*BN−1$@vN − x2
1%, dx1
1%(N−1)/2cN−1 dx1 .
a $vN − x2

= λN (N )−1- b
= λN (N )−1- b

a

dx1 . . . dxN

2.6 The Normal Distributions

45

In statistical mechanics, an extension of this theorem justiﬁes Maxwell’s velocity distribution
2 is
of the particles in a gas. If x ∈ RN is the vector of the velocities of all particles, then |x|
proportional to the kinetic energy, PN corresponds to the Liouville measure in velocity space,
and X1(x) = x1 is the ﬁrst velocity coordinate of the ﬁrst particle. (The theorem still holds if
the kinetic energy per particle, instead of being bounded by v, is kept constant equal to v, which
means that PN is replaced by the uniform distribution on the surface of the ball.)
Proof. Let N be so large that N v > max(a2, b2). Using Deﬁnition (1.17) of λN, and
computing multiple integrals successively according to Fubini’s theorem (see [52]),
we can write

Here, BN−1(r ) stands for the centred ball in RN−1 with radius r, and cN−1 =
λN−1(BN−1(1))isthevolumeofthe (N−1)-dimensionalunitball; thesecondequation
is obtained by integrating over the variables x2, . . . , xN. Similarly, we get

λN (N ) =- √vN

−√vN$vN − x2

1%(N−1)/2cN−1 dx1 .

fN (x) dx ,

Thus by cancelling the constant cN−1(vN )(N−1)/2 we obtain
fN (x) dx=- √vN
−√vN

PN (a ≤ X1 ≤ b) =- b
a
where fN (x) = (1 − x2/vN )(N−1)/2.
We now perform the limit N → ∞, treating the integrals in the numerator and
the denominator separately. By the well-known approximation formula for the ex-
ponential function, fN (x) converges to e−x2/2v, and this convergence is uniform on
every compact interval, in particular on [a, b]. The numerator therefore converges to
> b
a e−x2/2v dx. To deal with the denominator, we take advantage of the estimate
For any c > 0 and N ≥ max(2, c2/v), this gives us the sandwich inequality

for all N ≥ 2.

≤ e−x2/4v

fN (x) ≤$e−x2/vN%(N−1)/2
fN (x) dx ≤- c

fN (x) dx ≤- √vN
−√vN

−c

fN (x) dx +-{|x|>c}

e−x2/4v dx .

- c

−c

46
2 Stochastic Standard Models
Now, if we let ﬁrst N and then c tend to ∞, the terms on the left and the right, and
therefore also the integral squeezed in between, converge towards> ∞
e−x2/2v dx.
The theorem thus follows from the next result.
(2.25) Lemma. Gaussian integral. > ∞

Proof. Treatingthesquareoftheintegralasatwo-dimensionalintegralandintroducing
polar coordinates one ﬁnds

e−x2/2v dx = √2π v.

−∞

−∞

dy e−(x2+y2)/2v

;- ∞

−∞

e−x2/2v dx<2

=- ∞
=- 2π

−∞

dx- ∞
dϕ- ∞

−∞

0

0

∞

dr re−r2/2v = −2π v e−r2/2vAAA

r=0 = 2π v . ✸
Theorem (2.24) can be rephrased as follows. Projecting the uniform distribution on
a large ball in high dimensions onto a single coordinate, one obtains in the limit a dis-
tribution density of the form e−x2/2v/√2π v. (The projection onto several coordinates
is the subject of Problem 2.16.) These densities play a fundamental role in stochastics.
The reason is that they also appear as asymptotic densities in another limit theorem,
the so-called central limit theorem, which will be discussed in Sections 5.2 and 5.3.
This will elucidate their signiﬁcance as a universal approximation, and gives rise to
their prominent role in statistics.
Deﬁnition. Let m ∈ R and v > 0. The probability measure Nm,v on (R, B ) with
density

φm,v(x) =

1

√2π v

e−(x−m)2/2v ,

x ∈ R,

is called the normal distribution or Gauss distribution with mean m and variance v.
(The names of the parameters m and v will be justiﬁed in Chapter 4.) N0,1 is called the
standard normal distribution, and φm,v is often called the Gaussian bell curve. Until
31st December 2001, it was pictured on the 10DM note, see Figure 2.8.

Problems
2.1. At a tombola, the winning lot shall be drawn by a ‘good luck fairy’ born on a Sunday.
How many ladies must be present so that, with a probability of 99%, at least one of them is a
Sunday child? Set up a suitable model.
2.2. Consider a system of n indistinguishable particles, each of which can be located in one of
N different cells. Na of the cells belong to an energy level a ∈ E, E a ﬁnite set. Under the
assumption of the Bose–Einstein distribution, determine the probability that, for each a ∈ E,
ka particles occupy a cell of energy a.

Problems

47

Figure 2.8. Portrait of Carl Friedrich Gauss (1777–1855) and the bell curve on the 10DM
note, before the euro was introduced.

2.3. Recall the situation of Bertrand’s paradox, and let X be the distance of the random chord
to the centre of the circle. Find the distribution density of X if
(a)
(b)

the midpoint of the chord is uniformly distributed on the unit disk,
the angle under which the cord is seen from the centre of the circle is uniformly distributed
on ]0, π].

2.4. Buffon’s needle problem (formulated by G.-L.L. Comte de Buffon in 1733 and analysed
in 1777). Think of (inﬁnitely many) parallel straight lines at distance a, embedded in a plane.
A needle of length l < a is randomly placed onto the plane. What is the probability that the
needle hits one of the straight lines? Set up an appropriate model. Hint: Describe the position
of the needle by a suitable angle and the distance of its midpoint to the closest straight line.
2.5. A light source is placed at a distance a > 0 from a straight line. It radiates uniformly
in all directions that eventually hit the line. Denote by X the point where a light ray hits the
straight line. Show that X has the distribution density ca (x) = a/(π(a2
+ x2)) on R. (The
corresponding distribution is called the Cauchy distribution with parameter a.)
2.6.
In the surroundings of each of 10 nuclear power stations, 100 people (chosen ‘with re-
placement’) are examined for a certain disease, which on average can be found in 1% of the
nation’s total population. The agreement is that a power station is considered suspicious if at
least 3 out of the 100 people tested show the symptoms of the disease.
(a) What is the probability that at least one power station is identiﬁed as suspicious, even
though the probability of having the disease in the neighbourhood of the power plants
does not deviate from the national average?

(b) What is the probability that none of them will be detected as being suspicious, even though

the probability of having the disease is 2% near the power plants?

48

2 Stochastic Standard Models

2.7. Simple symmetric random walk.
In the evening of an election day, the votes for two
competing candidates A and B are being counted. Both candidates are equally popular, i.e., on
each ballot A or B are chosen with equal probability 1/2; in total 2N ballots have been cast. Set
Xi = 1 or −1 depending on whether the ith ballot is for A or B. Then the sum Sj ="j
i=1 Xi
indicates by how much A is leading before B after j ballots have been counted (or by how
much A is behind B); the sequence (Sj )j≥1 is called the simple symmetric random walk. Let
1 ≤ n ≤ N and set un := 2−2n$2n
n%. Specify the probability model and show the following:
(a) The event Gn = {S2n = 0, S2k ̸= 0 for 1 ≤ k < n} (‘the ﬁrst tie appears when 2n ballots

have been counted’) satisﬁes

P(Gn) = 2−2n+1B$2n−2

n−1% −$2n−2

n %C = un−1 − un .

Hint: Each realisation of the sequence (Sj )j≤2n can be visualised by its path, a bro-
ken line through the points (j, Sj ). Find a bijection between the paths from (1,1) to
(2n−1,1) that hit the horizontal axis, and all paths from (1,−1) to (2n−1,1).
(b) The event G>n = {S2k ̸= 0 for 1 ≤ k ≤ n} (‘no tie during the count of the ﬁrst 2n
ballots’) has the probability P(G>n) = un.
2.8. The interval [0,2] is split in two parts by picking a point at random in [0,1] according to
the uniform distribution. Let X = l1/l2 be the ratio of the length of the shorter part l1 to the
length l2 of the longer one. Find the distribution density of X.
2.9. The genome of the fruit ﬂy Drosophila melanogaster is divided into approximately m =
7000 sections(whichcanbe identiﬁedby the colouringof the giant polytene chromosomesfound
in the salivary glands). As a simpliﬁcation, suppose that each section contains the same number
of M = 23000 base pairs. Hence, the genome contains N = mM base pairs. Using high energy
radiation, n = 1000 (randomly distributed) base pairs are destroyed. Find a stochastic model
for the number of destroyed base pairs in all genome sections. Determine the distribution of the
number Zi of destroyed base pairs in section i (1 ≤ i ≤ m) and show that Zi is approximately
Poisson distributed.
2.10. Projecting the multinomial distribution. Let E be a ﬁnite set, ϱ a discrete density on
E, n ∈ N, and X = (Xa )a∈E a random variable with values in/ =6⃗k = (ka )a∈E ∈ ZE
+ :
"a∈E ka = n7 and multinomial distribution Mn,ϱ. Show that, for every a ∈ E, Xa has the

binomial distribution Bn,ϱ(a).
2.11. Fixed points of a random permutation. Before a theatre performance, n people leave
their coats in the cloak room. After the performance, due to a power cut, the coats are returned
in the dark in random order. Let X be the random number of people who get their own coat
back. Find the distribution of X, i.e., P(X = k) for every k ≥ 0. What happens in the limit as
n → ∞? (The case k = 0 corresponds to the rencontre problem of Problem 1.12.) Hint: Use
Problem 1.6 again.
2.12. Banach’s matchbox problem. A famous mathematician always carried one matchbox in
each of the two pockets of his coat. With equal probability, he used the matchbox in the left or
in the right pocket. On ﬁnding an empty box, he replaced both boxes by new ones. Find the
distribution of the remaining matches after one cycle (i.e., after ﬁnding an empty box), if each
new box contains N matches.

Problems

49
2.13. Gamma and negative binomial distributions. Let r ∈ N, α, t > 0, (pn)n≥1 a sequence
in ]0,1[ with npn → α, and (tn)n≥1 a sequence in Z+ with tn/n → t. Show that

Γα,r (]0, t]) = limn→∞

Br,pn ({0, . . . , tn}) ,

and interpret this result in terms of waiting times. Hint: First show that Br,p({0,1, . . . , m}) =
Br+m,p({r,r + 1, . . . ,r + m}).
2.14. Gamma and beta distributions. InthesituationofSection2.5.3, let (sn)n≥1 beasequence
in ]0,∞[ with n/sn → α > 0. Show that for all r ∈ N and t > 0,
P(snTr:n ≤ t) .

Γα,r (]0, t]) = limn→∞

Can you rephrase this result in terms of random points on the positive time axis?
2.15. Afﬁne transformations of normal distributions. Let X be a real random variable with
normal distribution Nm,v, and a, b ∈ R, a ̸= 0. Show that the random variable aX + b has the
distribution Nam+b,a2v.
2.16. Extending the Poincaré–Borel theorem. Prove the following stronger version of Theo-
rem (2.24). If Xi : N → R denotes the projection onto the ith coordinate, then
N0,v$[ai , bi]%

PN$Xi ∈ [ai , bi] for 1 ≤ i ≤ k% =

for all k ∈ N and all ai , bi ∈ R with ai < bi for 1 ≤ i ≤ k. That is, asymptotically, the
projections are independent (as to be deﬁned in Section 3.3) and normally distributed.

lim
N→∞

k.i=1

3 Conditional Probabilities and Independence

The interdependence of events, or of subexperiments, is a central theme of stochastics.
It can be expressed by means of the fundamental concept of conditional probability.
After an introductory discussion of this notion, we will see how it can be used to
construct multi-stage probability models that describe a sequence of subexperiments
with a given dependence structure. The simplest case of dependence is independence,
which will receive particular attention. In particular, we will consider a concrete model
with ‘quite a lot of independence’, the Poisson process, as well as several algorithms
for the simulation of independent random variables with given distributions. Finally,
we will investigate the effect of independence on the long-term behaviour of a random
experiment that is repeated inﬁnitely often.
3.1 Conditional Probabilities
Let us start with an example.
(3.1) Example. Sampling without replacement. From an urn containing r red and w
white balls, two balls are drawn one after the other without replacement. We imagine
that the balls are labelled and so choose the model  = {(k,l) : 1≤ k,l ≤r+w, k ̸=l}
and P = U, the uniform distribution. Here, the labels 1, . . . ,r stand for red and
r+1, . . . ,r+w for white balls. We consider the events

A = {ﬁrst ball is red} = {(k,l) ∈  : k ≤ r} ,
B = {second ball is red} = {(k,l) ∈  : l ≤ r} .

Before the start of the experiment, one expects B to occur with probability

P(B) = |B|
|| =

r (r + w − 1)

(r + w)(r + w − 1) =

r
r + w

.

If A occurs in the ﬁrst draw, do we still expect B to occur with probability r/(r + w)?
Certainly not! Intuitively, we would argue that r−1 red balls and w white balls are left
r−1
r+w−1. In other words, the occurrence
in the urn, so now the probability should be
of A has led us to revise the way we assign probabilities to the events. This means
that the probability measure P must be replaced by a new probability measure PA that
takes account of the information that A has occurred. Sensibly, PA should satisfy the
following two conditions.

51

3.1 Conditional Probabilities
(a) PA(A) = 1, i.e., the event A is now certain.
(b) For subevents of A, the new probability is proportional to the original one, i.e.,
there exists a constant cA > 0 such that PA(B) = cA P(B) for all B ∈ F with
B ⊂ A.
The following proposition shows that PA is uniquely determined by these properties.
(3.2) Proposition. Re-weighting of events. Let (, F , P) be a probability space and
A ∈ F with P(A) > 0. Then there is a unique probability measure PA on (, F )
satisfying (a) and (b), which is given by

PA(B) :=

P(A ∩ B)
P(A)

for B ∈ F .

Proof. Suppose PA satisﬁes (a) and (b). Then for every B ∈ F we have
PA(B) = PA(A ∩ B) + PA(B \ A) = cA P(A ∩ B) ,

since PA(B \ A) = 0 by (a). For B = A, it follows that 1 = PA(A) = cA P(A),
so cA = 1/P(A). Hence, PA has the required form. Conversely, it is clear that PA
deﬁned as above satisﬁes (a) and (b). ✸
Deﬁnition. In the setting of Proposition (3.2), for every B ∈ F, the expression

P(B|A) :=

P(A ∩ B)
P(A)

What does this imply for Example (3.1)? By deﬁnition, we obtain

is called the conditional probability of B given A with respect to P. (If P(A) = 0, it
is sometimes convenient to set P(B|A) := 0.)
|| = |A ∩ B|
|A| =

r (r − 1)
r (r + w − 1) =

P(B|A) = |B ∩ A|

|| !|A|

so the conditional probability takes exactly the value that corresponds to our intuition.
Let us now consider the following reversed situation. The ﬁrst ball is drawn without
looking at it, and the second one is red. How certain can one be that the ﬁrst ball was
red as well? Intuitively, one would argue that since B is known to occur, B is the set
of all possible cases and A ∩ B the set of favourable cases, so with certainty

r − 1
r + w − 1 ,

|A ∩ B|
|B| =

r (r − 1)
r (r + w − 1) =

r − 1
r + w − 1 ,

one can bet that A has occurred before. This is exactly the value of P(A|B) according
to the deﬁnition of the conditional probability. We thus ﬁnd that, although the event B
has deﬁnitely no inﬂuence on the occurrence of A, the information that B has occurred

52

3 Conditional Probabilities and Independence

leads us to re-estimate the probability of A, and to use its conditional probability in
place of its absolute probability. This observation entails the following conclusion
about the
Interpretationofconditionalprobabilities. Thecalculationofconditionalprobabilities
does not allow to infer any causality relations among the events! Instead, conditional
probabilities can be interpreted in either of the following ways.

(a) The frequency interpretation.

(b) The subjective interpretation.

If the random experiment is repeated many times,
P(B|A) gives the proportion of cases in which B occurs among those in which
A occurs.
If P corresponds to my evaluation of the situation
before the experiment, then P(·|A) is my evaluation after I have been informed
that A has occurred (rather than: after A has occurred).
A naive interpretation of conditional probabilities would be dangerously close to an
erroneous inference of causality relations, and is therefore omitted here.

Here are two elementary facts about conditional probabilities.

(3.3) Theorem. Case-distinction and Bayes’ formula. Let (, F , P) be a probability
space and  = "i∈I Bi an at most countable partition of  into pairwise disjoint
events Bi ∈ F. Then the following holds.
(a) Case-distinction formula. For every A ∈ F,
P(A) =#i∈I

P(Bi )P(A|Bi ) .

(b) Bayes’ formula (1763). For every A ∈ F with P(A) > 0 and every k ∈ I, the

reverse conditional probability can be expressed as
P(Bk )P(A|Bk )
$i∈I P(Bi )P(A|Bi )
P(A|B1)

P(Bk|A) =

P(B1)

B1

.

P(B2)

P(B3)

P(A|B2)

A

P(A|B3)

B2

B3

Figure 3.1. Illustration of Theorem (3.3). Part (a): P(A) is split into the probabilities of
the different paths leading to A. Part (b): P(Bk|A) is the probability of the path via Bk in
relation to the total probability of all paths to A. (The probabilities are multiplied along
each path.)

3.1 Conditional Probabilities

53

Proof. (a) By the deﬁnition of conditional probabilities and the σ-additivity of P, it

follows that$i∈I P(Bi ) P(A|Bi ) =$i∈I P(A ∩ Bi ) = P(A).

(b) This follows from (a) and the deﬁnition. ✸
Thomas Bayes (1702–1761) was a Presbyterian minister (and member of the Royal Society)
in England. His mathematical work was only posthumously published in 1763. At that time
Bayes’ formula caused quite a stir, because people believed they could use it to deduce causes
from their effects. But as we have seen above, this is impossible.

The following example presents a typical (and correct) application.

(3.4) Example. Evaluation of medical tests. A certain disease is present in 2% of
the population (in medical jargon, ‘the prevalence of the disease is 2%’). A test of
the disease gives a positive result for 95% of the individuals that are affected by the
disease(‘thesensitivityofthetestis95%’)andfor10%ofthosethatarenot(‘speciﬁcity
90%’). What is the predictive value of the positive test result, in other words, what is
the probability that a randomly chosen person has the disease when her test result is
positive?
To answer this question we will set up the following stochastic model. Let  be the
ﬁnite set of all individuals in the population and P = U the uniform distribution on .
Let B1 denote the set of individuals that are affected by the disease, and B2 =  \ B1
the set of those that are not. Finally, let A be the set of individuals reacting positive
to the test (as soon as they are tested). Then, by assumption, we have P(B1) = 0.02,
P(B2) = 0.98, P(A|B1) = 0.95 and P(A|B2) = 0.1. By Bayes’ formula, the
predictive value is given by

P(B1|A) =

0.02 · 0.95

0.02 · 0.95 + 0.98 · 0.1 !

1
6 .

So, the‘positivecorrectness’ofthetestissurprisinglylow,andmostofthetestpositives
are actually false positive. On the other hand,

P(B1|Ac) =
=

P(B1)P(Ac|B1)

P(B1)P(Ac|B1) + P(B2)P(Ac|B2)
0.02 · 0.05 + 0.98 · 0.9 ≈ 0.001 .

0.02 · 0.05

That is, it is extremely unlikely that a person tested negative is, indeed, affected; so the
‘negative correctness’ is very high. Hence, the test is useful to rule out the possibility
of having the disease, but a positive result does not mean very much without further
investigation.

How can it be that a test with such a high sensitivity has such a low positive correctness?
The reason is that the disease is so rare. Quite often, this effect is not well understood – not
even by doctors –, and so patients with a positive test result are too readily told they have the
disease, see the report in [22]. (Imagine what this means for the patients in the case of AIDS or
breast cancer!) This effect is more readily understood if the percentages in the formulation of

54

3 Conditional Probabilities and Independence

the problem (which each refer to a different reference population) are expressed so as to refer
to the same population, see Table 3.1. It then becomes clear that, despite the low incidence of
false negatives (one out of 20 affected), the majority of those tested positive (namely, 98 out of
117) are actually healthy (i.e., they are false positives). The picture changes if the individual
tested belongs to a risk group, in which the disease shows up with prevalence 10%: Among
1000 members of this group, 185 are test positive, and 95 of these are affected. This means that
the positive correctness within this group is slightly above 50%.

Table 3.1. Table for Bayes’ formula, for a population of size 1000.

test positive
test negative



affected
19
1
20

healthy
98
882
980


117
883
1000

The next example is one of the best-known stochastic brainteasers, and its correct

interpretation is still under discussion.
(3.5) Example. The three doors paradox (or Monty Hall problem). Inspired by Monty
Hall’s American TV show ‘Let’s Make a Deal’, in 1990 a reader sent the following
problem to the American journalist Marilyn vos Savant to be included in her column
in the ‘Parade Magazine’:

Suppose you’re on a game show, and you’re given the choice of three
doors. Behind one door is a car, behind the others, goats. You pick a door,
say #1, and the host, who knows what’s behind the doors, opens another
door, say #3, which has a goat. He says to you, ‘Do you want to pick door
#2?’ Is it to your advantage to switch your choice of doors?

Her answer was: ‘Yes, you should switch. The ﬁrst door has a 1/3 chance of winning,
but the second door has a 2/3 chance’. She justiﬁed her answer by referring to the
analogous problem of 1 million doors, where all but two doors are opened by the host.
This started a lively public discussion of the problem. Often it was claimed that after
opening door 3, the two remaining doors had the same probability 1/2 of winning.
So who is right? To ﬁnd out, we must interpret the situation precisely. We label the
three doors by the numbers 1, 2, 3. Since the doors look the same from the outside, we
can assume without loss of generality that the winning door is number 1. Two doors
are chosen randomly, one by the contestant and the other by the host. Their respective
choices are recorded by two random variables C and H taking values in{1,2,3}. Since
the contestant has no information about which one is the winning door, she will choose
any door with the same probability, so C has the uniform distribution on {1,2,3}. In
the problem, it is assumed that the event A := {C ̸= H ̸= 1} = {H ̸= C} ∩ {H ̸= 1}
has occurred, and the contestant gets another chance to choose a door, either the same
as before or the remaining third door; see Figure 3.2. In the ﬁrst case, the conditional

3.1 Conditional Probabilities

55

t h e h o s t

s t
’ s
W h a t
C o u l d h e h a v e o p e n e d
I h a v e

i s
t h e d o o r

r a t e g y ?
c h o s e n ?

Well, would you now prefer
to choose another door?

?

?

Figure 3.2. The Monty Hall problem.

probability of winning is P(C = 1|A). To calculate this, the contestant needs more
information about A, in particular on how the host will behave. So what information
is available?

First of all, it is obvious that the host will not open the winning door, because oth-
erwise the game is immediately over, which would be rather pointless for the viewers.
This justiﬁes the assumption P(H ̸= 1) = 1. Further, we can interpret the formulation
‘opens another door’ such that the host will not open the door chosen by the contestant.
Then P(H ̸= C) = 1 and by Theorem (1.11b) we also have P(A) = 1, and hence

P(C = 1|A) = P(C = 1) =

1
3 .

Correspondingly, if the contestant switches to the third door (̸= C, H), the conditional
probabilityofwinningis P(C ̸= 1|A) = 2/3. ThisispreciselytheanswerthatMarilyn
vos Savant gave, and its justiﬁcation is surprisingly simple.
The triviality of this answer comes from the assumption that the host behaves
according to ﬁxed rules, so that each time he carries out the game in exactly the same
way as described in the problem, which implies that the event A will certainly occur.
The deeper reason for this assumption is the implicit use of the frequency interpretation
of conditional probabilities, which requires that the procedure can be repeated in the
same way and thus needs ﬁxed rules. (This becomes quite evident when people argue
that Marilyn’s answer can be justiﬁed by simulating the problem on a computer.) In
reality, however, the host will not behave in a predictable way every time (then there
would be no element of surprise for neither contestants nor viewers). From this point
of view the subjective interpretation seems more suitable. So everything depends on
how the contestant predicts the behaviour of the host. As before, the contestant can
guess that the host will not open the winning door, and assume that P(H ̸= 1) = 1.

3 Conditional Probabilities and Independence

56
Then, P(A|C = 1) = P(H ̸= 1|C = 1) = 1 and by Bayes’ formula (3.3b)
(3.6)
P(C = 1) P(A|C = 1) + P(C ̸= 1) P(A|C ̸= 1)
1/3 + (2/3) P(A|C ̸= 1)

P(C = 1) P(A|C = 1)
1/3

P(C = 1|A) =
=

.

How should the contestant estimate the conditional probability P(A|C ̸= 1)? As
before, she might conclude that P(H ̸= C) = 1 and hence P(A) = 1. Alternatively,
she might assume that the host opens each of the doors concealing a goat with equal
probability 1/2, irrespective of which door C the contestant has chosen. (For example,
if H = C, the host would say ‘Look! You had bad luck. But I give you a second
chance, you may pick another door!’) Then P(H = C|C = c) = 1/2 for c ∈ {2,3}
and thus by the case-distinction formula (3.3a) we also have

P(H = C|C ̸= 1) =

1
2 P(C = c|C ̸= 1) =

1
2 .

3#c=2

By the assumption P(H ̸= 1) = 1, it follows that

P(A|C ̸= 1) = P(H ̸= C|C ̸= 1) =

1
2

and thus by (3.6) P(C = 1|A) = 1/2. This is exactly the answer of the critics!
LikeinBertrand’sparadox, thedifferentanswersdependondifferentinterpretations
of a problem that is posed in an ambiguous way. The different viewpoints boil down
to the question of whether or not the event A occurs according to a ﬁxed rule, and are
often intertwined with an uncertainty about the philosophical meaning of conditional
probabilities. Moreonthistopiccanbefoundin, e.g., [22,26,29,48]andthereferences
therein. These sources present a number of different approaches to the problem, which
shows that a general agreement has not yet been reached.
In the above discussion, it has still been left open whether the random variables
C and H with their respective properties actually do exist. But this is an immediate
consequence of the next section.
3.2 Multi-Stage Models
Consider a random experiment that is performed in n successive stages, or sub-
experiments. We want to construct a probability space (, F , P) for the full ex-
periment, as well as random variables (Xi )1≤i≤n on  that describe the outcomes of
the individual subexperiments. Suppose we are given
(a) the distribution of X1,
(b) the conditional distribution of Xk when the values of X1, . . . , Xk−1 are known,

for all 2 ≤ k ≤ n.

3.2 Multi-Stage Models

57

In other words, we know how to describe the ﬁrst subexperiment and, for each time
point, how to describe the next subexperiment if all previous subexperiments have been
performed so that their outcomes are known. The following proposition provides an
idea how to attack this problem.
(3.7) Proposition. Multiplication rule.
A1, . . . , An ∈ F. Then,

Let (, F , P) be a probability space and

P(A1 ∩ ··· ∩ An) = P(A1) P(A2|A1) . . . P(An|A1 ∩ ··· ∩ An−1) .

Proof. If the left hand side vanishes, then the last factor on the right is zero as well.
Otherwise, all the conditional probabilities on the right-hand side are deﬁned and
non-zero. They form a telescoping product, in which consecutive numerators and
denominators cancel, and so only the left-hand side remains. ✸

The following theorem describes the construction of random variables satisfying
properties (a) and (b). For simplicity, we assume that every subexperiment has an at
most countable sample space.
(3.8) Theorem. Construction of probability measures via conditional probabilities.
Suppose we are given n countable sample spaces 1, . . . , n ̸= ∅, n ≥ 2. Let ϱ1
be a discrete density on 1 and, for k = 2, . . . , n and arbitrary ωi ∈ i with i < k,
let ϱk|ω1,...,ωk−1 be a discrete density on k. Further, let  =%n
i=1 i be the product
space and Xi :  → i the ith projection. Then there exists a unique probability
measure P on (, P()) with the properties
(a) P(X1 = ω1) = ϱ1(ω1) for all ω1 ∈ 1,
(b) for every k = 2, . . . , n,

P(Xk = ωk|X1 = ω1, . . . , Xk−1 = ωk−1) = ϱk|ω1,...,ωk−1 (ωk)

for all ωi ∈ i such that P(X1 = ω1, . . . , Xk−1 = ωk−1) > 0 .

Equation (3.9) is illustrated by the tree diagram in Figure 3.3.

Proof. We claim that P can only be deﬁned by (3.9). Indeed, writing Ai = {Xi = ωi}
and {ω} =&n
i=1 Ai, and using assumptions (a) and (b), we see that equation (3.9) is
identical to the multiplication rule. This proves the uniqueness of P.

This P is given by
(3.9)
for ω = (ω1, . . . , ωn) ∈ .

P({ω}) = ϱ1(ω1) ϱ2|ω1 (ω2) ϱ3|ω1,ω2 (ω3) . . . ϱn|ω1,...,ωn−1 (ωn)

58

3 Conditional Probabilities and Independence

1×2

1

☛
a
✡

  ✒
 
ϱ1(a)

 

ϱ2|a (a)
✟✟✟✟✟✟✯
✟
❍❍❍❍❍❍❥
✠
ϱ2|a (b)

✉ 
❅

 

❅

❅

ϱ1(b)
❅

❅❅❘

☛
b
✡

ϱ2|b(a)
✟✟✟✟✟✟✯
✟
❍❍❍❍❍❍❥
✠
ϱ2|b(b)

1×2×3
✟
✠
✟
✠
✟
✠
✟
✠
✟
✠
✟
✠
✟
✠
✟
✠

☛
aaa
✡
☛
aab
✡
☛
aba
✡
☛
abb
✡
☛
baa
✡
☛
bab
✡
☛
bba
✡
☛
bbb
✡

ϱ3|aa (a)

✘✘✘✘✘✘✿
✟
❳❳❳❳❳❳③
✠

✘✘✘✘✘✘✿
✟
❳❳❳❳❳❳③
✠

ϱ3|aa (b)
ϱ3|ab(a)

ϱ3|ab(b)
ϱ3|ba (a)

✘✘✘✘✘✘✿
✟
❳❳❳❳❳❳③
✠

ϱ3|ba (b)
ϱ3|bb(a)

✘✘✘✘✘✘✿
✟
❳❳❳❳❳❳③
✠

ϱ3|bb(b)

☛
aa
✡

☛
ab
✡

☛
ba
✡

☛
bb
✡

#ωk+1∈k+1,...,ωn∈n

Figure 3.3. Tree diagram for the construction of multi-stage models, in this case for
n = 3 and i = {a, b}. The probability of a triple in  is the product of the transition
probabilities along the path leading to this triple.
So deﬁne P by (3.9). Then, for all 1 ≤ k ≤ n and ω1, . . . , ωk, we can sum over all

P({(ω1, . . . , ωn)})
ϱk+1|ω1,...,ωk (ωk+1) . . .#ωn∈n

possible values of ωk+1, . . . , ωn to obtain
P(X1 = ω1, . . . , Xk = ωk) =
= ϱ1(ω1) . . . ϱk|ω1,...,ωk−1 (ωk ) #ωk+1∈k+1
ϱn|ω1,...,ωn−1 (ωn) .
Since ϱn|ω1,...,ωn−1 is a probability density, the last sum takes the value 1 and can thus
be omitted. Evaluating the second last sum, we ﬁnd that it also yields 1. Continuing in
this way, we see that the total of all the sums in the last row is 1. For k = 1 we obtain
(a), and another summation over ω1 shows that the right-hand side of (3.9) is indeed a
probability density. For k > 1 we get
P(X1 = ω1, . . . , Xk = ωk) = P(X1 = ω1, . . . , Xk−1 = ωk−1) ϱk|ω1,...,ωk−1 (ωk)
and thus (b). ✸

3.2 Multi-Stage Models

59

(3.10) Example. The game of skat. Skat is a popular German card-game, which is
played with a deck of 32 cards (including 4 aces). What is the probability that each
of the three players gets exactly one ace? As we have seen in Section 2.3.1, we can
assume that (after the cards have been well shufﬂed) the players, one by one, receive
their batch of ten cards; the two remaining cards form the ‘skat’. We are interested in
the number of aces for each player, so we choose the sample spaces 1 = 2 = 3 =
{0, . . . ,4} for the subexperiments, and the product space  = {0, . . . ,4}3 for the full
experiment. The probability measure P on  can be constructed by Theorem (3.8) via
the hypergeometric transition probabilities

ϱ1(ω1) = H10;4,28({ω1}) =’ 4
ω1(’ 28
10−ω1()’32
10( ,
ϱ2|ω1 (ω2) = H10;4−ω1,18+ω1 ({ω2}) ,
ϱ3|ω1,ω2 (ω3) = H10;4−ω1−ω2,8+ω1+ω2 ({ω3});

see Section 2.3.2. The event {(1,1,1)} that each player receives one ace thus has the
probability

P’{(1,1,1)}( = ϱ1(1) ϱ2|1(1) ϱ3|1,1(1)
1(’10
9(
’2
10( = 103
’12

1(’28
9(
= ’4
’32
10(

1(’19
9(
’3
’22
10(

2 · 4!
32 . . .29 ≈ 0.0556 .

(3.11) Example. Population genetics. Consider a gene with two alleles A and a.
An individual with a diploid set of chromosomes thus has one of the three possible
genotypes AA, Aa and aa. Suppose these genotypes are present in a population with
relative frequencies u, 2v, w respectively, where u + 2v + w = 1. We assume that for
this gene there is no mutation or selection, and the gene is irrelevant for the choice of
a partner. What is the distribution of the genotypes in the offspring generation?
As in Theorem (3.8), we construct a probability measure P on the product space
{AA,Aa,aa}3, which contains all possible genotypes of mother, father and offspring.
By assumption, the genotype ω1 of the mother has the distribution ϱ1 = (u,2v, w),
and the genotype ω2 of the father has the same (conditional) distribution ϱ2|ω1 = ϱ1,
which by assumption does not depend on ω1. The conditional distribution ϱ3|ω1ω2 (ω3)
of the genotype ω3 of the offspring can now be deduced from the fact that one gene

Table 3.2. The transition probabilities ϱ3|ω1ω2 (AA) for the offspring genotype AA given
the genotypes ω1, ω2 of mother and father.

ω1
ω2
AA AA
Aa
AA
Aa
Aa
otherwise

ϱ3|ω1ω2 (AA)

1
1/2
1/2
1/4
0

60

3 Conditional Probabilities and Independence

from the mother is combined with one gene from the father, where both genes are
chosen with equal probabilities; see Table 3.2.
3 of the offspring genotype? Using (3.9), we obtain
by summation over all possible genotypes for the parents

What is the distribution P ◦ X−1
u1 := P(X3 = AA) = u2

+ 2uv/2 + 2vu/2 + 4v2/4 = (u + v)2 .
By symmetry, it follows that w1 := P(X3 = aa) = (w + v)2, and hence that

+ (u + v)(w + v)(2
= (u + v)2
= u1

− (u + v)2

− (w + v)2

= 2(u + v)(w + v) .

Similarly, the probability u2 of the genotype AA in the second generation is obtained
as

2v1 := P(X3 = Aa) = 1 − u1 − w1

= ’(u + v) + (w + v)(2
u2 = (u1 + v1)2
= (u + v)2’(u + v) + (w + v)(2

=’(u + v)2

and, likewise, w2 = w1, v2 = v1. This is the famous law of G.H. Hardy and W. Wein-
berg(1908): Undertheassumptionofrandommating, thegenotypefrequenciesremain
constant from the ﬁrst offspring generation onwards.

Our next aim is to extend Theorem (3.8) to the case of a random experiment that
consists of inﬁnitely many subexperiments. Recall that the necessity to deal with an
inﬁnite sequence of subexperiments already turned up in Section 2.5.1 in the context
of waiting times for Bernoulli trials, since one cannot know in advance how long it
will take until the ﬁrst success.
(3.12) Theorem. Construction of probability measures on inﬁnite product spaces. For
̸= ∅ be a countable set. Let ϱ1 be a discrete density on 1
every i ∈ N, let i
and, for every k ≥ 2 and ωi ∈ i with i < k, let ϱk|ω1,...,ωk−1 be a discrete density
on k. Let  =%i≥1 i, Xi :  → i the projection onto the ith coordinate, and
F =*i≥1 P(i ) the product σ-algebra on . Then there exists a unique probability
measure P on (, F ) such that
(3.13)
for all k ≥ 1 and ωi ∈ i.
to the conditions (a) and (b) stated there.
Proof. The uniqueness follows from the uniqueness theorem (1.12), since

P(X1 = ω1, . . . , Xk = ωk) = ϱ1(ω1) ϱ2|ω1 (ω2) . . . ϱk|ω1,...,ωk−1 (ωk)

Equation (3.13) corresponds to equation (3.9) in Theorem (3.8) and is equivalent

G =+{X1 = ω1, . . . , Xk = ωk} : k ≥ 1, ωi ∈ i, ∪ {∅}

is an intersection-stable generator of F; cf. Problem 1.5.

3.2 Multi-Stage Models

1

1
3

✟✟✟✟✟✟✯
❍❍❍❍❍❍❥

t

2
3

2
3

I1

I0

0

✘✘✘✘✘✘✿
❳❳❳❳❳❳③

✏✏✏✏✏✏✶
❳❳❳❳❳❳③

1
3

2
3
1
3

2
3

61

✲26
27
22
27
16
27

8
27

✛ I111
I110
I101
I100
I011
I010
I001

I000

8
9

4
9

I11
I10

I01

I00

...
1
3

2
3

✘✘✘✘✘✘✿
❳❳❳❳❳❳③

Figure 3.4. The intervals of the ﬁrst up to the third level for i = {0,1} and
ϱk|ω1,...,ωk−1 (1) = 1/3, where the intervals are split into two parts with proportion 1:2.
The arrows indicate the analogy to the tree diagram. We have Z (1/2) = (0,1,0, . . . ).

The existence of P will be deduced from the existence of the Lebesgue measure
λ = U[0,1[ on the half-open unit interval [0,1[, cf. Remark (1.17). As illustrated in
Figure 3.4, we partition the interval [0,1[ into half-open intervals (Iω1 )ω1∈1 of length
ϱ1(ω1); they will be referred to as intervals of the ﬁrst level. Each Iω1 is then split into
half-open intervals (Iω1ω2 )ω2∈2 of length ϱ1(ω1)ϱ2|ω1 (ω2); these are the intervals of
the second level. We continue in this way, that is, after deﬁning the interval Iω1...ωk−1
of the (k − 1)st level, we split it further into disjoint subintervals (Iω1...ωk )ωk∈k of the
kth level with lengths λ(Iω1...ωk−1 ) ϱk|ω1,...,ωk−1 (ωk ).
For each x ∈ [0,1[ and arbitrary k there exists a unique interval of level k that
contains x. Inotherwords,thereisauniquesequence Z (x) = (Z1(x), Z2(x), . . . ) ∈ 
such that x ∈ IZ1(x)...Zk (x) for all k ≥ 1. The mapping Z : [0,1[ →  is a random
variable; indeed, for A = {X1 = ω1, . . . , Xk = ωk} ∈ G we have

Z−1A = {x : Z1(x) = ω1, . . . , Zk (x) = ωk} = Iω1...ωk ∈ B[0,1[ ,

sothattheclaimfollowsfromRemark(1.25). Hence, byTheorem(1.28), P := λ◦Z−1
isawell-deﬁnedprobabilitymeasureon (, F ),andbyconstruction,ithastherequired
properties. ✸
(3.14) Example. Pólya’s urn model. The following urn model goes back to the
Hungarian mathematician G. Pólya (1887–1985). An urn contains r red and w white
balls. An inﬁnite sequence of balls is drawn from the urn, and after each draw the
selected ball plus c additional balls of the same colour are placed into the urn. The case
c = 0 corresponds to drawing with replacement. We are interested in the case c ∈ N,
when a self-reinforcing effect appears. Namely, the greater the proportion of red balls
in the urn, the more likely it is that another red ball is drawn and so the proportion of
red balls increases even further. This is a simple model for two competing populations
(and maybe also for the career of politicians).

ϱk|ω1,...,ωk−1 (ωk) =⎧⎨⎩

r+cℓ

r+w+c(k−1)
w+c(k−1−ℓ)
r+w+c(k−1)

if k−1$i=1

ωi = ℓ and ωk =0 1

0 .

62

3 Conditional Probabilities and Independence

Which is the probability space for this urn model? We can proceed exactly as in
Theorem (3.12). If we write 1 for ‘red’ and 0 for ‘white’, then i = {0,1} and so
 = {0,1}N. For the initial distribution ϱ1 we obviously have ϱ1(0) = w/(r + w)
and ϱ1(1) = r/(r + w) corresponding to the initial proportion of white and red balls
in the urn. For the transition densities at time k > 1, we obtain analogously

Indeed, if we have drawn ℓ red (and so k − 1 − ℓ white) balls in the ﬁrst k − 1 draws,
then the urn contains r + cℓ red and w + c(k − 1 − ℓ) white balls. We now build the
product of the transition probabilities according to (3.9), and consider the numerator of
the resulting product. At the ℓ different times k with ωk = 1, we obtain the successive
factors r, r + c, r + 2c, . . ., and at the remaining times with ωk = 0 the factors w,
w + c, w + 2c, . . ., respectively. The factors in the denominator do not depend on the
ωk. Combining all factors, we arrive at the following characterisation of the probability
measure P that Theorem (3.12) provides for the Polya urn:
P(X1 = ω1, . . . , Xn = ωn) = %ℓ−1

(w + cj )

ωk = ℓ .

Remarkably, these probabilities do not depend on the order of the ωi, but only on their
sum. For this reason, the random variables X1, X2, . . . are said to be exchangeable
under P.
Now let Rn =$n
k=1 Xi denote the number of red balls after n draws. Since all ω
with Rn(ω) = ℓ have the same probability, we obtain
j=0

(w + cj )

j=0

i=0 (r + ci ) %n−ℓ−1
%n−1
m=0(r + w + cm)

if n$k=1

.

P(Rn = ℓ) =1n

ℓ2%ℓ−1

i=0 (r + ci ) %n−ℓ−1
%n−1
m=0(r + w + cm)

For c = 0, this is just the binomial distribution, in agreement with Theorem (2.9).
In the case c ̸= 0, we can cancel the factor (−c)n in the fraction. Using the general
binomial coefﬁcient (2.18) and the abbreviations a := r/c, b := w/c we then ﬁnd

P(Rn = ℓ) = ’−a
ℓ(’ −b
n−ℓ(
(
’−a−b
The probability measure P ◦ R−1
n on {0, . . . , n} thus obtained is known as the Pólya
distribution with parameters a, b > 0 and n ∈ N. In the case c = −1, i.e. −a,−b ∈ N,
which corresponds to sampling without replacement, these are exactly the hypergeo-
metric distributions, as it should be according to Section 2.3.2. If a = b = 1, we obtain
the uniform distribution. Figure 3.5 illustrates the Pólya distributions for various pa-
rameter values. Note their resemblance with the densities of the beta distributions in
Figure 2.7 – this is no coincidence, see Problem 3.4. The long term behaviour of Rn/n
is discussed in Problem 5.11.

n

.

3.3 Independence

63

0.1

0.05

0

30

Figure 3.5. Bar charts of the Pólya distributions for n = 30 and (a, b) = (5/7,4/7) (light
grey), (8/4,7/4) (grey), and (5,9) (dark grey).

3.3 Independence
Intuitively, the independence of two events A and B can be expressed as follows: The
probability one assigns to A is not inﬂuenced by the information that B has occurred,
and conversely the occurrence of A does not lead to a re-weighting of the probability
of B. Explicitly, this means that

P(A|B) = P(A) and P(B|A) = P(B), provided P(A), P(B) > 0.

Let us consider two examples for illustration.

Writing these equations in a symmetric form one obtains:
Deﬁnition. Let (, F , P) be a probability space. Two events A, B ∈ F are called
(stochastically) independent with respect to P if P(A ∩ B) = P(A)P(B).
(3.15) Example. Sampling with and without replacement. We take two samples with
replacement from an urn with r red and w white (labelled) balls. A suitable model is
 = {1, . . . ,r + w}2 and P = U, the uniform distribution. We consider the events
A = {the ﬁrst ball is red} and B = {the second ball is red}. Then, we have

P′(A ∩ B) =

r (r − 1)

(r + w)(r + w − 1)

< P′(A)P′(B) .

P(A ∩ B) =

r2
(r + w)2 = P(A) P(B) ,

so A and B are independent with respect to P. However, if we replace P by another
probability measure P′, the events A and B need not be independent. For instance,
, the uniform distribution on ̸= = {(k,l) ∈
this happens for P′ = P(·|̸=) = U̸=
 : k ̸= l}, which describes sampling without replacement, cf. Example (3.1). Then,

64

3 Conditional Probabilities and Independence

This emphasises that independence is not only a property of events, but also of the
underlying probability measure – a fact that is self-evident, though still sometimes
overlooked.
(3.16) Example. Independence despite causality. Consider the experiment of rolling
two distinguishable dice, which can be described by  = {1, . . . ,6}2 with the uniform
distribution P = U. Let

A = {sum of the two dice is 7} = {(k,l) ∈  : k + l = 7} ,
B = {ﬁrst die shows 6} = {(k,l) ∈  : k = 6} .

Then |A| = |B| = 6, |A ∩ B| = 1, so
P(A ∩ B) =

1
62 = P(A) P(B),

even though the sum is causally determined by the number shown by the ﬁrst die. In
this case the independence follows because we have chosen 7 (instead of 12, say) for
the value of the sum. Nevertheless it shows the following:

Next we proceed to the independence of more than just two events.

Independence should not be misunderstood as causal independence, although Ex-
ample (3.15) seems to suggest just this. Rather, independence means a proportional
overlap of probabilities and does not involve any causality. It depends essentially on
the underlying probability measure. One should also note that A is independent of
itself when P(A) ∈ {0,1}.
Deﬁnition. Let (, F , P) be a probability measure and I ̸= ∅ an arbitrary index set.
A family (Ai )i∈I of events in F is called independent with respect to P if, for every
ﬁnite subset ∅ ̸= J ⊂ I, we have
P34i∈J

(The trivial case |J| = 1 is included here just for simplicity of the formulation.)
The independence of a family of events is a stronger property than pairwise inde-
pendence of any two events in the family, but it corresponds exactly to what one would
intuitively understand as mutual independence. This becomes clear in the following
example.
(3.17) Example. Dependence despite pairwise independence. In the model for tossing
a coin twice (with  = {0,1}2 and P = U) consider the three events

Ai5 =6i∈J

P(Ai ) .

A = {1} × {0,1} = {ﬁrst toss is heads} ,
B = {0,1} × {1} = {second toss is heads} ,
C = {(0,0), (1,1)} = {both tosses give the same result} .

65
3.3 Independence
Then P(A ∩ B) = 1/4 = P(A) P(B), P(A ∩ C) = 1/4 = P(A) P(C), and
P(B ∩ C) = 1/4 = P(B) P(C), so A, B,C are pairwise independent. However,

P(A ∩ B ∩ C) =

1
4 ̸=

1
8 = P(A) P(B) P(C) ,

i.e., A, B, C are dependent according to the deﬁnition above. This is exactly what one
would expect, since in fact C = (A ∩ B) ∪ (Ac ∩ Bc).
We can take the generalisation even one step further. We are not only interested in
the independence of events, but also in the independence of subexperiments, in other
words: in the independence of random variables that describe such subexperiments.
Deﬁnition. Let (, F , P) be a probability space, I ̸= ∅ an arbitrary index set, and
for every i ∈ I let Yi :  → i be a random variable on (, F ) taking values in an
event space (i , Fi ). The family (Yi )i∈I is called independent with respect to P if,
for an arbitrary choice of events Bi ∈ Fi, the family ({Yi ∈ Bi})i∈I is independent,
i.e., if the product formula
(3.18)

P34i∈J{Yi ∈ Bi}5 =6i∈J

P(Yi ∈ Bi )

holds for any ﬁnite subset ∅ ̸= J ⊂ I and for all Bi ∈ Fi (with i ∈ J).
How can one check that a family of random variables is independent? Is it really
necessary to try each Bi ∈ Fi? This is hardly possible, since in most cases all that is
known explicitly about a σ-algebra is its generator. Hence, the following criterion is
essential.
(Readers who have skipped the proof of the uniqueness theorem (1.12) can also skip this
proof and just take the result and its consequences for granted.)
(3.19) Theorem. Independence criterion.
In the setting of the previous deﬁnition,
suppose that, for every i ∈ I, an intersection-stable generator Gi of Fi is given, so
that σ (Gi ) = Fi. To show the independence of (Yi )i∈I, it is then sufﬁcient to verify
equation (3.18) for the events Bi in Gi only (rather than all events in Fi).
Proof. It is sufﬁcient to prove the following statement by induction on n: Equation
(3.18) holds for all ﬁnite J ⊂ I and all Bi ∈ Fi with |{i ∈ J : Bi /∈ Gi}| ≤ n.
For n ≥ |J|, the last condition holds automatically, and the required independence
follows. The case n = 0 corresponds exactly to our hypothesis that (3.18) holds for
any Bi ∈ Gi. The inductive step n ❀ n + 1 runs as follows.
Suppose J ⊂ I and Bi ∈ Fi are such that |{i ∈ J : Bi /∈ Gi}| = n + 1. Pick
any j ∈ J with Bj /∈ Gj and set J′ = J \ {j} and A = &i∈J′{Yi ∈ Bi}. The
inductive hypothesis implies that P(A) = %i∈J′ P(Yi ∈ Bi ). We can assume that
P(A) > 0, because otherwise both sides of (3.18) vanish. We consider the probability
measures P(Yj ∈ ·|A) := P(·|A) ◦ Y −1
on Fj. By
j
the inductive hypothesis, these coincide on Gj, so, by the uniqueness theorem (1.12),

and P(Yj ∈ · ) := P ◦ Y −1
j

66

3 Conditional Probabilities and Independence

they are identical on all of Fj. Multiplying by P(A) shows that (3.18) holds for the
required sets, and the inductive step is completed. ✸

As a ﬁrst application, we obtain a relation between the independence of events and

i , , ∅} is selected, then the family (Ci )i∈I is also independent.

their corresponding indicator functions; cf. (1.16).
(3.20) Corollary. Independence of indicator functions. A family (Ai )i∈I of events is
independent if and only if the corresponding family (1Ai )i∈I of indicator functions is
independent. In particular, if (Ai )i∈I is independent and for each i ∈ I an arbitrary
Ci ∈ {Ai , Ac
Proof. Every indicator function 1A is a random variable taking values in the event
space ({0,1}, P({0,1})), and P({0,1}) has the intersection-stable generator G =
{{1}}, which contains the singleton set {1} as its only element. Moreover, we have
{1A = 1} = A.
Hence, if (Ai )i∈I is independent, then (1Ai )i∈I satisﬁes the assumption of The-
orem (3.19). Conversely, if (1Ai )i∈I is independent, then by deﬁnition the family
({1Ai ∈ Bi})i∈I is independent no matter which sets Bi ⊂ {0,1} we choose. This
proves the last statement, and for Bi = {1} we see that (Ai )i∈I is independent. ✸
Next, we state a criterion for independence of ﬁnite families of random variables.
(3.21) Corollary. Independence of ﬁnitely many random variables.
Let (Yi )1≤i≤n
be a ﬁnite sequence of random variables on a probability space (, F , P). Then the
following holds.
(a) Discrete case: If each Yi takes values in a countable set i, then (Yi )1≤i≤n is

independent if and only if

P(Y1 = ω1, . . . , Yn = ωn) =

n6i=1

P(Yi = ωi )

for arbitrary ωi ∈ i.

(b) Real case: If each Yi is real-valued, then (Yi )1≤i≤n is independent if and only if

P(Y1 ≤ c1, . . . , Yn ≤ cn) =

P(Yi ≤ ci )

n6i=1

for all ci ∈ R.

Proof. The implication ‘only if’ is trivial in both cases; the direction ‘if’ is obtained
as follows.
Incase(a),Example(1.7)showsthat Gi =+{ωi} : ωi ∈ i,∪{∅}isanintersection-
stable generator of Fi = P(i ); the trivial events {Yi ∈ ∅} = ∅ need not be consid-
ered since, in this case, both sides in (3.18) vanish. Our assumption thus corresponds
exactly to the condition of Theorem (3.19) for the special case J = I. In the case
J " I, the corresponding product formula is simply obtained by summation over all
ωj with j ∈ I \ J. Hence, the claim follows from Theorem (3.19).

3.3 Independence

67

Statement (b) follows in the same way, by using the intersection-stable generator
{]−∞, c] : c ∈ R} of the Borel σ-algebra B (cf. Example (1.8d)), and letting ci → ∞
for j ∈ I \ J. ✸
Note that the cases (a) and (b) in the preceding corollary can in fact both apply at the same
time, namely when each Yi takes values in a countable set i ⊂ R. By Problem 1.4, it then does
not make a difference whether Yi is treated as a random variable with values in (i , P(i )),
or in (R, B), and both criteria in (a) and (b) can be used.
(3.22) Example. Product measures. Let E be a ﬁnite set, ϱ a discrete density on E,
n ≥ 2 and P = ϱ⊗n the n-fold product measure on  = En; this includes the situation
of ordered samples with replacement taken from an urn, where the colours of the balls
are distributed according to ϱ, see Section 2.2.1. Let Xi :  → E be the ith projection.
Then, by deﬁnition, the equation

ϱ(ωi )

j

1 + Z2

P’X1 = ω1, . . . , Xn = ωn( = P’{(ω1, . . . , ωn)}( =

n6i=1
holds for arbitrary ωi ∈ E, and summing over all ωj ∈ E for all
̸= i yields
P(Xi = ωi ) = ϱ(ωi ). So, Corollary (3.21a) shows that, relative to P = ϱ⊗n, the
random variables Xi are independent with distribution ϱ, as one would expect for
sampling with replacement.
(3.23) Example. Polar coordinates of a random point of the unit disc. Let K =
{x = (x1, x2) ∈ R2 : |x| ≤ 1} be the unit disc and Z = (Z1, Z2) a K-valued random
variable (on an arbitrary probability space (, F , P)) with uniform distribution UK
on K. Let R = |Z| = 7Z2
2 and  = arg(Z1 + i Z2) ∈ [0,2π[ be the polar
coordinates of Z. ( is the argument of the complex number Z1 +i Z2, in other words
the angle between the line segment from 0 to Z and the positive half-line.) Then we
have for any 0 ≤ r ≤ 1 and 0 ≤ ψ < 2π
πr2
π

P(R ≤ r,  ≤ ψ) =

ψ

2π = P(R ≤ r ) P( ≤ ψ) .

Thus, by Corollary (3.21b), R and  are independent. In particular,  is uniformly
distributed on [0,2π[, and R2 is uniformly distributed on [0,1].
The next theorem shows that independence is conserved if independent random
variables are grouped into disjoint classes and combined to form new random variables.
Figure 3.6 illustrates the situation.
(3.24) Theorem. Combining independent random variables.
Let (Yi )i∈I be an
independent family of random variables on a probability space (, F , P), so that each
Yi takesvaluesinanarbitraryeventspace (i , Fi ). Let (Ik)k∈K beafamilyofpairwise
disjoint subsets of I, and for k ∈ K, let (8k , 8Fk) be an arbitrary event space and
8Yk := ϕk◦(Yi )i∈Ik forsomerandomvariable ϕk : (%i∈Ik i ,*i∈Ik Fi ) → (8k , 8Fk).
Then the family (8Yk )k∈K is independent.

68

3 Conditional Probabilities and Independence

  ✒
Y1
 
Y2
 ✏✏✏✏✏✶
 
 
PPPPPq
Y3
❅
❅
Y4
❅

❅❅❘

1

2

3

4

⎫⎬⎭
⎫⎬⎭

ϕ1

✲

ϕ2

✲

81

82

Figure 3.6. Disjoint classes of random variables are combined and ‘processed further’.

generator

Proof. For k ∈ K let (<k , <Fk) = (%i∈Ik i ,*i∈Ik Fi )and<Yk := (Yi )i∈Ik :  →<k
be the corresponding vector-valued random variable. <Fk has the intersection-stable
where Xk,i :<k → i denotes the ith projection. We choose a ﬁnite ∅ ̸= L ⊂ K
and, for each k ∈ L, an arbitrary set<Bk =&i∈Jk{Xk,i ∈ Bi} ∈ <Gk (with ﬁnite Jk ⊂ Ik
and Bi ∈ Fi). Then we can write

<Gk ==4i∈J{Xk,i ∈ Bi} : ∅ ̸= J ﬁnite ⊂ Ik, Bi ∈ Fi> ,

P34k∈L{<Yk ∈<Bk}5 = P34k∈L4i∈Jk
= 6k∈L6i∈Jk

{Yi ∈ Bi}5
P(Yi ∈ Bi ) =6k∈L

P(<Yk ∈<Bk );

the last two equalities follow from the independence of (Yi )i∈I. So we conclude from
Theorem (3.19) that (<Yk )k∈K is independent. Consequently, choosing arbitrary sets
8Bk ∈ 8Fk and noting that ϕ−1
k 8Bk ∈ <Fk, we ﬁnd that the product formula (3.18) holds,
in particular, for the events {8Yk ∈ 8Bk} = {<Yk ∈ ϕ−1
k 8Bk}. This means that (8Yk )k∈K is
independent. ✸
(3.25) Example. Partial sums when rolling a die. Let M, N ≥ 2 and let  =
{1, . . . ,6}MN, P = U the uniform distribution, and let Xi :  → {1, . . . ,6} denote
the ith projection. Then, by Example (3.22) and Theorem (3.24), the random variables

kM#i=(k−1)M+1

8Xk =

Xi , 1 ≤ k ≤ N ,

are independent.

3.4 Existence of Independent Random Variables, Product Measures
3.4 Existence of Independent Random Variables,

Product Measures

69

Do independent random variables actually exist? And if so, how can they be con-
structed? We have already seen some examples of ﬁnite families of independent ran-
dom variables. But how about the existence of inﬁnitely many independent random
variables? This question naturally arises when one wants to set up a model for tossing
a coin inﬁnitely often, see Example (1.3). After the negative result in Theorem (1.5)
(where we showed that we cannot simply use the power set as the σ-algebra), we will
now obtain a positive result by using the product σ-algebra. We conﬁne ourselves to
the case of countably many random variables.
(3.26) Theorem. Construction of independent random variables with prescribed dis-
tributions. Let I be a countable index set, and for each i ∈ I let (i , Fi , Pi ) be
an arbitrary probability space. Then there exists a probability space (, F , P) and
independent random variables Yi :  → i with P ◦ Y −1
Proof. Since each subfamily of an independent family of random variables is, by
deﬁnition, independent, we can assume that I is countably inﬁnite, and so (via a
suitable bijection) that I = N. We proceed in stages by distinguishing several cases.
Case 1: All i are countable. Applying Theorem (3.12) to the transition densities
ϱk|ω1,...,ωk−1 (ωk ) = Pk({ωk}) (which do not depend on the conditions), we obtain
random variables Yi = Xi, namely the projections on the product space  =%i∈N i
with a suitable probability measure, that satisfy (3.13). It is then evident that each
Yi has distribution Pi. This in turn implies that equation (3.13), for our choice of
transition densities, is equivalent to the independence criterion in Corollary (3.21a),
and the independence of (Yi )i≥1 follows.
Case 2: For eachi ∈ N, i = [0,1] and Pi = U[0,1]. Since N×N iscountable, the
ﬁrst case provides us with an auxiliary family (Yi,j )i,j≥1 of independent {0,1}-valued
random variables on some suitable (, F , P) so that P(Yi,j = 1) = P(Yi,j = 0) =
1/2. Then, for i ∈ N let

i = Pi for all i ∈ I.

Yi =#j≥1

Yi,j 2−j = ϕ ◦ (Yi,j )j≥1

be the number with binary expansion (Yi,j )j≥1. Here, ϕ(y1, y2, . . . ) =$j≥1 yj 2−j
is the mapping from {0,1}N to [0,1] that assigns to each inﬁnite binary sequence
the corresponding real number. We claim that ϕ is a random variable with respect
to the underlying σ-algebras P({0,1})⊗N and B[0,1].
: {0,1}N →
{0,1} denotes the ith projection and if 0 ≤ m < 2n has the binary expansion m =
$n
k=1 yk 2n−k with yk ∈ {0,1}, then

Indeed, if Xi

ϕ−1? m

2n , m+1

2n @ = {X1 = y1, . . . , Xn = yn} ∈ P({0,1})⊗N ,

70

3 Conditional Probabilities and Independence

and by Remark (1.25) this implies our claim. Furthermore, we have in this case that

P3Yi ∈? m
P3Yi ∈@ m

Case 3: i = R for all i ∈ N.
i = U[0,1].

In particular, letting the intervals shrink to one point shows that P(Yi = m/2n) = 0
for all i, m, n and thus

2n @5 = P(Yi,1 = y1, . . . , Yi,n = yn) = 2−n .
2n , m+1
2n @5 .
2n @5 = 2−n = U[0,1]3@ m
2n , m+1
2n , m+1
The uniqueness theorem (1.12) thus yields the identity P ◦ Y −1
i = U[0,1]. Finally,
Theorem (3.24) implies that the sequence (Yi )i≥1 is independent.
According to the second case, there exist
independent random variables (Yi )i≥1 on a probability space (, F , P) such that
P ◦ Y −1
In fact, we even know that P(0 < Yi <1 for all i ≥ 1) = 1
because U[0,1](]0,1[)=1. According to Proposition (1.30), each probability measure
Pi on (R, B ) is the distribution of a random variable ϕi : ]0,1[ → R, namely the
quantile transformation of Pi; that is, U]0,1[ ◦ ϕ−1
i = Pi. It follows that the family
(ϕi ◦ Yi )i≥1 has the required properties: It is independent by Theorem (3.24), and
P ◦ (ϕi ◦ Yi )−1 = U]0,1[ ◦ ϕ−1
If i = Rd or i is a complete separable metric space, then in
some intricate way it is still possible to ﬁnd a ϕi as in the third case. In the general case,
however, the existence problem cannot be reduced to the existence of the Lebesgue
measure (as was done in the proof of Theorem (3.12) and hence in the particular cases
above), and more measure theory is required. We do not pursue this further because
the particular cases above are all we need later on. The full result can be found in
Durrett [16], Section 1.4.c, or Dudley [15], Theorem 8.2.2. ✸
(3.27) Corollary. Existence of inﬁnite product measures. Let (i , Fi , Pi ), i ∈ I,
be a countable family of probability spaces and  =%i∈I i, F =*i∈I Fi. Then
there is a unique probability measure P on (, F ) that satisﬁes the product formula

General case.

i = Pi.

P(Xi ∈ Ai for all i ∈ J ) =6i∈J

Pi (Ai )

for all ﬁnite ∅ ̸= J ⊂ I and Ai ∈ Fi, which is to say that the projections Xi :  → i
are independent with distribution Pi.
Deﬁnition. P is called the product of the Pi and is denoted by*i∈I Pi or, if Pi = Q
for all i ∈ I, by Q⊗I.
Proof. The uniqueness of P follows from the uniqueness theorem (1.12), since the sets
for i ∈ J} with ﬁnite ∅ ̸= J ⊂ I and Ai ∈ Fi form an intersection-stable
{Xi ∈ Ai
generator of F.
As for the existence, we can apply Theorem (3.26) to obtain independent random
variables (Yi )i∈I deﬁned on a probability space (′, F ′, P′) such that P′ ◦Y −1
i = Pi.

71
3.4 Existence of Independent Random Variables, Product Measures
Then, Y = (Yi )i∈I : ′ →  is a random variable. Indeed, for each ﬁnite ∅ ̸= J ⊂ I
and all Ai ∈ Fi we have

Y −1

{Xi ∈ Ai for i ∈ J} = {Yi ∈ Ai for i ∈ J} ∈ F ′ ,

whence our claim follows from Remark (1.25). So the distribution P = P′ ◦ Y −1 of
Y is well-deﬁned, and
P(Xi ∈ Ai for i ∈ J ) = P′(Yi ∈ Ai for i ∈ J ) =6i∈J
Pi (Ai ) .

P′(Yi ∈ Ai ) =6i∈J

Thus P has the required property. ✸

As the above proof shows, the concepts of independence and product measure are

closely related:
(3.28) Remark.
Independence as a property of distributions. A countable family
(Yi )i∈I of random variables taking values in arbitrary event spaces (i , Fi ) is inde-
pendent if and only if

P ◦ (Yi )−1

i∈I =Ai∈I

P ◦ Y −1
i

,

.

or, in words, if the joint distribution of the Yi (namely the distribution of the random
vector Y = (Yi )i∈I with values in%i∈I i) coincides with the product of the single
distributions P ◦ Y −1
i
The typical case of interest is when all random variables have the same distribution.
(3.29) Example and Deﬁnition: Canonical product models and the Bernoulli mea-
sures. Let I = N and (i , Fi , Pi ) = (E, E , Q) for each i ∈ N. Then, by Corollary
(3.27), one can deﬁne the inﬁnite product probability space (E N, E ⊗N, Q⊗N), which
serves as the so-called canonical model for the inﬁnite independent repetition of an
experiment described by (E, E , Q). The outcomes of the single experiments are then
described by the projection variables Xi :  → E onto the ith coordinate, and these
are independent with identical distribution Q. As such sequences of random variables
are a basic and frequent ingredient of stochastic modelling, it is common to use the
abbreviation i.i.d. for independent and identically distributed.
In the case E = {0,1} and Q({1}) = p ∈ ]0,1[, the product measure Q⊗N
is called the (inﬁnite) Bernoulli measure or Bernoulli distribution on {0,1}N with
probability p of success; its existence on the product σ-algebra P({0,1})⊗N is the
positive counterpart of the ‘no-go theorem’ (1.5). Likewise, a sequence (Yi )i≥1 of
{0,1}-valued random variables is called a Bernoulli sequence with parameter p if it
has the joint distribution Q⊗N, in other words if
P(Yi = xi for all i ≤ n) = p$n

for all n ≥ 1 and xi ∈ {0,1}. The joint distributionof (Y1, . . . , Yn) is then the Bernoulli
distribution on the ﬁnite product {0,1}n, as introduced in Section 2.2.1.

i=1 xi (1 − p)$n

i=1(1−xi )

72

3 Conditional Probabilities and Independence

ϱ(x) :=

Finite products of probability measures on R have a density if and only if all factor
measures have a density. More precisely, the following holds.
(3.30) Example. Product densities. For each 1 ≤ i ≤ n, let Pi be a probability mea-
sure on (R, B) with existing Lebesgue density ϱi. Then the (ﬁnite) product measure
P =*n
i=1 Pi on (Rn, Bn) is precisely the probability measure with Lebesgue density
n6i=1
ϱi (xi )
Indeed, for arbitrary ci ∈ R we have
n6i=1
P(X1 ≤ c1, . . . , Xn ≤ cn) =
= B c1
ϱ(x) dx ;
the third equality is justiﬁed by Fubini’s theorem for multiple integrals, see for instance
[52]. Hence, by the uniqueness theorem (1.12), we ﬁnd that P(A) =CA ϱ(x) dx for
all A ∈ Bn. (Note that an inﬁnite product measure does not admit a density, even if
all factors do. This follows already from the fact that there is no Lebesgue measure
on RN.)

for x = (x1, . . . , xn) ∈ Rn.
n6i=1B ci

ϱ1(x1) . . . ϱn(xn) dx1 . . . dxn = B{X1≤c1,...,Xn≤cn}

Pi (]−∞, ci]) =

ϱi (xi ) dxi

. . .B cn

−∞

−∞

−∞

We conclude this section by introducing the notion of convolution, which is closely
related to that of a product measure. As a motivation, let Y1 and Y2 be two independent
real-valued random variables with distributions Q1 and Q2, respectively. Then, by
Remark (3.28), the pair (Y1, Y2) has distribution Q1⊗Q2 on R2. On the other hand, the
sum Y1 +Y2 arises from the pair (Y1, Y2) by applying the addition map A : (x1, x2) →
x1 + x2 from R2 to R. That is, Y1 +Y2 = A◦ (Y1, Y2). Hence, Y1 +Y2 has distribution
(Q1 ⊗ Q2) ◦ A−1. (Note that A is continuous, and thus a random variable by (1.27).)
Deﬁnition. For any two probability measures Q1, Q2 on (R, B ), the probability
measure Q1 ⋆ Q2 := (Q1 ⊗ Q2) ◦ A−1 on (R, B ) is called the convolution of Q1
and Q2.
In other words, Q1 ⋆ Q2 is the distribution of the sum of any two independent
random variables with distributions Q1 and Q2 respectively. In the case of probability
measures with densities, the convolution also has a density:
(3.31) Remark. Convolution of densities. In the setting of the previous deﬁnition, the
following holds:

(a) Discrete case.

If Q1 and Q2 are probability measures on (Z, P(Z)) with asso-
ciated discrete densities ϱ1 and ϱ2 respectively, then Q1 ⋆ Q2 is the probability
measure on (Z, P(Z)) with discrete density

ϱ1 ⋆ ϱ2(k) :=#l∈Z

ϱ1(l) ϱ2(k−l) ,

k ∈ Z.

3.5 The Poisson Process

73

(b) Continuous case.

If Q1 and Q2 each have a Lebesgue density ϱ1 and ϱ2

respectively, then Q1 ⋆ Q2 has the Lebesgue density

ϱ1 ⋆ ϱ2(x) :=B ϱ1(y) ϱ2(x−y) dy ,

x ∈ R.

Proof. In case (a) we have for any k ∈ Z

ϱ1(l1) ϱ2(l2) = ϱ1 ⋆ ϱ2(k) .

Q1 ⊗ Q2(A = k) = #l1,l2∈Z:l1+l2=k
In case (b), we use Example (3.30), apply the substitutions x1 " y, x2 " x =
y + x2, and interchange the integrals to ﬁnd
Q1 ⊗ Q2(A ≤ c) =B dy ϱ1(y)B dx ϱ2(x − y)1{x≤c} =B c
−∞
for arbitrary c ∈ R. The result then follows from Remark (1.31). ✸
One instance are the normal distributions.
(3.32) Example. Convolution of normal distributions. For each m1, m2 ∈ R and
v1, v2 > 0, we have Nm1,v2 ⋆ Nm2,v2 = Nm1+m2,v1+v2. That is, the convolution of
normal distributions is normal, and the parameters simply add up. One thus says that
the normal distributions form a two-parameter convolution semigroup. For the proof,
assume without loss of generality that m1 = m2 = 0. A short calculation then shows
that, for every x, y ∈ R,

In a few important cases, the type of distribution is preserved under convolution.

ϱ1 ⋆ ϱ2(x) dx

φ0,v1 (y) φ0,v2 (x − y) = φ0,v1+v2 (x) φxu,v2u(y) ,

where u = v1/(v1 + v2). Applying Remark (3.31b) and integrating over y, the claim
follows.
Further examples of convolution semigroups follow in Corollary (3.36), Prob-

lem 3.15, and Section 4.4.

3.5 The Poisson Process
Let us return to the model of random points on the time axis that was discussed in
Sections 2.4 and 2.5.2. The existence of inﬁnitely many independent random variables
withgivendistributionnowallowsustospecifythismodelinmoredetail. FromSection
2.5.2 we know that the waiting time for the ﬁrst point has an exponential distribution,
and the heuristic in Section 2.4 suggests that the gaps between two consecutive points
are independent. Hence we use the following approach.

74

3 Conditional Probabilities and Independence
Let α > 0 and (Li )i≥1 be a sequence of i.i.d. random variables that are exponen-
tially distributed with parameter α; Theorem (3.26) guarantees the existence of such
a sequence on a suitable probability space (, F , P). We interpret Li as the gap
between the (i − 1)st and the ith point; then Tk =$k
i=1 Li is the kth random point in
time; cf. Figure 3.7. Let
1]0,t](Tk )
(3.33)

Nt =#k≥1

be the number of points in the interval ]0, t]. Thus, for s < t, Nt − Ns is the number
of points in ]s, t].
EF

•D EF G
Figure 3.7. Deﬁnition of the Poisson process Nt. The gaps Li are independent and
exponentially distributed. For t ∈ [Tk , Tk+1[ one has Nt = k.

•D EF GL3

•DEFGL2

•DEFGL6

0

|D

T3

•D

T1

T2

T4

G

L4

EF

T5

T6
•

L1

G

✲

L5

(3.34) Theorem. Construction of the Poisson process. The Nt are random variables,
and, for 0 = t0 < t1 < ··· < tn, the increments Nti − Nti−1 are independent and
Poisson distributed with parameter α(ti − ti−1), 1 ≤ i ≤ n.
Deﬁnition. A family (Nt )t≥0 of random variables satisfying the properties in Theo-
rem (3.34) is called a Poisson process with intensity α > 0.
TheindependenceofthenumberofpointsindisjointintervalsshowsthatthePoisson
process does indeed provide a model of time points that are arranged as randomly as
possible. Oneshouldnoteatthisstagethattherelation(3.33)canbeinvertedbywriting
Tk = inf{t > 0 : Nt ≥ k} for k ≥ 1. In other words, Tk is the kth time point at which
the ‘sample path’ t → Nt of the Poisson process performs a jump of size 1. The times
Tk are therefore also called the jump times of the Poisson process, and (Nt )t≥0 and
(Tk )k∈N are two manifestations of the same mathematical object.
Proof. Since {Nt = k} = {Tk ≤ t < Tk+1} and the Tk are random variables by
Problem 1.13, every Nt is a random variable. For the main part of the proof, we
conﬁne ourselves to the case n = 2 to keep the notation simple; the general case
follows analogously. So let 0 < s < t, k,l ∈ Z+. We show that
k! 53e−α(t−s) (α(t − s))l
5 .
(3.35)
l!
For, summing over l and k, respectively, we can then conclude that Ns and Nt − Ns
are Poisson distributed, and their independence follows from Corollary (3.21a). By
Example (3.30), the (joint) distribution of (Lj )1≤j≤k+l+1 has the product density

P(Ns = k, Nt − Ns = l) =3e−αs (αs)k

x = (x1, . . . , xk+l+1) → αk+l+1 e−ατk+l+1(x) ,

75

3.5 The Poisson Process
where we set τj (x) = x1 + ··· + xj. Thus, in the case l ≥ 1 we can write

P(Ns = k, Nt − Ns = l) = P(Tk ≤ s < Tk+1 ≤ Tk+l ≤ t < Tk+l+1)
= B ∞

dx1 . . . dxk+l+1 αk+l+1 e−ατk+l+1(x)
· 1
{τk(x) ≤ s < τk+1(x) ≤ τk+l (x) ≤ t < τk+l+1(x)} ,

. . .B ∞

0

0

and for l = 0 we obtain an analogous formula. We integrate stepwise starting from
the innermost integral and moving outwards. For ﬁxed x1, . . . , xk+l, the substitution
z = τk+l+1(x) yields

B ∞

0

dxk+l+1 αe−ατk+l+1(x)1{τk+l+1(x)>t} =B ∞

t

dz αe−αz = e−αt .

Next, we ﬁx x1, . . . , xk and make the substitutions y1 = τk+1(x) − s, y2 = xk+2, . . .,
yl = xk+l to obtain
B ∞
. . .B ∞
=B ∞

dxk+1 . . . dxk+l 1{s<τk+1(x)≤τk+l (x)≤t}
. . .B ∞
dy1 . . . dyl 1{y1+···+yl≤t−s} =

The last equality can be proved by induction on l. (In the case l = 0, this integral does
not appear and can formally be set equal to 1.) For the remaining integral, we ﬁnd in
the same way that

(t − s)l
l!

0

0

0

0

.

0
Combining everything, we obtain

0

. . .B ∞

B ∞
dx1 . . . dxk 1{τk (x)≤s} =
P(Ns = k, Nt − Ns = l) = e−αt αk+l sk
k!

.

sk
k!
(t − s)l
l!

and hence (3.35). ✸

The Poisson process is the prototypical stochastic model for time points that are
purely random.
It is the rigorous version of the heuristic approach in Section 2.4.
Along the way, it provides us with two further examples of convolution semigroups.
(3.36) Corollary. Convolution of Poisson and gamma distributions. The convolution
formulas Pλ ⋆ Pµ = Pλ+µ and Γα,r ⋆ Γα,s = Γα,r+s are valid for arbitrary parameters
λ, µ > 0 and α > 0, r, s ∈ N, respectively.
Proof. Let (Nt )t≥0 be the Poisson process with parameter α > 0 as constructed
above, and suppose ﬁrst that α = 1. By Theorem (3.34), the random variables Nλ and
Nλ+µ − Nλ are independent with distribution Pλ and Pµ respectively, and their sum
Nλ+µ has distribution Pλ+µ. This proves the ﬁrst claim.

76

3 Conditional Probabilities and Independence
i=1 Li the rth point of the Poisson process.
As a sum of r independent exponentially distributed random variables, Tr has the
distribution E ⋆r

Now let α be arbitrary and Tr = $r

α . On the other hand, we have for any t > 0

P(Tr ≤ t) = P(Nt ≥ r ) = 1 − Pαt ({0, . . . ,r − 1}) = Γα,r (]0, t]) .

r and s, see Problem 3.15 and Corollary (9.9).

Here, the ﬁrst equality follows from the deﬁnition of Nt, the second from Theo-
α = Γα,r, which implies the second
rem (3.34), and the third from (2.19). Hence, E ⋆r
claim. ✸
In fact, it is easy to verify that the relation Γα,r ⋆ Γα,s = Γα,r+s also holds for non-integer
As one of the basic models of stochastics, the Poisson process is the starting point
for a large variety of modiﬁcations and generalisations. Here, we will only mention
two examples.
(3.37) Example. The compound Poisson process. Let (Nt )t≥0 be a Poisson process
with intensity α > 0. As noticed above, the sample path t → Nt (ω) associated with
any ω ∈  is a piecewise constant function, which performs a jump of height 1 at the
times Tk(ω), k ≥ 1. We now modify the process by allowing the jump heights to vary
randomly as well.
Let (Zi )i≥1 be a sequence of real random variables, which are independent of each
other as well as of (Nt )t≥0, and identically distributed according to Q on (R, B ).
(Such random variables exist by Theorem (3.26).) The process (St )t≥0 deﬁned by

St =

Zi ,

t ≥ 0,

Nt#i=0

is then called the compound Poisson process with jump distribution Q and intensity α.
If each Zi ≥ 0, this process models, for example, the evolution of collective claims
arriving at an insurance company. The ith claim arrives at the ith jump time Ti of the
Poisson process (Nt ), and Zi is its amount. On the other hand, the regular premium
income of the insurance company leads to a continuous increase in capital with rate
c > 0. The net loss of the insurance company in the interval [0, t] is thus described
by the process Vt = St − ct, t ≥ 0. This is the basic model of risk theory. Of special
interest is the ‘ruin probability’r (a) = P(supt≥0 Vt > a), which is the probability that
the total loss exceeds the capital reserve a > 0 at some time. To ﬁnd the supremum
over all Vt, it is clearly sufﬁcient to consider only the jump times Tk. Using the Li
from Figure 3.7, we can therefore rewrite the ruin probability as

r (a) = P3 sup

k≥1

k#i=1
(Zi − cLi ) > a5 .

Moreonthistopiccanbefoundforinstancein[19], SectionsVI.5andXII.5. Figure3.8
shows a simulation of (Vt )t≥0.

3.5 The Poisson Process

77

0

5

10

15

20

25

Figure 3.8. Simulation of the ruin process (Vt ) for Q = U]0,1[, α = 2, c = 1.1.

(3.38) Example. The Poisson point process in R2. Up to now, the Poisson process
served as a model for random times in [0,∞[. In many applications, however, there is
also an interest in random points in higher-dimensional spaces. Think for instance of
the particle positions in an ideal gas, or the positions of the pores in a liquid ﬁlm. Here
we conﬁne ourselves to two dimensions and consider random points in a ‘window’
 = [0, L]2 of the plane. Let α > 0 and (Nt )t≥0 be a Poisson process with intensity
αL and jump times (Tk)k≥1. Also, let (Zi )i≥1 be a sequence of i.i.d. random variables
with uniform distribution U[0,L] on [0, L], which is independent of the Poisson process.
Then, the random set of points

ξ =+ (Tk, Zk ) : 1 ≤ k ≤ NL,

is called the Poisson point process on  with intensity α. (For an alternative construc-
tion of ξ see Problem 3.25.) As a variation of this model, one can draw a circle with
random radius Rk > 0 around each point (Tk , Zk ) ∈ ξ. The union of these circles
then forms a random set , which is called the Boolean model and is used in stochastic
geometry as a basic model of random structures. More on this can be found for instance
in [46, 58]. Two simulated realisations of  for different intensities are presented in
Figure 3.9.

Figure 3.9. Simulations of the Boolean model for L = 15, Rk = 0.5, and α = 0.8 and 2,
respectively.

3 Conditional Probabilities and Independence

78
3.6 Simulation Methods
When developing a stochastic model for a speciﬁc application, one would often like
to get a ﬁrst impression of how the model behaves and if it exhibits the phenomena
one expects. To this end, ‘experimental stochastics’ provides the useful tool of Monte
Carlo simulation; we have seen two examples in Figures 3.8 and 3.9. In the following,
we will present a few fundamental simulation methods.
Recall the proof of Theorem (3.26), which provided us with more than just the
existence of independent random variables. In its second case, we saw how to construct
independent U[0,1]-distributed random variables from a Bernoulli sequence (using the
binary expansion), and in its third case, how to use these in combination with the
quantile transformation (1.30) to generate random variables with arbitrary distribution
in R. These were two examples of the general problem: How can one transform a
givenfamilyofknownrandomvariablesintonewrandomvariableswithcertaindesired
properties? This is, in fact, the central question in computer simulation as well, where
one starts with a sequence of i.i.d. random variables with uniform distribution on [0,1]
and uses them to construct new random variables with prescribed distributions. We will
demonstrate this by means of several examples. We start with two simple applications
of the quantile transformation, which is also known as the inversion method in this
context.
(3.39) Example. Sampling from binomial distributions. Let 0 < p <1 and U1, . . . ,Un
be independent U[0,1]-distributed random variables. By Theorem (3.24), the random
variables Xi = 1{Ui≤p} then form a Bernoulli sequence with parameter p. Theorem
(2.9)thusimpliesthatthesum S =$n
i=1 Xi hasthebinomialdistribution Bn,p. (Check
that the construction of Xi is a special case of the quantile transformation.)
(3.40) Example. Sampling from exponential distributions. Let Ui, i ≥ 1, be i.i.d.
U[0,1]-distributed random variables and α > 0. Then the random variables Xi =
(−logUi )/α are exponentially distributed with parameter α (and by Theorem (3.24)
also independent). To see this, observe that P(Xi ≥ c) = P(Ui ≤ e−αc) = e−αc for
every c > 0. (Again, the reader should check that this is a simple modiﬁcation of the
quantile transformation.)

If we combine the last example with the construction of the Poisson process in The-
orem (3.34), we obtain a convenient method of simulating Poisson random variables.
(3.41) Example. Sampling from Poisson distributions. Let Ui, i ≥ 1, be independent
U[0,1]-distributed random variables. By the previous example, the random variables
Li = −logUi are then independent and exponentially distributed with parameter 1.
Writing Tk =$k
i=1 Li for the kth partial sum and applying Theorem (3.34), we thus
see that for every λ > 0 the random variable

Nλ = min{k ≥ 0 : Tk+1 > λ} = min{k ≥ 0 : U1 . . .Uk+1 < e−λ}

3.6 Simulation Methods

79

(Here, U stands for a uniform random number
in [0,1] that is generated afresh at each call.)

(which coincides with the quantity in (3.33)) is Pλ-distributed. This yields the follow-
ing algorithm to simulate a Poisson distributed random variable Nλ, which is speciﬁed
in pseudocode here:
v ← 1, k ← −1
repeat v ← U v, k ← k + 1
until v < e−λ
Nλ ← k
Unfortunately, theinversionmethodisnotalwaysfeasible, namelywhenthedesired
distribution function is not accessible numerically. In such cases, the following general
principle, which goes back to J. von Neumann (1903–1957), provides an alternative.
(3.42) Example. Rejection sampling and conditional distributions. Let (Zn)n≥1 be an
i.i.d. sequence of random variables on a probability space (, F , P) taking values in
an arbitrary event space (E, E ), and Q their identical distribution, i.e., P ◦ Z−1
n = Q
for all n. Let B ∈ E be an event such that Q(B) > 0. How can we construct a random
variable Z∗ with the conditional distribution Q(·| B), using only the Zn ? The basic
idea is as follows: Observe the Zn one after the other, ignore all n with Zn ̸∈ B, and
then set Z∗ = Zn for the ﬁrst n with Zn ∈ B. More precisely, let

τ = inf{n ≥ 1 : Zn ∈ B}

be the ﬁrst hitting time of B or, put differently, the time of the ﬁrst success of the
Bernoulli sequence 1B (Zn), n ≥ 1. From Section 2.5.1 we know that τ − 1 has the
geometric distribution with parameter p = Q(B). In particular, P(τ < ∞) = 1,
which means that the hypothetical case that Zn ̸∈ B for all n, and thus τ = ∞, only
occurs with probability zero. Deﬁne Z∗ = Zτ, i.e., Z∗(ω) = Zτ (ω)(ω) for all ω with
τ (ω) < ∞. (To be formal, one can set Z∗(ω) = Z1(ω) for the remaining ω, which do
not play any role.) It then follows that for all A ∈ E
∞#n=1
P’Zn ∈ A, τ = n(
∞#n=1
P’Z1 ̸∈ B, . . . , Zn−1 ̸∈ B, Zn ∈ A ∩ B(
∞#n=1
(1 − Q(B))n−1 Q(A ∩ B) = Q(A|B) ,

P(Z∗ ∈ A) =

=

=

which shows that Z∗ has distribution Q(·|B).
with a speciﬁed distribution density.

The rejection sampling method can be used as follows to simulate a random variable

80

3 Conditional Probabilities and Independence
(3.43) Example. Monte-Carlo simulation via rejection sampling.
Let [a, b] be a
compact interval and ϱ a probability density function on [a, b]. Suppose ϱ is bounded,
so there exists a c > 0 with 0 ≤ ϱ(x) ≤ c for all x ∈ [a, b]. Let Un, Vn, n ≥ 1, be
i.i.d. with uniform distribution U[0,1]. Then the random variables
Zn = (Xn, Yn) := (a + (b − a)Un, cVn)

are independent with uniform distribution U[a,b]×[0,c]. Let
τ = inf+n ≥ 1 : Yn ≤ ϱ(Xn),

and Z∗ = (X∗, Y ∗) = (Xτ , Yτ ). Example (3.42) then tells us that Z∗ is uniformly
distributed on B = {(x, y) : a ≤ x ≤ b, y ≤ ϱ(x)}. Consequently, for all A ∈ B[a,b],
we can write

P(X∗ ∈ A) = UB’(x, y) : x ∈ A, y ≤ ϱ(x)( =BA

ϱ(x) dx ,

where the last equality follows from Fubini’s theorem. This shows that X∗ has distribu-
tion density ϱ. The construction of X∗ corresponds to the following simple algorithm
written in pseudocode as follows.

repeat u ← U , v ← V
(At each call, U, V ∈ [0,1] are two fresh random
samples from U[0,1], which are independent of
until cv ≤ ϱ(a + (b − a)u)
each other and of everything else before.)
X∗ ← cv
(If ϱ is a discrete density on a ﬁnite set {0, . . . , N − 1}, we obtain an analogous
algorithm by considering the Lebesgue density x → ϱ(⌊x⌋) on the interval [0, N[.)
Combining rejection sampling with a suitable transformation, one can simulate
random variables with normal distributions.
(3.44) Example. Polar method for sampling from normal distributions. Let K =
{x ∈ R2 : |x| ≤ 1} be the unit disc and Z = (Z1, Z2) a K-valued random variable
with uniform distribution UK on K; for instance, one can use rejection sampling as
in Example (3.42) to obtain Z from a sequence of random variables with uniform
distribution on [−1,1]2. Let

X = (X1, X2) := 2H−log|Z|

Z
|Z|

.

Then the coordinate variables X1 and X2 are independent and N0,1-distributed.
To see this, consider the polar coordinates R,  of Z. As was shown in Example
(3.23), R2 and  are independent with distribution U[0,1] resp. U[0,2π[. Let S =
H−2 log R2. By Theorem (3.24), S and  are independent. Moreover, S has the
distribution density s → s e−s2/2 on [0,∞[ because
≥ e−c2/2) = 1 − e−c2/2

P(S ≤ c) = P(R2

s e−s2/2 ds

=B c

0

P(X ∈ A) =
=

1

dϕB ∞

2π B 2π
2π B dx1B dx2 e−(x2

1

ds s e−s2/2 1A(s cos ϕ, s sin ϕ)

0

0

81
3.6 Simulation Methods
for all c > 0. Now, obviously, X = (S cos , S sin ). Hence, for any A ∈ B2
transforming polar into Cartesian coordinates yields

2 )/2 1A(x1, x2) = N0,1 ⊗ N0,1(A);
the last equality comes from Example (3.30). Remark (3.28) thus gives the result.
code) for generating two independent standard normal random variables X1, X2.

The above construction yields the following algorithm (again written in pseudo-

1+x2

repeat

(At each call, U, V ∈ [0,1] are
fresh and independent random
samples from U[0,1].)

u ← 2U − 1, v ← 2V − 1, w ← u2
+ v2
until w ≤ 1
a ←H(−2 log w)/w, X1 ← au, X2 ← av
Each of the previous examples has presented a method to construct new random
variables with a desired distribution from independent uniform random numbers in
[0,1]. All these methods reduce the problem of simulating speciﬁc random variables
to the simulation of independent U[0,1]-variables. But how can the latter problem be
solved? This is the subject of our concluding remark.
(3.45) Remark. Random numbers. Random realisations of independent U[0,1]-
distributed random variables are called random numbers. They can be found in tables
or on the internet. Partly, these are generated by real chance, see e.g. http://www.
rand.org/pubs/monograph_reports/MR1418/index.html.
In practice, how-
ever, it is common to use so-called pseudo-random numbers, which are not random
at all, but produced deterministically. A standard method to generate pseudo-random
numbers is the following linear congruence method.
Choose a ‘modulus’ m (for example m = 232) as well as a factor a ∈ N and an
increment b ∈ N (this requires a lot of skill). Next, pick a ‘seed’ k0 ∈ {0, . . . , m − 1}
(e.g., tied to the internal clock of the processor), and deﬁne the recursive sequence
ki+1 = a ki + b mod m. The pseudo-random numbers then consist of the sequence
ui = ki /m, i ≥ 1. For an appropriate choice of a, b, the sequence (ki ) has period
m (so it does not repeat itself after fewer iterations), and it survives several statistical
tests of independence. (For example, this is the case for a = 69069, b = 1; Marsaglia
1972.) Pseudo-random variables are readily available as a standard feature of many
compilers and software packages – but the user still has the responsibility to check
whether they are suitable for the speciﬁc application at hand. It is a nice anecdote that
the random generator randu by IBM, which was widely distributed in the 1960s, has
the property that, for a = 65539, b = 0, m = 231 and period 229, the consecutive
triples (ui , ui+1, ui+2) lie in only 15 different parallel planes of R3, which is certainly
not a characteristic of randomness! In fact, the existence of such grid structures is
an inevitable consequence of the linear nature of the method; the art is to make them
sufﬁciently ﬁne. A standard reference on pseudo-random numbers is Knuth [36].

3 Conditional Probabilities and Independence

82
3.7 Tail Events
The existence of inﬁnite models, as discussed above in Theorems (3.12) and (3.26), is
not only of theoretical interest. It also opens up some new perspectives, since it allows
us to deﬁne and describe events that capture the long-term behaviour of a random
process. Let (, F , P) be a probability space and (Yk )k≥1 a sequence of random
variables on (, F ) with values in arbitrary event spaces (k , Fk ).
Deﬁnition. An event A ∈ F is called an asymptotic or tail event for (Yk )k≥1 if, for
every n ≥ 0, A depends only on (Yk )k>n, in that there exists an event Bn ∈*k>n Fk
such that
(3.46)
Let T (Yk : k ≥ 1) be the collection of all such tail events.
We immediately note that T (Yk : k ≥ 1) is a sub-σ-algebra of F; it is called the
asymptotic or tail σ-algebra of the sequence (Yk )k≥1. Naively, one might think: Since
an event A ∈ T (Yk : k ≥ 1) cannot depend on Y1, . . . , Yn and this is true for all n, A
‘cannot depend on anything’, and so one could conclude that A =  or A = ∅. This
kind of reasoning, however, is completely mistaken! In fact, T (Yk : k ≥ 1) contains
a particularly interesting class of events, namely those that describe the asymptotic
behaviour of (Yk )k≥1. To see this, consider the following examples.
(3.47) Example. Lim sup of events. For arbitrary Ak ∈ Fk let

A = {(Yk )k>n ∈ Bn} .

A = {Yk ∈ Ak for inﬁnitely many k} = 4m≥1Ik≥m{Yk ∈ Ak} .

In view of the relation 1A = lim supk→∞
1{Yk∈Ak} for the indicator functions, one
writes A = lim supk→∞ {Yk ∈ Ak} and calls A the lim sup of the events {Yk ∈ Ak}.
Alternatively, one writes A = {Yk ∈ Ak i.o.}, where ‘i.o.’ stands for ‘inﬁnitely often’.
Now, whether or not something happens inﬁnitely often does not depend on the ﬁrst
n instances. In other words, every such A is a tail event for (Yk )k≥1. To check this
formally, take any n ≥ 0 and let Xi :%k>n k → i be the projection onto the ith
coordinate. Then the event

Bn = 4m>nIk≥m{Xk ∈ Ak}

belongs to*k>n Fk, and (3.46) holds.
(3.48) Example. Existence of long-term averages. Let (k , Fk ) = (R, B ) for all k,
and a < b. Then the event
N#k=1

Yk exists and belongs to [a, b]>

A == lim

N→∞

1
N

83
3.7 Tail Events
is a tail event for (Yk )k≥1. This is because the existence and the value of a long-term
average is not affected by a shift of all indices, so that (3.46) holds for the events

Bn == lim

N→∞

1
N

N#k=1

Xn+k exists and is in [a, b]>;

C = {X1 ∈ C1, . . . , Xn ∈ Cn} , n ≥ 1, Ck ∈ Fk.

here, Xi :%k>n R → R is again the ith projection. It only remains to be observed
that Bn does indeed belong to*k>n B; recall Problem 1.13.
Quite remarkably, if the random variables (Yk )k≥1 are independent, it turns out that
theeventsin T (Yk : k ≥ 1)(althoughfarfrombeingtrivialingeneral)arenevertheless
‘trivial in probability’.
(3.49) Theorem. Kolmogorov’s zero-one law. Let (Yk )k≥1 be independent random
variables on a probability space (, F , P) with values in arbitrary event spaces
(k , Fk ). Then, for every A ∈ T (Yk : k ≥ 1), either P(A) = 0 or P(A) = 1.
Proof. Fix A ∈ T (Yk : k ≥ 1) and let G be the collection of all sets C ⊂%k≥1 k
of the form
Then G is an intersection-stable generator of*k≥1 Fk; see the analogous result in
Problem 1.5. For C = {X1 ∈ C1, . . . , Xn ∈ Cn} ∈ G , Theorem (3.24) implies that the
indicator function 1{(Yk )k≥1∈C} =%n
k=1 1Ck (Yk ) is independent of 1A = 1{(Yk )k>n∈Bn}.
Hence, by Theorem (3.19) it follows that (Yk )k≥1 is independent of 1A . Thus, A =
{(Yk )k≥1 ∈ B0} is independent of A = {1A = 1}, which means that P(A ∩ A) =
P(A)P(A) and thus P(A) = P(A)2. But the equation x = x2 only admits the
solutions 0 and 1. ✸
Knowingthatataileventforanindependentsequenceiseithercertainorimpossible,
one would like to decide which of these alternatives is true. In general, this can only
be done ad hoc as the case arises. For events as in Example (3.47), however, an easy
criterion is available.
(3.50) Theorem. Borel–Cantelli lemma, 1909/1917. Let (Ak)k≥1 be a sequence of
events in a probability space (, F , P), and consider

A := {ω ∈  : ω ∈ Ak for inﬁnitely many k} = lim sup
k→∞

Ak.

(a) If $k≥1 P(Ak) < ∞, then P(A) = 0.
(b) If $k≥1 P(Ak) = ∞ and (Ak )k≥1 is independent, then P(A) = 1.
Proof. (a) We have that A ⊂"k≥m Ak and thus P(A) ≤$k≥m P(Ak ) for all m. The
last sum is the tail of a convergent series, and thus tends to 0 as m → ∞.

Note that no independence is required for statement (a).

84

3 Conditional Probabilities and Independence

Ac

k, we can write

(b) Since Ac ="m≥1&k≥m Ac
k5 =#m≥1
P3&k≥m
limn→∞
n6k=m[1 − P(Ak)]
limn→∞
expJ−
limn→∞

P(Ac) ≤ #m≥1
= #m≥1
≤ #m≥1

P3 n&k=m

Ac

k5

n$k=m

0 = 0 ,

k )k≥1 are
The Borel–Cantelli lemma will become important later on in Sections 5.1.3 and

P(Ak)K =#m≥1
provided$k≥1 P(Ak) = ∞. Here we have used that the complements (Ac
independent by Corollary (3.20), and that 1 − x ≤ e−x. ✸
6.4. At this point, we will only present a simple application to number theory.
(3.51) Example. Divisibility by prime numbers. For each prime p let Ap be the set
containing all multiples of p. Then there is no probability measure P on (N, P(N))
for which the events Ap are independent with P(Ap) = 1/p. Indeed, suppose there
were such a P. Since$p prime 1/p = ∞, part (b) of the Borel–Cantelli lemma would
then imply that the impossible event

A = {n ∈ N : n is a multiple of inﬁnitely many primes}

had probability 1.
Problems
3.1. A shop is equipped with an alarm system which in case of a burglary alerts the police with
probability 0.99. During a night without a burglary, a false alarm is set off with probability 0.002
(e.g. by a mouse). The probability of a burglary on a given night is 0.0005. An alarm has just
gone off. What is the probability that there is a burglary going on?
3.2. Prisoners’ paradox. Three prisoners Andy, Bob and Charlie are sentenced to death. By
drawing lots, where each had the same chance, one of the prisoners was granted pardon. The
prisoner Andy, who has a survival probability of 1/3, asks the guard, who knows the result, to tell
him which of his fellow sufferers has to die. The guard answers ‘Bob’. Now Andy calculates:
‘Since either me or Charlie are going to survive, I have a chance of 50%.’ Would you agree
with him? (For the construction of the probability space, suppose that the guard answers ‘Bob’
or ‘Charlie’ with equal probability, if he knows that Andy has been granted pardon.)
3.3. You are ﬂying from Munich to Los Angeles and stop over in London and New York. At
eachairport, includingMunich, yoursuitcasemustbeloadedontotheplane. Duringthisprocess,
it will get lost with probability p. In Los Angeles you notice that your suitcase hasn’t arrived.
Find the conditional probability that it got lost in Munich, resp. London, resp. New York. (As
always, a complete solution includes a description of the probability model.)

Problems

85

3.4. Beta-binomial representation of the Pólya distribution. Consider Pólya’s urn model with
parameters a = r/c > 0 and b = w/c > 0. Let Rn be the number of red balls obtained in n
draws. Use the recursive formula (2.23) to show that

P(Rn = ℓ) =B 1

0

dp βa,b(p) Bn,p({ℓ})

for all 0 ≤ ℓ ≤ n. (Hence, the Pólya model is equivalent to an urn model with replacement
where the initial ratio between red and white balls was determined by ‘chance’ according to a
beta distribution.)
3.5. Generalise Pólya’s urn model to the case when the balls can take colours from a ﬁnite
set E (instead of only red and white), and ﬁnd the distribution of the histogram Rn after n
draws; cf. equation (2.7). Can you also generalise the previous Problem 3.4 to this case? (The
corresponding generalisation of the beta distribution is called the Dirichlet distribution.)
3.6. Let (, F , P) be a probability space and A, B,C ∈ F. Show directly (without using
Corollary (3.20) and Theorem (3.24)):
If A, B are independent, then so are A, Bc.
(a)
(b)
If A, B,C are independent, then so are A ∪ B, C.
3.7.
In number theory, Euler’s ϕ-function is deﬁned as the mapping ϕ : N → N such that
ϕ(1) = 1 and ϕ(n) = the number of integers in n = {1, . . . , n} that are relatively prime to n,
if n ≥ 2. Show that if n = pk11 . . . pkmm is the prime factorisation of n into pairwise distinct
primes p1, . . . , pm with powers ki ∈ N, then
ϕ(n) = n11 −

pm2 .
Hint: Consider the events Ai = {pi ,2pi ,3pi , . . . , n}, 1 ≤ i ≤ m.
3.8. Let X be a real-valued random variable on a probability space (, F , P). Show that X is
independent of itself if and only if X is constant with probability 1, i.e., if there exists a constant
c ∈ R such that P(X = c) = 1. Hint: Consider the distribution function of X.
3.9. Let X, Y beindependentrandomvariablesthatareexponentiallydistributedwithparameter
α > 0. Find the distribution density of X/(X + Y ).
3.10. A system consists of four components that are similar but work independently. To operate
properly, it is necessary that (A and B) or (C and D) are working.

1

1

p12 . . .11 −

A

C

B

D

Let T be the failure time of the complete system, and Tk the failure time of component k ∈
{A, B,C, D}. Suppose Tk has the exponential distribution with parameter α. Show that

P(T < t) =’1 − e−2αt(2

.

86

3 Conditional Probabilities and Independence

3.11. Consider a fair tetrahedral die, whose faces are numbered by 1, 2, 3, 4, and which is
thrown twice. Let X be the sum and Y the maximum of the two respective numbers on the faces
falling downside.
(a) Find the joint distribution P ◦ (X, Y )−1 of X and Y.
(b) Construct two random variables X′ and Y′ on a suitable probability space (′, F′, P′),
= P′ ◦ X′−1 and P ◦Y−1
=

which have the same distributions as X and Y (i.e., P ◦ X−1
P′ ◦ Y′−1), but so that the distribution of X′ + Y′ differs from that of X + Y.
3.12. Let X, Y be i.i.d. random variables taking values in Z+. Suppose that either
(a) P(X = k|X + Y = n) = 1/(n + 1) for all 0 ≤ k ≤ n, or
(b) P(X = k|X + Y = n) =’n
Find the distribution of X (and hence of Y).
3.13. Coin tossing paradox. Alice suggests the following game to Bob: ‘You randomly choose
two integers X, Y ∈ Z with X < Y. Then you toss a fair coin. If it shows tails, you tell me Y,
otherwise X. Then I will guess whether the coin showed tails or heads. If my guess is right, you
pay me e100, otherwise you get e100 from me.’ Should Bob agree to play the game? (After
all, he can freely dispose of the distribution β according to which he picks (X, Y ), and isn’t it
clear that the chance of guessing the result of a fair coin toss is at best 50:50?) To answer this,
consider the following guessing strategy for Alice: Alice picks a random number Z ∈ Z with
distribution α, where α is any discrete density on Z with α(k) > 0 for every k ∈ Z. She guesses
that the coin was showing tails if the number Bob is announcing is at least Z, otherwise she
guesses heads. Set up a stochastic model and ﬁnd the winning probability for Alice when α and
β are given.
3.14. Dice paradox. Two dice D1 and D2 are labelled as follows.
D2 : 5 5 5 2 2 2 .

k(2−n for all 0 ≤ k ≤ n.

D1 : 6 3 3 3 3 3 ,

Andy and Beth roll D1 and D2 respectively. Whoever gets the higher number wins.
(a) Show that Andy has a higher probability of winning; we write this as D1 ≻ D2.
(b) Beth notices this and suggests to Andy: ‘I am now going to label a third die. You can then
choose an arbitrary die and I will take one of the remaining two.’ Can Beth label the third
die in such a way that she can always choose a die with a better chance of winning, i.e.,
so that D1 ≻ D2 ≻ D3 ≻ D1, meaning that the relation ≻ is not transitive?

3.15. Convolutions of gamma and negative binomial distributions. Show that
(a)
(b)

for α,r, s > 0, we have Γα,r ⋆ Γα,s = Γα,r+s;
for p ∈ ]0,1[ and r, s > 0 we have Br,p ⋆ Bs,p = Br+s,p. Hint: The Pólya distribution
provides you with a useful identity for negative binomial coefﬁcients.
3.16. Convolution of Cauchy distributions (Huygens’ principle). Consider the situation in
Problem 2.5 and show that ca ⋆ cb = ca+b for a, b > 0. In other words, the distribution of light
on a straight line at distance a+b from the light source is the same as if every light point on the
straight line at distance a is treated as a new light source radiating uniformly in all directions.

Problems

87

b

✓

✓✓✼❍❍❍❍❍❥
✘✘✘✘✘✘✘✘✿
✓
s✓
a

Hint: Verify the partial fraction decomposition
x2+b2−a2+2xy
ca (y)cb(x−y)/ca+b(x) =
x2+(a−b)2
and use that limn→∞C x+n
x−n z ca (z) dz = 0 for all x.

b
a+b

ca (y) +

a
a+b

x2+a2−b2+2x(x−y)

x2+(a−b)2

cb(x−y)

3.17. Thinning of a Poisson distribution. Suppose that the number of eggs an insect lays is
Poisson distributed with parameter λ. Out of each egg, a larva hatches with probability p,
independently of all other eggs. Find the distribution of the number of larvae.
3.18. ThinningofaPoissonprocess. Let α > 0, (Li )i≥1 beasequenceofi.i.d.randomvariables
that are exponentially distributed with parameter α, and let Tk =$k
i=1 Li, k ≥ 1. Furthermore,
let (Xk )k≥1 be a Bernoulli sequence with parameter p ∈ ]0,1[, which is independent of the Li.
Show that the random variables
N Xt
t ≥ 0,
In particular, T X

1 := inf{t > 0 : N Xt ≥ 1} is
form a Poisson process with parameter pα.
exponentially distributed with parameter pα.
3.19. Telegraph process. Let (Nt )t≥0 be a Poisson process with intensity α > 0 and Zt =
(−1)Nt . Show that P(Zs = Zt ) = (1 + e−2α(t−s))/2 for 0 ≤ s < t.
3.20. Bernoulli sequence as a discrete analogue of the Poisson process.
(a) Let (Xn)n≥1 be a Bernoulli sequence for p ∈ ]0,1[ and let

Xk 1]0,t](Tk ) ,

:=#k≥1

T0 = 0, Tk = inf{n > Tk−1 : Xn = 1}, Lk = Tk − Tk−1 − 1

for k ≥ 1. (Tk is the time of the kth success and Lk the waiting time between the (k − 1)st
and the kth success.) Show that the random variables (Lk )k≥1 are independent and have the
geometric distribution with parameter p.
(b) Let (Li )i≥1 be an i.i.d. sequence of random variables that are geometrically distributed
with parameter p ∈ ]0,1[. For k ≥ 1 let Tk =$k

i=1 Li + k, and for n ≥ 1 deﬁne

Xn =0 1

0

if n = Tk for some k ≥ 1 ,
otherwise.

Show that the random variables (Xn)n≥1 form a Bernoulli sequence with parameter p.
3.21. Let (Nt )t≥0 be a Poisson process and 0 < s < t. Find the conditional probability
P(Ns = k|Nt = n) for 0 ≤ k ≤ n.

88

3 Conditional Probabilities and Independence

3.22.
In a service centre with s different counters, customers arrive at the times of independent
Poisson processes (N (i )t
)t≥0 with intensities α(i ) > 0, 1 ≤ i ≤ s. At time t, you observe
that a total of n customers is waiting. What is the conditional distribution of the s-tuple of the
customers waiting in front of each of the counters?
3.23. Comparison of independent Poisson processes. Let (Nt )t≥0 and ( ˜Nt )t≥0 be two inde-
pendent Poisson processes with intensities α resp. ˜α and jump times (Tk ) resp. ( ˜Tk ). Show the
following.
(a) N
(b) The random variables N
˜Tk − N
(c) Deduce from (b) that Xn := 1

˜Tk−1, k ≥ 1, form an i.i.d. sequence; here we set ˜T0 := 0.
, n ≥ 1, is a Bernoulli sequence. How does
{ ˜NTn= ˜NTn−1}

˜T1 has a geometric distribution (with which parameter?).

this provide an explanation for (a)?

3.24. Let (St )t≥0 be the compound Poisson process with jump distribution Q and intensity
α > 0. Show that, for ﬁxed t > 0, St has the distribution
(αt)n
n!

Q⋆n .

Qt := e−αt#n≥0
= δ0 is the Dirac distribution at 0.

Here, Q⋆0
3.25. Construction of the Poisson point process in Rd. Let  ⊂ Rd be a Borel set with
0 < λd () < ∞, and α > 0. Also, let (Xi )i≥1 be a sequence of i.i.d. random variables with
uniform distribution on , and N a Poisson random variable with parameter αλd (), which
is independent of (Xi )i≥1. Consider the random points Xi ∈  for i ≤ N. For every Borel
set B ⊂  let NB be the number of points in B. That is,

NB =

1B (Xi ) .

N#i=1
Check that NB is a random variable. Show further that, for every partition  = "n
i=1 Bi
of  into disjoint Borel sets Bi ∈ B d
, the random variables (NBj )1≤j≤n are independent
and Poisson distributed with parameter αλ(Bj ). Finally, use a computer to produce a random
2, either by the above construction
sample of the Poisson point process on a square  = [0, L]
or that of Example (3.38). (To see that these constructions are equivalent, consider the process
N (1)t
:= N]0,t]×[0,L], which describes the ﬁrst coordinates of all points. By the above, this is
exactly the Poisson process on [0, L] with intensity αL.)
3.26. Box–Muller method for sampling from normal distributions, 1958. Let U, V be in-
dependent random variables with uniform distribution on ]0,1[, and deﬁne R = √−2 logU,
X = R cos(2πV ), andY = R sin(2πV ). Showthat X, Y areindependentand N0,1-distributed.
Hint: Firstcalculatethedistributiondensityof R andthenusethepolarcoordinatetransformation
of double integrals.

Problems

89

3.27. Failure times. Determine the random life span of a wire rope (or any kind of technical
appliance) as follows. For t > 0 let F(t) := P(]0, t]) be the probability that the rope fails in the
time interval ]0, t], and suppose P has a Lebesgue density ρ. Suppose further that the condi-
tional probability for failure of the rope in an inﬁnitesimal time interval[t, t+dt[, provided it has
notfailedyet, isequaltor (t) dt forsomecontinuousfunctionr : [0,∞[ → [0,∞[, theso-called
failure rate function. Find a differential equation for ϱ and solve it. Which distribution do you
obtain in the case of a constant failure rate r? If r (t) = αβt β−1 for some constants α, β > 0,
one obtains the so-called Weibull distribution with density
ϱ(t) = αβ t β−1 exp[−α t β] ,

3.28. Find all the probability measures P on [0,∞[ satisfying the following property:
If
n ∈ N is arbitrary and X1, . . . , Xn are independent random variables with identical distribution
P, then the random variable n min(X1, . . . , Xn) also has distribution P. Hint: Start by ﬁnding
an equation for F(t) := P(]t,∞[).
3.29. Let Yk, k ≥ 1, be [0,∞[-valued random variables on a probability space (, F , P), and
consider the events

t > 0 .

A1 =+$k≥1 Yk < ∞, ,
A3 =+infk≥1 Yk < 1, ,

A2 =+$k≥1 Yk < 1, ,
A4 =+lim infk→∞ Yk < 1, .

Which of these belong to the tail σ-algebra T (Yk : k ≥ 1)? Decide and give proofs.
3.30. Let (Xk )k≥1 be a Bernoulli sequence for p ∈ ]0,1[. For n,l ∈ N, let Aln be the event
{Xn = Xn+1 = ··· = Xn+l−1 = 1} that a run of luck of length at least l starts at time n, and
Aln. Show that P(&l∈N Al ) = 1. Hence, with probability 1 there exists
let Al = lim supn→∞
inﬁnitely many runs of luck of arbitrary length.
3.31. Oscillations of the simple symmetric random walk, cf. Problem 2.7. Let (Xi )i≥1 be a
sequence of independent random variables which are uniformly distributed on {−1,1}, and set
Sn =$n
Deduce that P(|Sn| ≤ m for all n) = 0 for all m, and further (using the symmetry of the Xi)
that

i=1 Xi for n ≥ 1. Show that, for all k ∈ N,

P’|Sn+k − Sn| ≥ k for inﬁnitely many n( = 1 .
P’ sup
n≥1 Sn = −∞( = 1 .
n≥1

Sn = ∞, inf

