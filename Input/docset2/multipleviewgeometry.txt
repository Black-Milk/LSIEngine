This page intentionally left blank

Multiple View Geometry in Computer Vision

Second Edition

Richard Hartley

Australian National University,

Canberra, Australia

Andrew Zisserman
University of Oxford, UK

CAMBRIDGE  UNIVERSITY  PRESS
Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo

Cambridge  University  Press
The Edinburgh Building, Cambridge CB2 2RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9780521540513

© Cambridge University Press 2000, 2003

This publication is in copyright. Subject to statutory exception and to the provision of
relevant collective licensing agreements, no reproduction of any part may take place
without the written permission of Cambridge University Press.

First published in print format 

2004

ISBN-13    978-0-511-18618-9
ISBN-10    0-511-18618-5

eBook (EBL)

eBook (EBL)

ISBN-13    978-0-521-54051-3
ISBN-10    0-521-54051-8

paperback

paperback

Cambridge University Press has no responsibility for the persistence or accuracy of URLs
for external or third-party internet websites referred to in this publication, and does not
guarantee that any content on such websites is, or will remain, accurate or appropriate.

Dedication

This book is dedicated to Joe Mundy whose vision and constant search for new ideas
led us into this ﬁeld.

Contents

Foreword
Preface
1

Introduction – a Tour of Multiple View Geometry
Introduction – the ubiquitous projective geometry
1.1
Camera projections
1.2
Reconstruction from more than one view
1.3
Three-view geometry
1.4
Four view geometry and n-view reconstruction
1.5
Transfer
1.6
Euclidean reconstruction
1.7
Auto-calibration
1.8
The reward I : 3D graphical models
1.9
1.10 The reward II: video augmentation

page xi
xiii
1
1
6
10
12
13
14
16
17
18
19

PART 0: The Background: Projective Geometry, Transformations and Esti-
mation

23
24
25
25
26
32
37
44
46
47
58
61
62
65
65
66

2

3

Planar geometry
The 2D projective plane
Projective transformations
A hierarchy of transformations
The projective geometry of 1D
Topology of the projective plane
Recovery of afﬁne and metric properties from images

Outline
Projective Geometry and Transformations of 2D
2.1
2.2
2.3
2.4
2.5
2.6
2.7
2.8 More properties of conics
2.9
2.10 Closure
Projective Geometry and Transformations of 3D
3.1
3.2

Points and projective transformations
Representing and transforming planes, lines and quadrics

Fixed points and lines

v

vi

4

5

Contents

Twisted cubics
The hierarchy of transformations
The plane at inﬁnity
The absolute conic
The absolute dual quadric
Closure

3.3
3.4
3.5
3.6
3.7
3.8
Estimation – 2D Projective Transformations
4.1
4.2
4.3
4.4
4.5
4.6
4.7
4.8
4.9
Algorithm Evaluation and Error Analysis
5.1
5.2
5.3 Monte Carlo estimation of covariance
5.4

The Direct Linear Transformation (DLT) algorithm
Different cost functions
Statistical cost functions and Maximum Likelihood estimation
Transformation invariance and normalization
Iterative minimization methods
Experimental comparison of the algorithms
Robust estimation
Automatic computation of a homography
Closure

Bounds on performance
Covariance of the estimated transformation

Closure

PART I: Camera Geometry and Single View Geometry

6

7

Finite cameras
The projective camera
Cameras at inﬁnity
Other camera models
Closure

Outline
Camera Models
6.1
6.2
6.3
6.4
6.5
Computation of the Camera Matrix P
7.1
7.2
7.3
7.4
7.5

Basic equations
Geometric error
Restricted camera estimation
Radial distortion
Closure

8 More Single View Geometry

8.1
8.2
8.3
8.4
8.5

Action of a projective camera on planes, lines, and conics
Images of smooth surfaces
Action of a projective camera on quadrics
The importance of the camera centre
Camera calibration and the image of the absolute conic

75
77
79
81
83
85
87
88
93
102
104
110
115
116
123
127
132
132
138
149
150

151
152
153
153
158
166
174
176
178
178
180
184
189
193
195
195
200
201
202
208

Contents

Vanishing points and vanishing lines
Afﬁne 3D measurements and reconstruction
Determining camera calibration K from a single view
Single view reconstruction

8.6
8.7
8.8
8.9
8.10 The calibrating conic
8.11 Closure

PART II: Two-View Geometry

9

Outline
Epipolar Geometry and the Fundamental Matrix
9.1
9.2
9.3
9.4
9.5
9.6
9.7

Epipolar geometry
The fundamental matrix F
Fundamental matrices arising from special motions
Geometric representation of the fundamental matrix
Retrieving the camera matrices
The essential matrix
Closure

10 3D Reconstruction of Cameras and Structure

10.1 Outline of reconstruction method
10.2 Reconstruction ambiguity
10.3 The projective reconstruction theorem
10.4 Stratiﬁed reconstruction
10.5 Direct reconstruction – using ground truth
10.6 Closure

11 Computation of the Fundamental Matrix F

11.1 Basic equations
11.2 The normalized 8-point algorithm
11.3 The algebraic minimization algorithm
11.4 Geometric distance
11.5 Experimental evaluation of the algorithms
11.6 Automatic computation of F
11.7 Special cases of F-computation
11.8 Correspondence of other entities
11.9 Degeneracies
11.10 A geometric interpretation of F-computation
11.11 The envelope of epipolar lines
11.12 Image rectiﬁcation
11.13 Closure

12 Structure Computation
12.1 Problem statement
12.2 Linear triangulation methods
12.3 Geometric error cost function
12.4 Sampson approximation (ﬁrst-order geometric correction)

vii

213
220
223
229
231
233

237
238
239
239
241
247
250
253
257
259
262
262
264
266
267
275
276
279
279
281
282
284
288
290
293
294
295
297
298
302
308
310
310
312
313
314

viii

Contents

12.5 An optimal solution
12.6 Probability distribution of the estimated 3D point
12.7 Line reconstruction
12.8 Closure

13 Scene planes and homographies

13.1 Homographies given the plane and vice versa
13.2 Plane induced homographies given F and image correspondences
13.3 Computing F given the homography induced by a plane
13.4 The inﬁnite homography H∞
13.5 Closure

14 Afﬁne Epipolar Geometry

14.1 Afﬁne epipolar geometry
14.2 The afﬁne fundamental matrix
14.3 Estimating FA from image point correspondences
14.4 Triangulation
14.5 Afﬁne reconstruction
14.6 Necker reversal and the bas-relief ambiguity
14.7 Computing the motion
14.8 Closure

PART III: Three-View Geometry

Outline

15 The Trifocal Tensor

15.1 The geometric basis for the trifocal tensor
15.2 The trifocal tensor and tensor notation
15.3 Transfer
15.4 The fundamental matrices for three views
15.5 Closure

16 Computation of the Trifocal Tensor T
16.1 Basic equations
16.2 The normalized linear algorithm
16.3 The algebraic minimization algorithm
16.4 Geometric distance
16.5 Experimental evaluation of the algorithms
16.6 Automatic computation of T
16.7 Special cases of T -computation
16.8 Closure

PART IV: N-View Geometry

Outline

17 N-Linearities and Multiple View Tensors

17.1 Bilinear relations
17.2 Trilinear relations

315
321
321
323
325
326
329
334
338
340
344
344
345
347
353
353
355
357
360

363
364
365
365
376
379
383
387
391
391
393
395
396
399
400
404
406

409
410
411
411
414

Contents

Intersections of four planes

17.3 Quadrilinear relations
17.4
17.5 Counting arguments
17.6 Number of independent equations
17.7 Choosing equations
17.8 Closure

18 N-View Computational Methods

18.1 Projective reconstruction – bundle adjustment
18.2 Afﬁne reconstruction – the factorization algorithm
18.3 Non-rigid factorization
18.4 Projective factorization
18.5 Projective reconstruction using planes
18.6 Reconstruction from sequences
18.7 Closure

19 Auto-Calibration
Introduction

19.1
19.2 Algebraic framework and problem statement
19.3 Calibration using the absolute dual quadric
19.4 The Kruppa equations
19.5 A stratiﬁed solution
19.6 Calibration from rotating cameras
19.7 Auto-calibration from planes
19.8 Planar motion
19.9 Single axis rotation – turntable motion
19.10 Auto-calibration of a stereo rig
19.11 Closure

20 Duality

20.1 Carlsson–Weinshall duality
20.2 Reduced reconstruction
20.3 Closure

21 Cheirality

21.1 Quasi-afﬁne transformations
21.2 Front and back of a camera
21.3 Three-dimensional point sets
21.4 Obtaining a quasi-afﬁne reconstruction
21.5 Effect of transformations on cheirality
21.6 Orientation
21.7 The cheiral inequalities
21.8 Which points are visible in a third view
21.9 Which points are in front of which
21.10 Closure

ix

418
421
422
428
431
432
434
434
436
440
444
447
452
456
458
458
459
462
469
473
481
485
486
490
493
497
502
502
508
513
515
515
518
519
520
521
523
525
528
530
531

Contents

x
22 Degenerate Conﬁgurations
22.1 Camera resectioning
22.2 Degeneracies in two views
22.3 Carlsson–Weinshall duality
22.4 Three-view critical conﬁgurations
22.5 Closure

PART V : Appendices
Appendix 1 Tensor Notation
Appendix 2 Gaussian (Normal) and χ2 Distributions
Appendix 3 Parameter Estimation
Appendix 4 Matrix Properties and Decompositions
Appendix 5 Least-squares Minimization
Appendix 6 Iterative Estimation Methods
Appendix 7 Some Special Plane Projective Transformations
Bibliography
Index

533
533
539
546
553
558

561
562
565
568
578
588
597
628
634
646

Foreword

By Olivier Faugeras

Making a computer see was something that leading experts in the ﬁeld of Artiﬁcial
Intelligence thought to be at the level of difﬁculty of a summer student’s project back
in the sixties. Forty years later the task is still unsolved and seems formidable. A
whole ﬁeld, called Computer Vision, has emerged as a discipline in itself with strong
connections to mathematics and computer science and looser connections to physics,
the psychology of perception and the neuro sciences.

One of the likely reasons for this half-failure is the fact that researchers had over-
looked the fact, perhaps because of this plague called naive introspection, that percep-
tion in general and visual perception in particular are far more complex in animals and
humans than was initially thought. There is of course no reason why we should pattern
Computer Vision algorithms after biological ones, but the fact of the matter is that

(i) the way biological vision works is still largely unknown and therefore hard to

emulate on computers, and

(ii) attempts to ignore biological vision and reinvent a sort of silicon-based vision

have not been so successful as initially expected.

Despite these negative remarks, Computer Vision researchers have obtained some

outstanding successes, both practical and theoretical.

On the side of practice, and to single out one example, the possibility of guiding vehi-
cles such as cars and trucks on regular roads or on rough terrain using computer vision
technology was demonstrated many years ago in Europe, the USA and Japan. This
requires capabilities for real-time three-dimensional dynamic scene analysis which are
quite elaborate. Today, car manufacturers are slowly incorporating some of these func-
tions in their products.

On the theoretical side some remarkable progress has been achieved in the area of
what one could call geometric Computer Vision. This includes the description of the
way the appearance of objects changes when viewed from different viewpoints as a
function of the objects’ shape and the cameras parameters. This endeavour would not
have been achieved without the use of fairly sophisticated mathematical techniques en-
compassing many areas of geometry, ancient and novel. This book deals in particular
with the intricate and beautiful geometric relations that exist between the images of ob-
jects in the world. These relations are important to analyze for their own sake because

xi

xii

0 Foreword

this is one of the goals of science to provide explanations for appearances; they are also
important to analyze because of the range of applications their understanding opens up.
The book has been written by two pioneers and leading experts in geometric Com-
puter Vision. They have succeeded in what was something of a challenge, namely to
convey in a simple and easily accessible way the mathematics that is necessary for
understanding the underlying geometric concepts, to be quite exhaustive in the cover-
age of the results that have been obtained by them and other researchers worldwide, to
analyze the interplay between the geometry and the fact that the image measurements
are necessarily noisy, to express many of these theoretical results in algorithmic form
so that they can readily be transformed into computer code, and to present many real
examples that illustrate the concepts and show the range of applicability of the theory.
Returning to the original holy grail of making a computer see we may wonder
whether this kind of work is a step in the right direction.
I must leave the readers
of the book to answer this question, and be content with saying that no designer of
systems using cameras hooked to computers that will be built in the foreseeable future
can ignore this work. This is perhaps a step in the direction of deﬁning what it means
for a computer to see.

Preface

Over the past decade there has been a rapid development in the understanding and mod-
elling of the geometry of multiple views in computer vision. The theory and practice
have now reached a level of maturity where excellent results can be achieved for prob-
lems that were certainly unsolved a decade ago, and often thought unsolvable. These
tasks and algorithms include:
• Given two images, and no other information, compute matches between the images,
and the 3D position of the points that generate these matches and the cameras that
generate the images.
• Given three images, and no other information, similarly compute the matches be-
tween images of points and lines, and the position in 3D of these points and lines
and the cameras.
• Compute the epipolar geometry of a stereo rig, and trifocal geometry of a trinocular
rig, without requiring a calibration object.
• Compute the internal calibration of a camera from a sequence of images of natural
scenes (i.e. calibration “on the ﬂy”).

The distinctive ﬂavour of these algorithms is that they are uncalibrated — it is not
necessary to know or ﬁrst need to compute the camera internal parameters (such as the
focal length).

Underpinning these algorithms is a new and more complete theoretical understand-
ing of the geometry of multiple uncalibrated views: the number of parameters involved,
the constraints between points and lines imaged in the views; and the retrieval of cam-
eras and 3-space points from image correspondences. For example, to determine the
epipolar geometry of a stereo rig requires specifying only seven parameters, the camera
calibration is not required. These parameters are determined from the correspondence
of seven or more image point correspondences. Contrast this uncalibrated route, with
the previous calibrated route of a decade ago: each camera would ﬁrst be calibrated
from the image of a carefully engineered calibration object with known geometry. The
calibration involves determining 11 parameters for each camera. The epipolar geome-
try would then have been computed from these two sets of 11 parameters.

This example illustrates the importance of the uncalibrated (projective) approach –
using the appropriate representation of the geometry makes explicit the parameters

xiii

xiv

Preface

that are required at each stage of a computation. This avoids computing parameters
that have no effect on the ﬁnal result, and results in simpler algorithms.
It is also
worth correcting a possible misconception. In the uncalibrated framework, entities (for
instance point positions in 3-space) are often recovered to within a precisely deﬁned
ambiguity. This ambiguity does not mean that the points are poorly estimated.

More practically, it is often not possible to calibrate cameras once-and-for-all; for
instance where cameras are moved (on a mobile vehicle) or internal parameters are
changed (a surveillance camera with zoom). Furthermore, calibration information is
simply not available in some circumstances. Imagine computing the motion of a cam-
era from a video sequence, or building a virtual reality model from archive ﬁlm footage
where both motion and internal calibration information are unknown.

The achievements in multiple view geometry have been possible because of develop-
ments in our theoretical understanding, but also because of improvements in estimating
mathematical objects from images. The ﬁrst improvement has been an attention to the
error that should be minimized in over-determined systems – whether it be algebraic,
geometric or statistical. The second improvement has been the use of robust estimation
algorithms (such as RANSAC), so that the estimate is unaffected by “outliers” in the
data. Also these techniques have generated powerful search and matching algorithms.
Many of the problems of reconstruction have now reached a level where we may

claim that they are solved. Such problems include:

(i) Estimation of the multifocal tensors from image point correspondences, par-
ticularly the fundamental matrix and trifocal tensors (the quadrifocal tensor
having not received so much attention).

(ii) Extraction of the camera matrices from these tensors, and subsequent projective

reconstruction from two, three and four views.

Other signiﬁcant successes have been achieved, though there may be more to learn
about these problems. Examples include:

(i) Application of bundle adjustment to solve more general reconstruction prob-

lems.

(ii) Metric (Euclidean) reconstruction given minimal assumptions on the camera

matrices.

(iii) Automatic detection of correspondences in image sequences, and elimination

of outliers and false matches using the multifocal tensor relationships.

Roadplan. The book is divided into six parts and there are seven short appendices.
Each part introduces a new geometric relation: the homography for background, the
camera matrix for single view, the fundamental matrix for two views, the trifocal tensor
for three views, and the quadrifocal tensor for four views.
In each case there is a
chapter describing the relation, its properties and applications, and a companion chapter
describing algorithms for its estimation from image measurements. The estimation
algorithms described range from cheap, simple, approaches through to the optimal
algorithms which are currently believed to be the best available.

Preface

xv
Part 0: Background. This part is more tutorial than the others. It introduces the
central ideas in the projective geometry of 2-space and 3-space (for example
ideal points, and the absolute conic); how this geometry may be represented,
manipulated, and estimated; and how the geometry relates to various objectives
in computer vision such as rectifying images of planes to remove perspective
distortion.

Part 1: Single view geometry. Here the various cameras that model the perspective
projection from 3-space to an image are deﬁned and their anatomy explored.
Their estimation using traditional techniques of calibration objects is described,
as well as camera calibration from vanishing points and vanishing lines.

Part 2: Two view geometry. This part describes the epipolar geometry of two
cameras, projective reconstruction from image point correspondences, methods
of resolving the projective ambiguity, optimal triangulation, transfer between
views via planes.

Part 3: Three view geometry. Here the trifocal geometry of three cameras is de-
scribed, including transfer of a point correspondence from two views to a third,
and similarly transfer for a line correspondence; computation of the geometry
from point and line correspondences, retrieval of the camera matrices.

Part 4: N-views. This part has two purposes. First, it extends three view geometry
to four views (a minor extension) and describes estimation methods applica-
ble to N-views, such as the factorization algorithm of Tomasi and Kanade for
computing structure and motion simultaneously from multiple images. Sec-
ond, it covers themes that have been touched on in earlier chapters, but can
be understood more fully and uniformly by emphasising their commonality.
Examples include deriving multi-linear view constraints on correspondences,
auto-calibration, and ambiguous solutions.

Appendices. These describe further background material on tensors, statistics, pa-
rameter estimation, linear and matrix algebra, iterative estimation, the solution
of sparse matrix systems, and special projective transformations.

Acknowledgements. We have beneﬁted enormously from ideas and discussions with
our colleagues: Paul Beardsley, Stefan Carlsson, Olivier Faugeras, Andrew Fitzgibbon,
Jitendra Malik, Steve Maybank, Amnon Shashua, Phil Torr, Bill Triggs.

If there are only a countable number of errors in this book then it is due to Antonio
Criminisi, David Liebowitz and Frederik Schaffalitzky who have with great energy and
devotion read most of it, and made numerous suggestions for improvements. Similarly
both Peter Sturm and Bill Triggs have suggested many improvements to various chap-
ters. We are grateful to other colleagues who have read individual chapters: David
Capel, Lourdes de Agapito Vicente, Bob Kaucic, Steve Maybank, Peter Tu.

We are particularly grateful to those who have provided multiple ﬁgures: Paul Beard-
sley, Antonio Criminisi, Andrew Fitzgibbon, David Liebowitz, and Larry Shapiro; and
for individual ﬁgures from: Martin Armstrong, David Capel, Lourdes de Agapito Vi-
cente, Eric Hayman, Phil Pritchett, Luc Robert, Cordelia Schmid, and others who are
explicitly acknowledged in ﬁgure captions.

xvi

Preface

At Cambridge University Press we thank David Tranah for his constant source of

advice and patience, and Michael Behrend for excellent copy editing.

A small number of minor errors have been corrected in the reprinted editions, and
we thank the following readers for pointing these out: Luis Baumela, Niclas Borlin,
Mike Brooks, Jun ho. Choi, Wojciech Chojnacki, Carlo Colombo, Nicolas Dano, An-
drew Fitzgibbon, Bogdan Georgescu, Fredrik Kahl, Bob Kaucic, Jae-Hak Kim, Han-
sung Lee, Dennis Maier, Karsten Muelhmann, David Nister, Andreas Olsson, St´ephane
Paris, Frederik Schaffalitzky, Bill Severson, Pedro Lopez de Teruel Alcolea, Bernard
Thiesse, Ken Thornton, Magdalena Urbanek, Gergely Vass, Eugene Vendrovsky, Sui
Wei, and Tom´aˇs Werner.

The second edition. This new paperback edition has been expanded to include some
of the developments since the original version of July 2000. For example, the book
now covers the discovery of a closed form factorization solution in the projective case
when a plane is visible in the scene, and the extension of afﬁne factorization to non-
rigid scenes. We have also extended the discussion of single view geometry (chapter 8)
and three view geometry (chapter 15), and added an appendix on parameter estimation.
In preparing this second edition we are very grateful to colleagues who have made
suggestion for improvements and additions. These include Marc Pollefeys, Bill Triggs
and in particular Tom´aˇs Werner who provided excellent and comprehensive comments.
We also thank Antonio Criminisi, Andrew Fitzgibbon, Rob Fergus, David Liebowitz,
and particularly Josef ˇSivic, for proof reading and very helpful comments on parts of
the new material. As always we are grateful to David Tranah of CUP.

The ﬁgures appearing in this book can be downloaded from

http://www.robots.ox.ac.uk/∼vgg/hzbook.html

This site also includes Matlab code for several of the algorithms, and lists the errata of
earlier printings.

I am never forget the day my ﬁrst book is published. Every chapter I stole from somewhere else. Index
I copy from old Vladivostok telephone directory. This book, this book was sensational!

Excerpts from “Nikolai Ivanovich Lobachevsky” by Tom Lehrer.

1

Introduction – a Tour of Multiple View Geometry

This chapter is an introduction to the principal ideas covered in this book. It gives an
informal treatment of these topics. Precise, unambiguous deﬁnitions, careful algebra,
and the description of well honed estimation algorithms is postponed until chapter 2
and the following chapters in the book. Throughout this introduction we will generally
not give speciﬁc forward pointers to these later chapters. The material referred to can
be located by use of the index or table of contents.

1.1 Introduction – the ubiquitous projective geometry

We are all familiar with projective transformations.When we look at a picture, we see
squares that are not squares, or circles that are not circles. The transformation that
maps these planar objects onto the picture is an example of a projective transformation.
So what properties of geometry are preserved by projective transformations? Cer-
tainly, shape is not, since a circle may appear as an ellipse. Neither are lengths since
two perpendicular radii of a circle are stretched by different amounts by the projective
transformation. Angles, distance, ratios of distances – none of these are preserved,
and it may appear that very little geometry is preserved by a projective transformation.
However, a property that is preserved is that of straightness. It turns out that this is
the most general requirement on the mapping, and we may deﬁne a projective trans-
formation of a plane as any mapping of the points on the plane that preserves straight
lines.
To see why we will require projective geometry we start from the familiar Euclidean
geometry. This is the geometry that describes angles and shapes of objects. Euclidean
geometry is troublesome in one major respect – we need to keep making an exception
to reason about some of the basic concepts of the geometry – such as intersection of
lines. Two lines (we are thinking here of 2-dimensional geometry) almost always meet
in a point, but there are some pairs of lines that do not do so – those that we call parallel.
A common linguistic device for getting around this is to say that parallel lines meet “at
inﬁnity”. However this is not altogether convincing, and conﬂicts with another dictum,
that inﬁnity does not exist, and is only a convenient ﬁction. We can get around this by

1

1 Introduction – a Tour of Multiple View Geometry

2
enhancing the Euclidean plane by the addition of these points at inﬁnity where parallel
lines meet, and resolving the difﬁculty with inﬁnity by calling them “ideal points.”
By adding these points at inﬁnity, the familiar Euclidean space is transformed into a
new type of geometric object, projective space. This is a very useful way of thinking,
since we are familiar with the properties of Euclidean space, involving concepts such as
distances, angles, points, lines and incidence. There is nothing very mysterious about
projective space – it is just an extension of Euclidean space in which two lines always
meet in a point, though sometimes at mysterious points at inﬁnity.
Coordinates. A point in Euclidean 2-space is represented by an ordered pair of real
numbers, (x, y). We may add an extra coordinate to this pair, giving a triple (x, y, 1),
that we declare to represent the same point. This seems harmless enough, since we
can go back and forward from one representation of the point to the other, simply by
adding or removing the last coordinate. We now take the important conceptual step
of asking why the last coordinate needs to be 1 – after all, the others two coordinates
are not so constrained. What about a coordinate triple (x, y, 2).
It is here that we
make a deﬁnition and say that (x, y, 1) and (2x, 2y, 2) represent the same point, and
furthermore, (kx, ky, k) represents the same point as well, for any non-zero value k.
Formally, points are represented by equivalence classes of coordinate triples, where
two triples are equivalent when they differ by a common multiple. These are called the
homogeneous coordinates of the point. Given a coordinate triple (kx, ky, k), we can
get the original coordinates back by dividing by k to get (x, y).
The reader will observe that although (x, y, 1) represents the same point as the co-
ordinate pair (x, y), there is no point that corresponds to the triple (x, y, 0). If we try
to divide by the last coordinate, we get the point (x/0, y/0) which is inﬁnite. This is
how the points at inﬁnity arise then. They are the points represented by homogeneous
coordinates in which the last coordinate is zero.
Once we have seen how to do this for 2-dimensional Euclidean space, extending it
to a projective space by representing points as homogeneous vectors, it is clear that we
can do the same thing in any dimension. The Euclidean space IRn can be extended to
a projective space IPn by representing points as homogeneous vectors. It turns out that
the points at inﬁnity in the two-dimensional projective space form a line, usually called
the line at inﬁnity. In three-dimensions they form the plane at inﬁnity.
Homogeneity. In classical Euclidean geometry all points are the same. There is no
distinguished point. The whole of the space is homogeneous. When coordinates are
added, one point is seemingly picked out as the origin. However, it is important to
realize that this is just an accident of the particular coordinate frame chosen. We could
just as well ﬁnd a different way of coordinatizing the plane in which a different point
is considered to be the origin. In fact, we can consider a change of coordinates for the
Euclidean space in which the axes are shifted and rotated to a different position. We
may think of this in another way as the space itself translating and rotating to a different
position. The resulting operation is known as a Euclidean transform.
A more general type of transformation is that of applying a linear transformation

1.1 Introduction – the ubiquitous projective geometry

3
to IRn, followed by a Euclidean transformation moving the origin of the space. We
may think of this as the space moving, rotating and ﬁnally stretching linearly possibly
by different ratios in different directions. The resulting transformation is known as an
afﬁne transformation.
The result of either a Euclidean or an afﬁne transformation is that points at inﬁn-
ity remain at inﬁnity. Such points are in some way preserved, at least as a set, by
such transformations. They are in some way distinguished, or special in the context of
Euclidean or afﬁne geometry.
From the point of view of projective geometry, points at inﬁnity are not any dif-
ferent from other points. Just as Euclidean space is uniform, so is projective space.
The property that points at inﬁnity have ﬁnal coordinate zero in a homogeneous co-
ordinate representation is nothing other than an accident of the choice of coordinate
frame. By analogy with Euclidean or afﬁne transformations, we may deﬁne a projec-
tive transformation of projective space. A linear transformation of Euclidean space IRn
is represented by matrix multiplication applied to the coordinates of the point. In just
the same way a projective transformation of projective space IPn is a mapping of the
homogeneous coordinates representing a point (an (n + 1)-vector), in which the coor-
dinate vector is multiplied by a non-singular matrix. Under such a mapping, points at
inﬁnity (with ﬁnal coordinate zero) are mapped to arbitrary other points. The points at
inﬁnity are not preserved. Thus, a projective transformation of projective space IPn is
represented by a linear transformation of homogeneous coordinates

X′ = H(n+1)×(n+1)X.

In computer vision problems, projective space is used as a convenient way of repre-
senting the real 3D world, by extending it to the 3-dimensional (3D) projective space.
Similarly images, usually formed by projecting the world onto a 2-dimensional repre-
sentation, are for convenience extended to be thought of as lying in the 2-dimensional
projective space. In reality, the real world, and images of it do not contain points at
inﬁnity, and we need to keep our ﬁnger on which are the ﬁctitious points, namely the
line at inﬁnity in the image and the plane at inﬁnity in the world. For this reason, al-
though we usually work with the projective spaces, we are aware that the line and plane
at inﬁnity are in some way special. This goes against the spirit of pure projective ge-
ometry, but makes it useful for our practical problems. Generally we try to have it both
ways by treating all points in projective space as equals when it suits us, and singling
out the line at inﬁnity in space or the plane at inﬁnity in the image when that becomes
necessary.
1.1.1 Afﬁne and Euclidean Geometry
We have seen that projective space can be obtained from Euclidean space by adding
a line (or plane) at inﬁnity. We now consider the reverse process of going backwards.
This discussion is mainly concerned with two and three-dimensional projective space.
Afﬁne geometry. We will take the point of view that the projective space is initially
homogeneous, with no particular coordinate frame being preferred. In such a space,

1 Introduction – a Tour of Multiple View Geometry

4
there is no concept of parallelism of lines, since parallel lines (or planes in the three-
dimensional case) are ones that meet at inﬁnity. However, in projective space, there is
no concept of which points are at inﬁnity – all points are created equal. We say that
parallelism is not a concept of projective geometry. It is simply meaningless to talk
about it.
In order for such a concept to make sense, we need to pick out some particular line,
and decide that this is the line at inﬁnity. This results in a situation where although
all points are created equal, some are more equal than others. Thus, start with a blank
sheet of paper, and imagine that it extends to inﬁnity and forms a projective space
IP2. What we see is just a small part of the space, that looks a lot like a piece of the
ordinary Euclidean plane. Now, let us draw a straight line on the paper, and declare
that this is the line at inﬁnity. Next, we draw two other lines that intersect at this
distinguished line. Since they meet at the “line at inﬁnity” we deﬁne them as being
parallel. The situation is similar to what one sees by looking at an inﬁnite plane. Think
of a photograph taken in a very ﬂat region of the earth. The points at inﬁnity in the
plane show up in the image as the horizon line. Lines, such as railway tracks show
up in the image as lines meeting at the horizon. Points in the image lying above the
horizon (the image of the sky) apparently do not correspond to points on the world
plane. However, if we think of extending the corresponding ray backwards behind the
camera, it will meet the plane at a point behind the camera. Thus there is a one-to-one
relationship between points in the image and points in the world plane. The points at
inﬁnity in the world plane correspond to a real horizon line in the image, and parallel
lines in the world correspond to lines meeting at the horizon. From our point of view,
the world plane and its image are just alternative ways of viewing the geometry of a
projective plane, plus a distinguished line. The geometry of the projective plane and a
distinguished line is known as afﬁne geometry and any projective transformation that
maps the distinguished line in one space to the distinguished line of the other space is
known as an afﬁne transformation.
By identifying a special line as the “line at inﬁnity” we are able to deﬁne parallelism
of straight lines in the plane. However, certain other concepts make sense as well, as
soon as we can deﬁne parallelism. For instance, we may deﬁne equalities of intervals
between two points on parallel lines. For instance, if A, B, C and D are points, and
the lines AB and CD are parallel, then we deﬁne the two intervals AB and CD to
have equal length if the lines AC and BD are also parallel. Similarly, two intervals on
the same line are equal if there exists another interval on a parallel line that is equal to
both.

Euclidean geometry. By distinguishing a special line in a projective plane, we gain
the concept of parallelism and with it afﬁne geometry. Afﬁne geometry is seen as
specialization of projective geometry, in which we single out a particular line (or plane
– according to the dimension) and call it the line at inﬁnity.
Next, we turn to Euclidean geometry and show that by singling out some special
feature of the line or plane at inﬁnity afﬁne geometry becomes Euclidean geometry. In

1.1 Introduction – the ubiquitous projective geometry

5
doing so, we introduce one of the most important concepts of this book, the absolute
conic.
We begin by considering two-dimensional geometry, and start with circles. Note that
a circle is not a concept of afﬁne geometry, since arbitrary stretching of the plane, which
preserves the line at inﬁnity, turns the circle into an ellipse. Thus, afﬁne geometry does
not distinguish between circles and ellipses.
In Euclidean geometry however, they are distinct, and have an important difference.
Algebraically, an ellipse is described by a second-degree equation. It is therefore ex-
pected, and true that two ellipses will most generally intersect in four points. However,
it is geometrically evident that two distinct circles can not intersect in more than two
points. Algebraically, we are intersecting two second-degree curves here, or equiva-
lently solving two quadratic equations. We should expect to get four solutions. The
question is, what is special about circles that they only intersect in two points.
The answer to this question is of course that there exist two other solutions, the two
circles meeting in two other complex points. We do not have to look very far to ﬁnd
these two points.

The equation for a circle in homogeneous coordinates (x, y, w) is of the form

(x − aw)2 + (y − bw)2 = r2w2

This represents the circle with centre represented in homogeneous coordinates as
(x0, y0, w0)T = (a, b, 1)T. It is quickly veriﬁed that the points (x, y, w)T = (1,±i, 0)T
lie on every such circle. To repeat this interesting fact, every circle passes through the
points (1,±i, 0)T, and therefore they lie in the intersection of any two circles. Since
their ﬁnal coordinate is zero, these two points lie on the line at inﬁnity. For obvious
reasons, they are called the circular points of the plane. Note that although the two
circular points are complex, they satisfy a pair of real equations: x2 + y2 = 0; w = 0.
This observation gives the clue of how we may deﬁne Euclidean geometry. Euclidean
geometry arises from projective geometry by singling out ﬁrst a line at inﬁnity and
subsequently, two points called circular points lying on this line. Of course the circular
points are complex points, but for the most part we do not worry too much about
this. Now, we may deﬁne a circle as being any conic (a curve deﬁned by a second-
degree equation) that passes through the two circular points. Note that in the standard
Euclidean coordinate system, the circular points have the coordinates (1,±i, 0)T. In
assigning a Euclidean structure to a projective plane, however, we may designate any
line and any two (complex) points on that line as being the line at inﬁnity and the
circular points.
As an example of applying this viewpoint, we note that a general conic may be
found passing through ﬁve arbitrary points in the plane, as may be seen by counting
the number of coefﬁcients of a general quadratic equation ax2 + by2 + . . . + f w2 = 0.
A circle on the other hand is deﬁned by only three points. Another way of looking at
this is that it is a conic passing through two special points, the circular points, as well
as three other points, and hence as any other conic, it requires ﬁve points to specify it
uniquely.
It should not be a surprise that as a result of singling out two circular points one

1 Introduction – a Tour of Multiple View Geometry

6
obtains the whole of the familiar Euclidean geometry. In particular, concepts such as
angle and length ratios may be deﬁned in terms of the circular points. However, these
concepts are most easily deﬁned in terms of some coordinate system for the Euclidean
plane, as will be seen in later chapters.
3D Euclidean geometry. We saw how the Euclidean plane is deﬁned in terms of
the projective plane by specifying a line at inﬁnity and a pair of circular points. The
same idea may be applied to 3D geometry. As in the two-dimensional case, one may
look carefully at spheres, and how they intersect. Two spheres intersect in a circle,
and not in a general fourth-degree curve, as the algebra suggests, and as two general
ellipsoids (or other quadric surfaces) do. This line of thought leads to the discovery
that in homogeneous coordinates (X, Y, Z, T)T all spheres intersect the plane at inﬁnity
in a curve with the equations: X2 + Y2 + Z2 = 0; T = 0. This is a second-degree curve
(a conic) lying on the plane at inﬁnity, and consisting only of complex points. It is
known as the absolute conic and is one of the key geometric entities in this book, most
particularly because of its connection to camera calibration, as will be seen later.
The absolute conic is deﬁned by the above equations only in the Euclidean coor-
dinate system. In general we may consider 3D Euclidean space to be derived from
projective space by singling out a particular plane as the plane at inﬁnity and specify-
ing a particular conic lying in this plane to be the absolute conic. These entities may
have quite general descriptions in terms of a coordinate system for the projective space.
We will not here go into details of how the absolute conic determines the complete
Euclidean 3D geometry. A single example will serve. Perpendicularity of lines in
space is not a valid concept in afﬁne geometry, but belongs to Euclidean geometry.
The perpendicularity of lines may be deﬁned in terms of the absolute conic, as follows.
By extending the lines until they meet the plane at inﬁnity, we obtain two points called
the directions of the two lines. Perpendicularity of the lines is deﬁned in terms of the
relationship of the two directions to the absolute conic. The lines are perpendicular if
the two directions are conjugate points with respect to the absolute conic (see ﬁgure
3.8(p83)). The geometry and algebraic representation of conjugate points are deﬁned
in section 2.8.1(p58). Brieﬂy, if the absolute conic is represented by a 3× 3 symmetric
matrix Ω∞, and the directions are the points d1 and d2, then they are conjugate with
respect to Ω∞ if dT
1 Ω∞d2 = 0. More generally, angles may be deﬁned in terms of the
absolute conic in any arbitrary coordinate system, as expressed by (3.23–p82).

1.2 Camera projections

One of the principal topics of this book is the process of image formation, namely the
formation of a two-dimensional representation of a three-dimensional world, and what
we may deduce about the 3D structure of what appears in the images.
The drop from three-dimensional world to a two-dimensional image is a projection
process in which we lose one dimension. The usual way of modelling this process is
by central projection in which a ray from a point in space is drawn from a 3D world
point through a ﬁxed point in space, the centre of projection. This ray will intersect a
speciﬁc plane in space chosen as the image plane. The intersection of the ray with the

1.2 Camera projections

7
image plane represents the image of the point. If the 3D structure lies on a plane then
there is no drop in dimension.
This model is in accord with a simple model of a camera, in which a ray of light
from a point in the world passes through the lens of a camera and impinges on a ﬁlm or
digital device, producing an image of the point. Ignoring such effects as focus and lens
thickness, a reasonable approximation is that all the rays pass through a single point,
the centre of the lens.
In applying projective geometry to the imaging process, it is customary to model the
world as a 3D projective space, equal to IR3 along with points at inﬁnity. Similarly
the model for the image is the 2D projective plane IP2. Central projection is simply
a map from IP3 to IP2. If we consider points in IP3 written in terms of homogeneous
coordinates (X, Y, Z, T)T and let the centre of projection be the origin (0, 0, 0, 1)T, then
we see that the set of all points (X, Y, Z, T)T for ﬁxed X, Y and Z, but varying T form
a single ray passing through the point centre of projection, and hence all mapping to
the same point. Thus, the ﬁnal coordinate of (X, Y, Z, T) is irrelevant to where the point
is imaged. In fact, the image point is the point in IP2 with homogeneous coordinates
(X, Y, Z)T. Thus, the mapping may be represented by a mapping of 3D homogeneous
coordinates, represented by a 3 × 4 matrix P with the block structure P = [I3×3|03],
where I3×3 is the 3 × 3 identity matrix and 03 a zero 3-vector. Making allowance for a
different centre of projection, and a different projective coordinate frame in the image,
it turns out that the most general imaging projection is represented by an arbitrary 3× 4
matrix of rank 3, acting on the homogeneous coordinates of the point in IP3 mapping it
to the imaged point in IP2. This matrix P is known as the camera matrix.
In summary, the action of a projective camera on a point in space may be expressed
in terms of a linear mapping of homogeneous coordinates as

x
y
w

⎛⎜⎝

⎛⎜⎝

⎞⎟⎠ = P3×4⎛⎜⎜⎜⎝
⎞⎟⎠ = H3×3⎛⎜⎝

X
Y
Z
T

X
Y
T

⎞⎟⎟⎟⎠
⎞⎟⎠

Furthermore, if all the points lie on a plane (we may choose this as the plane Z = 0)
then the linear mapping reduces to

x
y
w
which is a projective transformation.
Cameras as points. In a central projection, points in IP3 are mapped to points in IP2,
all points in a ray passing through the centre of projection projecting to the same point
in an image. For the purposes of image projection, it is possible to consider all points
along such a ray as being equal. We can go one step further, and think of the ray
through the projection centre as representing the image point. Thus, the set of all
image points is the same as the set of rays through the camera centre. If we represent

8

1 Introduction – a Tour of Multiple View Geometry

image plane

x

2

x

1

x

3

x

4

C

X

1

X

2

X

3

X4

/

x3
x

3

x

2/

/

x1

x

2

x

1

x

3

x

4

x

2

x

1

C

X

3

X4

x

3

x

4

x

2

x

1

a

x

4

c

C

X

3

X4

C

X3

X4

x

/
4

x

/3

(cid:83)

x /1

x2/

/

C

X1

X

1

X

2

x

3

x

4

x

2

x

1

C

X3

X4

X2

e

X1

(cid:83)

x

2/

x

/3

x

/
4

x /1

/

C

X1

X2

b

X2
d

Fig. 1.1. The camera centre is the essence. (a) Image formation: the image points xi are the inter-
section of a plane with rays from the space points Xi through the camera centre C. (b) If the space
points are coplanar then there is a projective transformation between the world and image planes,
xi = H3×3Xi. (c) All images with the same camera centre are related by a projective transformation,
x′i = H′3×3xi. Compare (b) and (c) – in both cases planes are mapped to one another by rays through
a centre. In (b) the mapping is between a scene and image plane, in (c) between two image planes. (d)
If the camera centre moves, then the images are in general not related by a projective transformation,
unless (e) all the space points are coplanar.

the ray from (0, 0, 0, 1)T through the point (X, Y, Z, T)T by its ﬁrst three coordinates
(X, Y, Z)T, it is easily seen that for any constant k, the ray k(X, Y, Z)T represents the
same ray. Thus the rays themselves are represented by homogeneous coordinates. In

1.2 Camera projections

9
fact they make up a 2-dimensional space of rays. The set of rays themselves may be
thought of as a representation of the image space IP2. In this representation of the
image, all that is important is the camera centre, for this alone determines the set of
rays forming the image. Different camera matrices representing the image formation
from the same centre of projection reﬂect only different coordinate frames for the set
of rays forming the image. Thus two images taken from the same point in space are
projectively equivalent. It is only when we start to measure points in an image, that
a particular coordinate frame for the image needs to be speciﬁed. Only then does it
become necessary to specify a particular camera matrix.
In short, modulo ﬁeld-of-
view which we ignore for now, all images acquired with the same camera centre are
equivalent – they can be mapped onto each other by a projective transformation without
any information about the 3D points or position of the camera centre. These issues are
illustrated in ﬁgure 1.1.

Calibrated cameras. To understand fully the Euclidean relationship between the im-
age and the world, it is necessary to express their relative Euclidean geometry. As
we have seen, the Euclidean geometry of the 3D world is determined by specifying
a particular plane in IP3 as being the plane at inﬁnity, and a speciﬁc conic Ω in that
plane as being the absolute conic. For a camera not located on the plane at inﬁnity, the
plane at inﬁnity in the world maps one-to-one onto the image plane. This is because
any point in the image deﬁnes a ray in space that meets the plane at inﬁnity in a single
point. Thus, the plane at inﬁnity in the world does not tell us anything new about the
image. The absolute conic, however being a conic in the plane at inﬁnity must project
to a conic in the image. The resulting image curve is called the Image of the Absolute
Conic, or IAC. If the location of the IAC is known in an image, then we say that the
camera is calibrated.
In a calibrated camera, it is possible to determine the angle between the two rays
back-projected from two points in the image. We have seen that the angle between two
lines in space is determined by where they meet the plane at inﬁnity, relative to the
absolute conic. In a calibrated camera, the plane at inﬁnity and the absolute conic Ω∞
are projected one-to-one onto the image plane and the IAC, denoted ω. The projective
relationship between the two image points and ω is exactly equal to the relationship
between the intersections of the back-projected rays with the plane at inﬁnity, and Ω∞.
Consequently, knowing the IAC, one can measure the angle between rays by direct
measurements in the image. Thus, for a calibrated camera, one can measure angles
between rays, compute the ﬁeld of view represented by an image patch or determine
whether an ellipse in the image back-projects to a circular cone. Later on, we will see
that it helps us to determine the Euclidean structure of a reconstructed scene.
Example1.1. 3D reconstructions from paintings
Using techniques of projective geometry, it is possible in many instances to reconstruct
scenes from a single image. This cannot be done without some assumptions being
made about the imaged scene. Typical techniques involve the analysis of features such
as parallel lines and vanishing points to determine the afﬁne structure of the scene, for

10

1 Introduction – a Tour of Multiple View Geometry

a

c

b

d

Fig. 1.2. Single view reconstruction. (a) Original painting – St. Jerome in his study, 1630, Hendrick
van Steenwijck (1580-1649), Joseph R. Ritman Private Collection, Amsterdam, The Netherlands. (b)
(c)(d) Views of the 3D model created from the painting. Figures courtesy of Antonio Criminisi.

example by determining the line at inﬁnity for observed planes in the image. Knowl-
edge (or assumptions) about angles observed in the scene, most particularly orthogonal
lines or planes, can be used to upgrade the afﬁne reconstruction to Euclidean.
It is not yet possible for such techniques to be fully automatic. However, projective
geometric knowledge may be built into a system that allows user-guided single-view
reconstruction of the scene.
Such techniques have been used to reconstruct 3D texture mapped graphical models
derived from old-master paintings. Starting in the Renaissance, paintings with ex-
tremely accurate perspective were produced. In ﬁgure 1.2 a reconstruction carried out
from such a painting is shown.
△

1.3 Reconstruction from more than one view

We now turn to one of the major topics in the book – that of reconstructing a scene
from several images. The simplest case is that of two images, which we will consider
ﬁrst. As a mathematical abstraction, we restrict the discussion to “scenes” consisting
of points only.
The usual input to many of the algorithms given in this book is a set of point cor-
respondences. In the two-view case, therefore, we consider a set of correspondences

1.3 Reconstruction from more than one view

11
xi ↔ x′i in two images. It is assumed that there exist some camera matrices, P and P′
and a set of 3D points Xi that give rise to these image correspondences in the sense
that PXi = xi and P′Xi = x′i. Thus, the point Xi projects to the two given data points.
However, neither the cameras (represented by projection matrices P and P′), nor the
points Xi are known. It is our task to determine them.
It is clear from the outset that it is impossible to determine the positions of the points
uniquely. This is a general ambiguity that holds however many images we are given,
and even if we have more than just point correspondence data. For instance, given
several images of a cube, it is impossible to tell its absolute position (is it located in
a night-club in Addis Ababa, or the British Museum), its orientation (which face is
facing north) or its scale. We express this by saying that the reconstruction is possible
at best up to a similarity transformation of the world. However, it turns out that unless
something is known about the calibration of the two cameras, the ambiguity in the
reconstruction is expressed by a more general class of transformations – projective
transformations.
This ambiguity arises because it is possible to apply a projective transformation (rep-
resented by a 4 × 4 matrix H) to each point Xi, and on the right of each camera matrix
Pj, without changing the projected image points, thus:
(1.1)
PjXi = (PjH−1)(HXi).
There is no compelling reason to choose one set of points and camera matrices over the
other. The choice of H is essentially arbitrary, and we say that the reconstruction has a
projective ambiguity, or is a projective reconstruction.
However, the good news is that this is the worst that can happen. It is possible to
reconstruct a set of points from two views, up to an unavoidable projective ambiguity.
Well, to be able to say this, we need to make a few qualiﬁcations; there must be sufﬁ-
ciently many points, at least seven, and they must not lie in one of various well-deﬁned
critical conﬁgurations.
The basic tool in the reconstruction of point sets from two views is the fundamental
matrix, which represents the constraint obeyed by image points x and x′ if they are
to be images of the same 3D point. This constraint arises from the coplanarity of the
camera centres of the two views, the images points and the space point. Given the
fundamental matrix F, a pair of matching points xi ↔ x′i must satisfy

x′i

TFxi = 0

where F is a 3 × 3 matrix of rank 2. These equations are linear in the entries of the
matrix F, which means that if F is unknown, then it can be computed from a set of point
correspondences.
A pair of camera matrices P and P′ uniquely determine a fundamental matrix F, and
conversely, the fundamental matrix determines the pair of camera matrices, up to a 3D
projective ambiguity. Thus, the fundamental matrix encapsulates the complete projec-
tive geometry of the pair of cameras, and is unchanged by projective transformation of
3D.

12

1 Introduction – a Tour of Multiple View Geometry

The fundamental-matrix method for reconstructing the scene is very simple, consist-

ing of the following steps:

equations in the entries of F based on the coplanarity equations x′i

(i) Given several point correspondences xi ↔ x′i across two views, form linear
(ii) Find F as the solution to a set of linear equations.
(iii) Compute a pair of camera matrices from F according to the simple formula
given in section 9.5(p253).
(iv) Given the two cameras (P, P′) and the corresponding image point pairs xi ↔ x′i,
ﬁnd the 3D point Xi that projects to the given image points. Solving for X in
this way is known as triangulation.

TFxi = 0.

The algorithm given here is an outline only, and each part of it is examined in de-
tail in this book. The algorithm should not be implemented directly from this brief
description.

1.4 Three-view geometry

In the last section it was discussed how reconstruction of a set of points, and the relative
placement of the cameras, is possible from two views of a set of points. The reconstruc-
tion is possible only up to a projective transformation of space, and the corresponding
adjustment to the camera matrices.
In this section, we consider the case of three views. Whereas for two views, the
basic algebraic entity is the fundamental matrix, for three views this role is played by
the trifocal tensor. The trifocal tensor is a 3 × 3 × 3 array of numbers that relate the
coordinates of corresponding points or lines in three views. Just as the fundamental
matrix is determined by the two camera matrices, and determines them up to projective
transformation, so in three views, the trifocal tensor is determined by the three camera
matrices, and in turn determines them, again up to projective transformation. Thus, the
trifocal tensor encapsulates the relative projective geometry of the three cameras.
For reasons that will be explained in chapter 15 it is usual to write some of the indices
of a tensor as lower and some as upper indices. These are referred to as the covariant
and contravariant indices. The trifocal tensor is of the form T jk
, having two upper and
one lower index.
The most basic relationship between image entities in three views concerns a corre-
spondence between two lines and a point. We consider a correspondence x ↔ l′ ↔ l′′
between a point x in one image and two lines l′ and l′′ in the other two images. This
relationship means that there is a point X in space that maps to x in the ﬁrst image, and
to points x′ and x′′ lying on the lines l′ and l′′ in the other two images. The coordinates
of these three images are then related via the trifocal tensor relationship:

i

xil′jl′′kT jk

i = 0.

(1.2)

’ijk

This relationship gives a single linear relationship between the elements of the tensor.
With sufﬁciently many such correspondences, it is possible to solve linearly for the

1.5 Four view geometry and n-view reconstruction

13
elements of the tensor. Fortunately, one can obtain more equations from a point corre-
spondence x ↔ x′ ↔ x′′. In fact, in this situation, one can choose any lines l′ and l′′
passing through the points x′ and x′′ and generate a relation of the sort (1.2). Since it
is possible to choose two independent lines passing through x′, and two others passing
through x′′, one can obtain four independent equations in this way. A total of seven
point correspondences are sufﬁcient to compute the trifocal tensor linearly in this way.
It can be computed from a minimum of six point correspondences using a non-linear
method.
The 27 elements of the tensor are not independent, however, but are related by a set
of so called internal constraints. These constraints are quite complicated, but tensors
satisfying the constraints can be computed in various ways, for instance by using the
6 point non-linear method. The fundamental matrix (which is a 2-view tensor) also
satisﬁes an internal constraint but a relatively simple one: the elements obey det F = 0.
As with the fundamental matrix, once the trifocal tensor is known, it is possible to
extract the three camera matrices from it, and thereby obtain a reconstruction of the
scene points and lines. As ever, this reconstruction is unique only up to a 3D projective
transformation; it is a projective reconstruction.
Thus, we are able to generalize the method for two views to three views. There are
several advantages to using such a three-view method for reconstruction.

(i) It is possible to use a mixture of line and point correspondences to compute the
projective reconstruction. With two views, only point correspondences can be
used.
(ii) Using three views gives greater stability to the reconstruction, and avoids unsta-
ble conﬁgurations that may occur using only two views for the reconstruction.

1.5 Four view geometry and n-view reconstruction

It is possible to go one more step with tensor-based methods and deﬁne a quadrifocal
tensor relating entities visible in four views. This method is seldom used, however, be-
cause of the relative difﬁculty of computing a quadrifocal tensor that obey its internal
constraints. Nevertheless, it does provide a non-iterative method for computing a pro-
jective reconstruction based on four views. The tensor method does not extend to more
than four views, however, and so reconstruction from more than four views becomes
more difﬁcult.
Many methods have been considered for reconstruction from several views, and we
consider a few of these in the book. One way to proceed is to reconstruct the scene
bit by bit, using three-view or two-view techniques. Such a method may be applied to
any image sequence, and with care in selecting the right triples to use, it will generally
succeed.
There are methods that can be used in speciﬁc circumstances. The task of reconstruc-
tion becomes easier if we are able to apply a simpler camera model, known as the afﬁne
camera. This camera model is a fair approximation to perspective projection whenever
the distance to the scene is large compared with the difference in depth between the
back and front of the scene. If a set of points are visible in all of a set of n views

1 Introduction – a Tour of Multiple View Geometry

14
involving an afﬁne camera, then a well-known algorithm, the factorization algorithm,
can be used to compute both the structure of the scene, and the speciﬁc camera models
in one step using the Singular Value Decomposition. This algorithm is very reliable
and simple to implement. Its main difﬁculties are the use of the afﬁne camera model,
rather than a full projective model, and the requirement that all the points be visible in
all views.
This method has been extended to projective cameras in a method known as projec-
tive factorization. Although this method is generally satisfactory, it can not be proven
to converge to the correct solution in all cases. Besides, it also requires all points to be
visible in all images.
Other methods for n-view reconstruction involve various assumptions, such as
knowledge of four coplanar points in the world visible in all views, or six or seven
points that are visible in all images in the sequence. Methods that apply to speciﬁc mo-
tion sequences, such as linear motion, planar motion or single axis (turntable) motion
have also been developed.
The dominant methodology for the general reconstruction problem is bundle adjust-
ment. This is an iterative method, in which one attempts to ﬁt a non-linear model to
the measured data (the point correspondences). The advantage of bundle-adjustment is
that it is a very general method that may be applied to a wide range of reconstruction
and optimization problems. It may be implemented in such a way that the discovered
solution is the Maximum Likelihood solution to the problem, that is a solution that is in
some sense optimal in terms of a model for the inaccuracies of image measurements.
Unfortunately, bundle adjustment is an iterative process, which can not be guaran-
teed to converge to the optimal solution from an arbitrary starting point. Much research
in reconstruction methods seeks easily computable non-optimal solutions that can be
used as a starting point for bundle adjustment. An initialization step followed by bundle
adjustment is the generally preferred technique for reconstruction. A common impres-
sion is that bundle-adjustment is necessarily a slow technique. The truth is that it is
quite efﬁcient when implemented carefully. A lengthy appendix in this book deals
with efﬁcient methods of bundle adjustment.
Using n-view reconstruction techniques, it is possible to carry out reconstructions
automatically from quite long sequences of images. An example is given in ﬁgure 1.3,
showing a reconstruction from 700 frames.

1.6 Transfer

We have discussed 3D reconstruction from a set of images. Another useful application
of projective geometry is that of transfer: given the position of a point in one (or more)
image(s), determine where it will appear in all other images of the set. To do this, we
must ﬁrst establish the relationship between the cameras using (for instance) a set of
auxiliary point correspondences. Conceptually transfer is straightforward given that a
reconstruction is possible. For instance, suppose the point is identiﬁed in two views (at
x and x′) and we wish to know its position x′′ in a third, then this may be computed by
the following steps:

1.6 Transfer

15

(b)

(c)

(a)

Fig. 1.3. Reconstruction. (a) Seven frames of a 700 frame sequence acquired by a hand held camera
whilst walking down a street in Oxford. (b)(c) Two views of the reconstructed point cloud and camera
path (the red curve). Figures courtesy of David Capel and 2d3 (www.2d3.com).

16

1 Introduction – a Tour of Multiple View Geometry

Fig. 1.4. Projective ambiguity: Reconstructions of a mug (shown with the true shape in the centre)
under 3D projective transformations in the Z direction. Five examples of the cup with different degrees
of projective distortion are shown. The shapes are quite different from the original.

respondences xi ↔ x′i ↔ x′′i .

(i) Compute the camera matrices of the three views P, P′, P′′ from other point cor-
(ii) Triangulate the 3D point X from x and x′ using P and P′.
(iii) Project the 3D point into the third view as x′′ = P′′X.

This procedure only requires projective information. An alternative procedure is to use
the multi-view tensors (the fundamental matrix and trifocal tensor) to transfer the point
directly without an explicit 3D reconstruction. Both methods have their advantages.
Suppose the camera rotates about its centre or that all the scene points of interest
lie on a plane. Then the appropriate multiple view relations are the planar projective
transformations between the images. In this case, a point seen in just one image can be
transferred to any other image.

1.7 Euclidean reconstruction

So far we have considered the reconstruction of a scene, or transfer, for images taken
with a set of uncalibrated cameras. For such cameras, important parameters such as
the focal length, the geometric centre of the image (the principal point) and possibly
the aspect ratio of the pixels in the image are unknown. If a complete calibration of
each of the cameras is known then it is possible to remove some of the ambiguity of
the reconstructed scene.
So far, we have discussed projective reconstruction, which is all that is possible with-
out knowing something about the calibration of the cameras or the scene. Projective
reconstruction is insufﬁcient for many purposes, such as application to computer graph-
ics, since it involves distortions of the model that appear strange to a human used to
viewing a Euclidean world. For instance, the distortions that projective transformations
induce in a simple object are shown in ﬁgure 1.4. Using the technique of projective re-
construction, there is no way to choose between any of the possible shapes of the mug
in ﬁgure 1.4, and a projective reconstruction algorithm is as likely to come up with
any one of the reconstructions shown there as any other. Even more severely distorted
models may arise from projective reconstruction.
In order to obtain a reconstruction of the model in which objects have their correct
(Euclidean) shape, it is necessary to determine the calibration of the cameras. It is
easy to see that this is sufﬁcient to determine the Euclidean structure of the scene.
As we have seen, determining the Euclidean structure of the world is equivalent to
specifying the plane at inﬁnity and the absolute conic. In fact, since the absolute conic

1.8 Auto-calibration

17
lies in a plane, the plane at inﬁnity, it is enough to ﬁnd the absolute conic in space.
Now, suppose that we have computed a projective reconstruction of the world, using
calibrated cameras. By deﬁnition, this means that the IAC is known in each of the
images; let it be denoted by ωi in the i-th image. The back-projection of each ωi is a
cone in space, and the absolute conic must lie in the intersection of all the cones. Two
cones in general intersect in a fourth-degree curve, but given that they must intersect in
a conic, this curve must split into two conics. Thus, reconstruction of the absolute conic
from two images is not unique – rather, there are two possible solutions in general.
However, from three or more images, the intersection of the cones is unique in general.
Thus the absolute conic is determined and with it the Euclidean structure of the scene.
Of course, if the Euclidean structure of the scene is known, then so is the position of
the absolute conic. In this case we may project it back into each of the images, produc-
ing the IAC in each image, and hence calibrating the cameras. Thus knowledge of the
camera calibration is equivalent to being able to determine the Euclidean structure of
the scene.

1.8 Auto-calibration

Without any knowledge of the calibration of the cameras, it is impossible to do better
than projective reconstruction. There is no information in a set of feature correspon-
dences across any number of views that can help us ﬁnd the image of the absolute
conic, or equivalently the calibration of the cameras. However, if we know just a little
about the calibration of the cameras then we may be able to determine the position of
the absolute conic.
Suppose, for instance that it is known that the calibration is the same for each of the
cameras used in reconstructing a scene from an image sequence. By this we mean the
following. In each image a coordinate system is deﬁned, in which we have measured
the image coordinates of corresponding features used to do projective reconstruction.
Suppose that in all these image coordinate systems, the IAC is the same, but just where
it is located is unknown. From this knowledge, we wish to compute the position of the
absolute conic.
One way to ﬁnd the absolute conic is to hypothesize the position of the IAC in one
image; by hypothesis, its position in the other images will be the same. The back-
projection of each of the conics will be a cone in space. If the three cones all meet in a
single conic, then this must be a possible solution for the position of the absolute conic,
consistent with the reconstruction.
Note that this is a conceptual description only. The IAC is of course a conic con-
taining only complex points, and its back-projection will be a complex cone. However,
algebraically, the problem is more tractable. Although it is complex, the IAC may be
described by a real quadratic form (represented by a real symmetric matrix). The back-
projected cone is also represented by a real quadratic form. For some value of the IAC,
the three back-projected cones will meet in a conic curve in space.
Generally given three cameras known to have the same calibration, it is possible
to determine the absolute conic, and hence the calibration of the cameras. However,

1 Introduction – a Tour of Multiple View Geometry

18
although various methods have been proposed for this, it remains quite a difﬁcult prob-
lem.

Knowing the plane at inﬁnity. One method of auto-calibration is to proceed in steps
by ﬁrst determining the plane on which it lies. This is equivalent to identifying the plane
at inﬁnity in the world, and hence to determining the afﬁne geometry of the world. In
a second step, one locates the position of the absolute conic on the plane to determine
the Euclidean geometry of space. Assuming one knows the plane at inﬁnity, one can
back-project a hypothesised IAC from each of a sequence of images and intersect the
resulting cones with the plane at inﬁnity. If the IAC is chosen correctly, the intersection
curve is the absolute conic. Thus, from each pair of images one has a condition that
the back-projected cones meet in the same conic curve on the plane at inﬁnity. It turns
out that this gives a linear constraint on the entries of the matrix representing the IAC.
From a set of linear equations, one can determine the IAC, and hence the absolute
conic. Thus, auto-calibration is relatively simple, once the plane at inﬁnity has been
identiﬁed. The identiﬁcation of the plane at inﬁnity itself is substantially more difﬁcult.

Auto-calibration given square pixels in the image.
If the cameras are partially
calibrated, then it is possible to complete the calibration starting from a projective
reconstruction. One can make do with quite minimal conditions on the calibration
of the cameras, represented by the IAC. One interesting example is the square-pixel
constraint on the cameras. What this means is that a Euclidean coordinate system is
known in each image. In this case, the absolute conic, lying in the plane at inﬁnity in
the world must meet the image plane in its two circular points. The circular points in a
plane are the two points where the absolute conic meets that plane. The back-projected
rays through the circular points of the image plane must intersect the absolute conic.
Thus, each image with square pixels determines two rays that must meet the absolute
conic. Given n images, the autocalibration task then becomes that of determining a
space conic (the absolute conic) that meets a set of 2n rays in space. An equivalent
geometric picture is to intersect the set of rays with a plane and require that the set of
intersection points lie on a conic. By a simple counting argument one may see that there
are only a ﬁnite number of conics that meet eight prescribed rays in space. Therefore,
from four images one may determine the calibration, albeit up to a ﬁnite number of
possibilities.

1.9 The reward I : 3D graphical models

We have now described all the ingredients necessary to compute realistic graphics mod-
els from image sequences. From point matches between images, it is possible to carry
out ﬁrst a projective reconstruction of the point set, and determine the motion of the
camera in the chosen projective coordinate frame.
Using auto-calibration techniques, assuming some restrictions on the calibration of
the camera that captured the image sequence, the camera may be calibrated, and the
scene subsequently transformed to its true Euclidean structure.

1.10 The reward II: video augmentation

19

a

b

Fig. 1.5. (a) Three high resolution images (3000 × 2000 pixels) from a set of eleven of the cityhall in
Leuven, Belgium. (b) Three views of a Euclidean reconstruction computed from the image set showing
the 11 camera positions and point cloud.

Knowing the projective structure of the scene, it is possible to ﬁnd the epipolar ge-
ometry relating pairs of images and this restricts the correspondence search for further
matches to a line – a point in one image deﬁnes a line in the other image on which the
(as yet unknown) corresponding point must lie. In fact for suitable scenes, it is possible
to carry out a dense point match between images and create a dense 3D model of the
imaged scene. This takes the form of a triangulated shape model that is subsequently
shaded or texture-mapped from the supplied images and used to generate novel views.
The steps of this process are illustrated in ﬁgure 1.5 and ﬁgure 1.6.

1.10 The reward II: video augmentation

We ﬁnish this introduction with a further application of reconstruction methods to com-
puter graphics. Automatic reconstruction techniques have recently become widely used
in the ﬁlm industry as a means for adding artiﬁcial graphics objects in real video se-
quences. Computer analysis of the motion of the camera is replacing the previously
used manual methods for correctly aligning the artiﬁcial inserted object.
The most important requirement for realistic insertion of an artiﬁcial object in a video

20

1 Introduction – a Tour of Multiple View Geometry

a

c

e

b

d

f

Fig. 1.6. Dense reconstructions. These are computed from the cameras and image of ﬁgure 1.5. (a)
Untextured and (b) textured reconstruction of the full scene. (c) Untextured and (d) textured close up of
the area shown in the white rectangle of (b). (e) Untextured and (f) textured close up of the area shown
in the white rectangle of (d). The dense surface is computed using the three-view stereo algorithm
described in [Strecha-02]. Figures courtesy of Christoph Strecha, Frank Verbiest, and Luc Van Gool.

1.10 The reward II: video augmentation

21

a

d

b

e

c

f

Fig. 1.7. Augmented video. The animated robot is inserted into the scene and rendered using the
computed cameras of ﬁgure 1.3.
(d)-(f) The augmented
frames. Figures courtesy of 2d3 (www.2d3.com).

(a)-(c) Original frames from the sequence.

sequence is to compute the correct motion of the camera. Unless the camera motion
is correctly determined, it is impossible to generate the correct sequences of views of
the graphics model in a way that will appear consistent with the background video.
Generally, it is only the motion of the camera that is important here; we do not need to
reconstruct the scene, since it is already present in the existing video, and novel views
of the scene visible in the video are not required. The only requirement is to be able to
generate correct perspective views of the graphics model.
It is essential to compute the motion of the camera in a Euclidean frame. It is not
enough merely to know the projective motion of the camera. This is because a Eu-
clidean object is to be placed in the scene. Unless this graphics object and the cameras
are known in the same coordinate frame, then generated views of the inserted object
will be seen to distort with respect to the perceived structure of the scene seen in the
existing video.
Once the correct motion of the camera, and its calibration are known the inserted
object may be rendered into the scene in a realistic manner. If the change of the camera
calibration from frame to frame is correctly determined, then the camera may change
focal length (zoom) during the sequence. It is even possible for the principal point to
vary during the sequence through cropping.
In inserting the rendered model into the video, the task is relatively straight-forward
if it lies in front of all the existing scene. Otherwise the possibility of occlusions arises,
in which the scene may obscure parts of the model. An example of video augmentation
is shown in ﬁgure 1.7.

Part 0

The Background: Projective
Geometry, Transformations and

Estimation

La reproduction interdite (The Forbidden Reproduction), 1937, Ren´e Magritte.

Courtesy of Museum Boijmans van Beuningen, Rotterdam.

c⃝ ADAGP, Paris, and DACS, London 2000.

Outline

The four chapters in this part lay the foundation for the representations, terminology,
and notation that will be used in the subsequent parts of the book. The ideas and
notation of projective geometry are central to an analysis of multiple view geometry.
For example, the use of homogeneous coordinates enables non-linear mappings (such
as perspective projection) to be represented by linear matrix equations, and points at
inﬁnity to be represented quite naturally avoiding the awkward necessity of taking
limits.

Chapter 2 introduces projective transformations of 2-space. These are the transfor-
mations that arise when a plane is imaged by a perspective camera. This chapter is
more introductory and sets the scene for the geometry of 3-space. Most of the concepts
can be more easily understood and visualized in 2D than in 3D. Specializations of pro-
jective transformations are introduced, including afﬁne and similarity transformations.
Particular attention is focussed on the recovery of afﬁne properties (e.g. parallel lines)
and metric properties (e.g. angles between lines) from a perspective image.

Chapter 3 covers the projective geometry of 3-space. This geometry develops in
much the same manner as that of 2-space, though of course there are extra properties
arising from the additional dimension. The main new geometry here is the plane at
inﬁnity and the absolute conic.

Chapter 4 introduces estimation of geometry from image measurements, which is
one of the main topics of this book. The example of estimating a projective transfor-
mation from point correspondences is used to illustrate the basis and motivation for the
algorithms that will be used throughout the book. The important issue of what should
be minimized in a cost function, e.g. algebraic or geometric or statistical measures, is
described at length. The chapter also introduces the idea of robust estimation, and the
use of such techniques in the automatic estimation of transformations.

Chapter 5 describes how the results of estimation algorithms may be evaluated. In

particular how the covariance of an estimation may be computed.

24

2

Projective Geometry and Transformations of 2D

This chapter introduces the main geometric ideas and notation that are required to un-
derstand the material covered in this book. Some of these ideas are relatively familiar,
such as vanishing point formation or representing conics, whilst others are more es-
oteric, such as using circular points to remove perspective distortion from an image.
These ideas can be understood more easily in the planar (2D) case because they are
more easily visualized here. The geometry of 3-space, which is the subject of the later
parts of this book, is only a simple generalization of this planar case.
In particular, the chapter covers the geometry of projective transformations of the
plane. These transformations model the geometric distortion which arises when a plane
is imaged by a perspective camera. Under perspective imaging certain geometric prop-
erties are preserved, such as collinearity (a straight line is imaged as a straight line),
whilst others are not, for example parallel lines are not imaged as parallel lines in
general. Projective geometry models this imaging and also provides a mathematical
representation appropriate for computations.
We begin by describing the representation of points, lines and conics in homoge-
neous notation, and how these entities map under projective transformations. The line
at inﬁnity and the circular points are introduced, and it is shown that these capture the
afﬁne and metric properties of the plane. Algorithms for rectifying planes are then
given which enable afﬁne and metric properties to be computed from images. We end
with a description of ﬁxed points under projective transformations.

2.1 Planar geometry

The basic concepts of planar geometry are familiar to anyone who has studied math-
ematics even at an elementary level. In fact, they are so much a part of our everyday
experience that we take them for granted. At an elementary level, geometry is the study
of points and lines and their relationships.
To the purist, the study of geometry ought properly to be carried out from a “geomet-
ric” or coordinate-free viewpoint. In this approach, theorems are stated and proved in
terms of geometric primitives only, without the use of algebra. The classical approach
of Euclid is an example of this method. Since Descartes, however, it has been seen that
geometry may be algebraicized, and indeed the theory of geometry may be developed

25

2 Projective Geometry and Transformations of 2D

26
from an algebraic viewpoint. Our approach in this book will be a hybrid approach,
sometimes using geometric, and sometimes algebraic methods. In the algebraic ap-
proach, geometric entities are described in terms of coordinates and algebraic entities.
Thus, for instance a point is identiﬁed with a vector in terms of some coordinate basis.
A line is also identiﬁed with a vector, and a conic section (more brieﬂy, a conic) is
represented by a symmetric matrix. In fact, we often carry this identiﬁcation so far as
to consider that the vector actually is a point, or the symmetric matrix is a conic, at
least for convenience of language. A signiﬁcant advantage of the algebraic approach
to geometry is that results derived in this way may more easily be used to derive algo-
rithms and practical computational methods. Computation and algorithms are a major
concern in this book, which justiﬁes the use of the algebraic method.

2.2 The 2D projective plane

As we all know, a point in the plane may be represented by the pair of coordinates
(x, y) in IR2. Thus, it is common to identify the plane with IR2. Considering IR2 as a
vector space, the coordinate pair (x, y) is a vector – a point is identiﬁed as a vector. In
this section we introduce the homogeneous notation for points and lines on a plane.

Row and column vectors. Later on, we will want to consider linear mappings be-
tween vector spaces, and represent such mappings as matrices. In the usual manner, the
product of a matrix and a vector is another vector, the image under the mapping. This
brings up the distinction between “column” and “row” vectors, since a matrix may be
multiplied on the right by a column and on the left by a row vector. Geometric entities
will by default be represented by column vectors. A bold-face symbol such as x always
represents a column vector, and its transpose is the row vector xT. In accordance with
this convention, a point in the plane will be represented by the column vector (x, y)T,
rather than its transpose, the row vector (x, y). We write x = (x, y)T, both sides of this
equation representing column vectors.

2.2.1 Points and lines
Homogeneous representation of lines. A line in the plane is represented by an equa-
tion such as ax+by +c = 0, different choices of a, b and c giving rise to different lines.
Thus, a line may naturally be represented by the vector (a, b, c)T. The correspondence
between lines and vectors (a, b, c)T is not one-to-one, since the lines ax + by + c = 0
and (ka)x + (kb)y + (kc) = 0 are the same, for any non-zero constant k. Thus, the
vectors (a, b, c)T and k(a, b, c)T represent the same line, for any non-zero k. In fact,
two such vectors related by an overall scaling are considered as being equivalent. An
equivalence class of vectors under this equivalence relationship is known as a homo-
geneous vector. Any particular vector (a, b, c)T is a representative of the equivalence
class. The set of equivalence classes of vectors in IR3 − (0, 0, 0)T forms the projective
space IP2. The notation −(0, 0, 0)T indicates that the vector (0, 0, 0)T, which does not
correspond to any line, is excluded.

2.2 The 2D projective plane

27
Homogeneous representation of points. A point x = (x, y)T lies on the line l =
(a, b, c)T if and only if ax + by + c = 0. This may be written in terms of an inner
product of vectors representing the point as (x, y, 1)(a, b, c)T = (x, y, 1)l = 0; that is
the point (x, y)T in IR2 is represented as a 3-vector by adding a ﬁnal coordinate of 1.
Note that for any non-zero constant k and line l the equation (kx, ky, k)l = 0 if and
only if (x, y, 1)l = 0. It is natural, therefore, to consider the set of vectors (kx, ky, k)T
for varying values of k to be a representation of the point (x, y)T in IR2. Thus, just as
with lines, points are represented by homogeneous vectors. An arbitrary homogeneous
vector representative of a point is of the form x = (x1, x2, x3)T, representing the point
(x1/x3, x2/x3)T in IR2. Points, then, as homogeneous vectors are also elements of IP2.

One has a simple equation to determine when a point lies on a line, namely

Result2.1. The point x lies on the line l if and only if xTl = 0.
Note that the expression xTl is just the inner or scalar product of the two vectors l
and x. The scalar product xTl = lTx = x.l. In general, the transpose notation lTx
will be preferred, but occasionally, we will use a . to denote the inner product. We
distinguish between the homogeneous coordinates x = (x1, x2, x3)T of a point, which
is a 3-vector, and the inhomogeneous coordinates (x, y)T, which is a 2-vector.
Degrees of freedom (dof). It is clear that in order to specify a point two values must
be provided, namely its x- and y-coordinates. In a similar manner a line is speciﬁed
by two parameters (the two independent ratios {a : b : c}) and so has two degrees
of freedom. For example, in an inhomogeneous representation, these two parameters
could be chosen as the gradient and y intercept of the line.
Intersection of lines. Given two lines l = (a, b, c)T and l′ = (a′, b′, c′)T, we wish to
ﬁnd their intersection. Deﬁne the vector x = l × l′, where × represents the vector or
cross product. From the triple scalar product identity l.(l × l′) = l′.(l × l′) = 0, we
see that lTx = l′Tx = 0. Thus, if x is thought of as representing a point, then x lies on
both lines l and l′, and hence is the intersection of the two lines. This shows:
Result2.2. The intersection of two lines l and l′ is the point x = l × l′.
Note that the simplicity of this expression for the intersection of the two lines is a direct
consequence of the use of homogeneous vector representations of lines and points.
Example2.3. Consider the simple problem of determining the intersection of the lines
x = 1 and y = 1. The line x = 1 is equivalent to −1x + 1 = 0, and thus has
homogeneous representation l = (−1, 0, 1)T. The line y = 1 is equivalent to −1y+1 =
0, and thus has homogeneous representation l′ = (0,−1, 1)T. From result 2.2 the
intersection point is

x = l × l′ =(((((((

j
0

i
k
−1
1
0 −1 1

which is the inhomogeneous point (1, 1)T as required.

=⎛⎜⎝

(((((((

1
1
1

⎞⎟⎠

△

2 Projective Geometry and Transformations of 2D

28
Line joining points. An expression for the line passing through two points x and x′
may be derived by an entirely analogous argument. Deﬁning a line l by l = x × x′, it
may be veriﬁed that both points x and x′ lie on l. Thus
Result2.4. The line through two points x and x′ is l = x × x′.
2.2.2 Ideal points and the line at inﬁnity
Intersection of parallel lines. Consider two lines ax+by+c = 0 and ax+by+c′ = 0.
These are represented by vectors l = (a, b, c)T and l′ = (a, b, c′)T for which the ﬁrst two
coordinates are the same. Computing the intersection of these lines gives no difﬁculty,
using result 2.2. The intersection is l × l′ = (c′ − c)(b,−a, 0)T, and ignoring the scale
factor (c′ − c), this is the point (b,−a, 0)T.
Now if we attempt to ﬁnd the inhomogeneous representation of this point, we ob-
tain (b/0,−a/0)T, which makes no sense, except to suggest that the point of intersec-
tion has inﬁnitely large coordinates. In general, points with homogeneous coordinates
(x, y, 0)T do not correspond to any ﬁnite point in IR2. This observation agrees with the
usual idea that parallel lines meet at inﬁnity.
Example2.5. Consider the two lines x = 1 and x = 2. Here the two lines are parallel,
and consequently intersect “at inﬁnity”. In homogeneous notation the lines are l =
(−1, 0, 1)T, l′ = (−1, 0, 2)T, and from result 2.2 their intersection point is

x = l × l′ =(((((((

i
j k
−1 0 1
−1 0 2

0
1
0
which is the point at inﬁnity in the direction of the y-axis.
△
Ideal points and the line at inﬁnity. Homogeneous vectors x = (x1, x2, x3)T such
that x3 ̸= 0 correspond to ﬁnite points in IR2. One may augment IR2 by adding points
with last coordinate x3 = 0. The resulting space is the set of all homogeneous 3-
vectors, namely the projective space IP2. The points with last coordinate x3 = 0 are
known as ideal points, or points at inﬁnity. The set of all ideal points may be written
(x1, x2, 0)T, with a particular point speciﬁed by the ratio x1 : x2. Note that this set lies
on a single line, the line at inﬁnity, denoted by the vector l∞ = (0, 0, 1)T. Indeed, one
veriﬁes that (0, 0, 1)(x1, x2, 0)T = 0.
Using result 2.2 one ﬁnds that a line l = (a, b, c)T intersects l∞ in the ideal point
(b,−a, 0)T (since (b,−a, 0)l = 0). A line l′ = (a, b, c′)T parallel to l intersects l∞
in the same ideal point (b,−a, 0)T irrespective of the value of c′. In inhomogeneous
notation (b,−a)T is a vector tangent to the line, and orthogonal to the line normal
(a, b), and so represents the line’s direction. As the line’s direction varies the ideal
point (b,−a, 0)T varies over l∞. For these reasons the line at inﬁnity can be thought of
as the set of directions of lines in the plane.
Note how the introduction of the concept of points at inﬁnity serves to simplify the
intersection properties of points and lines. In the projective plane IP2, one may state
without qualiﬁcation that two distinct lines meet in a single point and two distinct

=⎛⎜⎝

(((((((

⎞⎟⎠

2.2 The 2D projective plane

x

2

29

ideal
point

x1

l

x

O

(cid:83)

x 3

Fig. 2.1. A model of the projective plane. Points and lines of IP2 are represented by rays and planes,
respectively, through the origin in IR3. Lines lying in the x1x2-plane represent ideal points, and the
x1x2-plane represents l∞.

points lie on a single line. This is not true in the standard Euclidean geometry of IR2,
in which parallel lines form a special case.
The study of the geometry of IP2 is known as projective geometry. In a coordinate-
free purely geometric study of projective geometry, one does not make any distinction
between points at inﬁnity (ideal points) and ordinary points. It will, however, serve
our purposes in this book sometimes to distinguish between ideal points and non-ideal
points. Thus, the line at inﬁnity will at times be considered as a special line in projective
space.

A model for the projective plane. A fruitful way of thinking of IP2 is as a set of
rays in IR3. The set of all vectors k(x1, x2, x3)T as k varies forms a ray through the
origin. Such a ray may be thought of as representing a single point in IP2. In this
model, the lines in IP2 are planes passing through the origin. One veriﬁes that two non-
identical rays lie on exactly one plane, and any two planes intersect in one ray. This
is the analogue of two distinct points uniquely deﬁning a line, and two lines always
intersecting in a point.
Points and lines may be obtained by intersecting this set of rays and planes by the
plane x3 = 1. As illustrated in ﬁgure 2.1 the rays representing ideal points and the
plane representing l∞ are parallel to the plane x3 = 1.
Duality. The reader has probably noticed how the role of points and lines may be
interchanged in statements concerning the properties of lines and points. In particular,
the basic incidence equation lTx = 0 for line and point is symmetric, since lTx = 0
implies xTl = 0, in which the positions of line and point are swapped. Similarly,
result 2.2 and result 2.4 giving the intersection of two lines and the line through two
points are essentially the same, with the roles of points and lines swapped. One may
enunciate a general principle, the duality principle as follows:

2 Projective Geometry and Transformations of 2D

30
Result2.6. Duality principle. To any theorem of 2-dimensional projective geometry
there corresponds a dual theorem, which may be derived by interchanging the roles of
points and lines in the original theorem.
In applying this principle, concepts of incidence must be appropriately translated as
well. For instance, the line through two points is dual to the point through (that is the
point of intersection of) two lines.
Note that is it not necessary to prove the dual of a given theorem once the original
theorem has been proved. The proof of the dual theorem will be the dual of the proof
of the original theorem.
2.2.3 Conics and dual conics
A conic is a curve described by a second-degree equation in the plane. In Euclidean
geometry conics are of three main types: hyperbola, ellipse, and parabola (apart from
so-called degenerate conics, to be deﬁned later). Classically these three types of conic
arise as conic sections generated by planes of differing orientation (the degenerate con-
ics arise from planes which contain the cone vertex). However, it will be seen that
in 2D projective geometry all non-degenerate conics are equivalent under projective
transformations.

The equation of a conic in inhomogeneous coordinates is
ax2 + bxy + cy2 + dx + ey + f = 0

i.e. a polynomial of degree 2. “Homogenizing” this by the replacements:
x ’→ x1/x3, y ’→ x2/x3 gives

2 + bx1x2 + cx2

2 + dx1x3 + ex2x3 + f x3

2 = 0

ax1

or in matrix form

xTCx = 0
where the conic coefﬁcient matrix C is given by

(2.1)

(2.2)

(2.3)

C =⎡⎢⎣

b/2 d/2
a
e/2
b/2
c
d/2 e/2
f

⎤⎥⎦ .

Note that the conic coefﬁcient matrix is symmetric. As in the case of the homogeneous
representation of points and lines, only the ratios of the matrix elements are important,
since multiplying C by a non-zero scalar does not affect the above equations. Thus C is
a homogeneous representation of a conic. The conic has ﬁve degrees of freedom which
can be thought of as the ratios {a : b : c : d : e : f} or equivalently the six elements of
a symmetric matrix less one for scale.
Five points deﬁne a conic. Suppose we wish to compute the conic which passes
through a set of points, xi. How many points are we free to specify before the conic
is determined uniquely? The question can be answered constructively by providing an

2.2 The 2D projective plane

31
algorithm to determine the conic. From (2.1) each point xi places one constraint on the
conic coefﬁcients, since if the conic passes through (xi, yi) then
2 + dxi + eyi + f = 0.

axi

2 + bxiyi + cyi

This constraint can be written as
/ x2

i xiyi y2

i xi yi 1 0 c = 0

where c = (a, b, c, d, e, f )T is the conic C represented as a 6-vector.

Stacking the constraints from ﬁve points we obtain
1 x1 y1 1
2 x2 y2 1
3 x3 y3 1
4 x4 y4 1
5 x5 y5 1

x2
1 x1y1 y2
x2
2 x2y2 y2
x2
3 x3y3 y2
x2
4 x4y4 y2
x2
5 x5y5 y2

⎡⎢⎢⎢⎢⎢⎢⎣

⎤⎥⎥⎥⎥⎥⎥⎦

c = 0

(2.4)

and the conic is the null vector of this 5 × 6 matrix. This shows that a conic is deter-
mined uniquely (up to scale) by ﬁve points in general position. The method of ﬁtting
a geometric entity (or relation) by determining a null space will be used frequently in
the computation chapters throughout this book.
Tangent lines to conics. The line l tangent to a conic at a point x has a particularly
simple form in homogeneous coordinates:
Result2.7. The line l tangent to C at a point x on C is given by l = Cx.
Proof. The line l = Cx passes through x, since lTx = xTCx = 0. If l has one-point
contact with the conic, then it is a tangent, and we are done. Otherwise suppose that l
meets the conic in another point y. Then yTCy = 0 and xTCy = lTy = 0. From this
it follows that (x + αy)TC(x + αy) = 0 for all α, which means that the whole line
l = Cx joining x and y lies on the conic C, which is therefore degenerate (see below).

Dual conics. The conic C deﬁned above is more properly termed a point conic, as it
deﬁnes an equation on points. Given the duality result 2.6 of IP2 it is not surprising
that there is also a conic which deﬁnes an equation on lines. This dual (or line) conic
is also represented by a 3 × 3 matrix, which we denote as C∗. A line l tangent to the
conic C satisﬁes lTC∗l = 0. The notation C∗ indicates that C∗ is the adjoint matrix of C
(the adjoint is deﬁned in section A4.2(p580) of appendix 4(p578)). For a non-singular
symmetric matrix C∗ = C−1 (up to scale).
The equation for a dual conic is straightforward to derive in the case that C has full
rank: From result 2.7, at a point x on C the tangent is l = Cx. Inverting, we ﬁnd the
point x at which the line l is tangent to C is x = C−1l. Since x satisﬁes xTCx = 0 we
obtain (C−1l)TC(C−1l) = lTC−1l = 0, the last step following from C−T = C−1 because
C is symmetric.
Dual conics are also known as conic envelopes, and the reason for this is illustrated

32

2 Projective Geometry and Transformations of 2D

a

b

Fig. 2.2. (a) Points x satisfying xTCx = 0 lie on a point conic. (b) Lines l satisfying lTC∗l = 0 are
tangent to the point conic C. The conic C is the envelope of the lines l.

in ﬁgure 2.2. A dual conic has ﬁve degrees of freedom. In a similar manner to points
deﬁning a point conic, it follows that ﬁve lines in general position deﬁne a dual conic.
Degenerate conics. If the matrix C is not of full rank, then the conic is termed degen-
erate. Degenerate point conics include two lines (rank 2), and a repeated line (rank
1).
Example2.8. The conic

C = l mT + m lT

is composed of two lines l and m. Points on l satisfy lTx = 0, and are on the conic
since xTCx = (xTl)(mTx) + (xTm)(lTx) = 0. Similarly, points satisfying mTx = 0
also satisfy xTCx = 0. The matrix C is symmetric and has rank 2. The null vector is
x = l × m which is the intersection point of l and m.
△
Degenerate line conics include two points (rank 2), and a repeated point (rank 1).
For example, the line conic C∗ = xyT + yxT has rank 2 and consists of lines passing
through either of the two points x and y. Note that for matrices that are not invertible
(C∗)∗ ̸= C.

2.3 Projective transformations

In the view of geometry set forth by Felix Klein in his famous “Erlangen Program”,
[Klein-39], geometry is the study of properties invariant under groups of transforma-
tions. From this point of view, 2D projective geometry is the study of properties of
the projective plane IP2 that are invariant under a group of transformations known as
projectivities.
A projectivity is an invertible mapping from points in IP2 (that is homogeneous 3-
vectors) to points in IP2 that maps lines to lines. More precisely,
Deﬁnition2.9. A projectivity is an invertible mapping h from IP2 to itself such that
three points x1, x2 and x3 lie on the same line if and only if h(x1), h(x2) and h(x3) do.
Projectivities form a group since the inverse of a projectivity is also a projectivity, and
so is the composition of two projectivities. A projectivity is also called a collineation

2.3 Projective transformations

33
(a helpful name), a projective transformation or a homography: the terms are synony-
mous.
In deﬁnition 2.9, a projectivity is deﬁned in terms of a coordinate-free geometric
concept of point line incidence. An equivalent algebraic deﬁnition of a projectivity is
possible, based on the following result.
Theorem2.10. A mapping h : IP2 → IP2 is a projectivity if and only if there exists a
non-singular 3 × 3 matrix H such that for any point in IP2 represented by a vector x it
is true that h(x) = Hx.
To interpret this theorem, any point in IP2 is represented as a homogeneous 3-vector,
x, and Hx is a linear mapping of homogeneous coordinates. The theorem asserts that
any projectivity arises as such a linear transformation in homogeneous coordinates, and
that conversely any such mapping is a projectivity. The theorem will not be proved in
full here. It will only be shown that any invertible linear transformation of homoge-
neous coordinates is a projectivity.
Proof. Let x1, x2 and x3 lie on a line l. Thus lTxi = 0 for i = 1, . . . , 3. Let H be a
non-singular 3 × 3 matrix. One veriﬁes that lTH−1Hxi = 0. Thus, the points Hxi all lie
on the line H−Tl, and collinearity is preserved by the transformation.
The converse is considerably harder to prove, namely that each projectivity arises in
this way.

As a result of this theorem, one may give an alternative deﬁnition of a projective

transformation (or collineation) as follows.
Deﬁnition2.11. Projective transformation. A planar projective transformation is a
linear transformation on homogeneous 3-vectors represented by a non-singular 3 × 3
matrix:

or more brieﬂy, x′ = Hx.

Note that the matrix H occurring in this equation may be changed by multiplication
by an arbitrary non-zero scale factor without altering the projective transformation.
Consequently we say that H is a homogeneous matrix, since as in the homogeneous
representation of a point, only the ratio of the matrix elements is signiﬁcant. There are
eight independent ratios amongst the nine elements of H, and it follows that a projective
transformation has eight degrees of freedom.
A projective transformation projects every ﬁgure into a projectively equivalent ﬁgure,
leaving all its projective properties invariant. In the ray model of ﬁgure 2.1 a projective
transformation is simply a linear transformation of IR3.

⎛⎜⎝

x′1
x′2
x′3

⎞⎟⎠ =⎡⎢⎣

h11 h12 h13
h21 h22 h23
h31 h32 h33

⎤⎥⎦

⎛⎜⎝

x1
x2
x3

⎞⎟⎠ ,

(2.5)

34

2 Projective Geometry and Transformations of 2D

O

x /

(cid:83) /

/

y

/

x

x

(cid:83)

y

x

Fig. 2.3. Central projection maps points on one plane to points on another plane. The projection
also maps lines to lines as may be seen by considering a plane through the projection centre which inter-
sects with the two planes π and π′. Since lines are mapped to lines, central projection is a projectivity
and may be represented by a linear mapping of homogeneous coordinates x′ = Hx.

Mappings between planes. As an example of how theorem 2.10 may be applied,
consider ﬁgure 2.3. Projection along rays through a common point (the centre of pro-
jection) deﬁnes a mapping from one plane to another. It is evident that this point-to-
point mapping preserves lines in that a line in one plane is mapped to a line in the other.
If a coordinate system is deﬁned in each plane and points are represented in homoge-
neous coordinates, then the central projection mapping may be expressed by x′ = Hx
where H is a non-singular 3× 3 matrix. Actually, if the two coordinate systems deﬁned
in the two planes are both Euclidean (rectilinear) coordinate systems then the mapping
deﬁned by central projection is more restricted than an arbitrary projective transforma-
tion. It is called a perspectivity rather than a full projectivity, and may be represented
by a transformation with six degrees of freedom. We return to perspectivities in section
A7.4(p632).
Example2.12. Removing the projective distortion from a perspective image of a
plane.
Shape is distorted under perspective imaging. For instance, in ﬁgure 2.4a the win-
dows are not rectangular in the image, although the originals are. In general parallel
lines on a scene plane are not parallel in the image but instead converge to a ﬁnite
point. We have seen that a central projection image of a plane (or section of a plane)
is related to the original plane via a projective transformation, and so the image is a
projective distortion of the original. It is possible to “undo” this projective transforma-
tion by computing the inverse transformation and applying it to the image. The result
will be a new synthesized image in which the objects in the plane are shown with their
correct geometric shape. This will be illustrated here for the front of the building of
ﬁgure 2.4a. Note that since the ground and the front are not in the same plane, the
projective transformation that must be applied to rectify the front is not the same as the
one used for the ground.
Computation of a projective transformation from point-to-point correspondences will
be considered in great detail in chapter 4. For now, a method for computing the trans-

2.3 Projective transformations

35

a

b

Fig. 2.4. Removing perspective distortion. (a) The original image with perspective distortion – the
lines of the windows clearly converge at a ﬁnite point. (b) Synthesized frontal orthogonal view of the
front wall. The image (a) of the wall is related via a projective transformation to the true geometry of the
wall. The inverse transformation is computed by mapping the four imaged window corners to corners
of an appropriately sized rectangle. The four point correspondences determine the transformation. The
transformation is then applied to the whole image. Note that sections of the image of the ground are
subject to a further projective distortion. This can also be removed by a projective transformation.

formation is brieﬂy indicated. One begins by selecting a section of the image corre-
sponding to a planar section of the world. Local 2D image and world coordinates are
selected as shown in ﬁgure 2.3. Let the inhomogeneous coordinates of a pair of match-
ing points x and x′ in the world and image plane be (x, y) and (x′, y′) respectively.
We use inhomogeneous coordinates here instead of the homogeneous coordinates of
the points, because it is these inhomogeneous coordinates that are measured directly
from the image and from the world plane. The projective transformation of (2.5) can
be written in inhomogeneous form as
h11x + h12y + h13
h31x + h32y + h33

h21x + h22y + h23
h31x + h32y + h33

Each point correspondence generates two equations for the elements of H, which

x′ =

=

x′1
x′3

.

,

y′ =

=

x′2
x′3

after multiplying out are

x′ (h31x + h32y + h33) = h11x + h12y + h13
y′ (h31x + h32y + h33) = h21x + h22y + h23.

These equations are linear in the elements of H. Four point correspondences lead to
eight such linear equations in the entries of H, which are sufﬁcient to solve for H up to
an insigniﬁcant multiplicative factor. The only restriction is that the four points must
be in “general position”, which means that no three points are collinear. The inverse
of the transformation H computed in this way is then applied to the whole image to
undo the effect of perspective distortion on the selected plane. The results are shown
in ﬁgure 2.4b.
△
Three remarks concerning this example are appropriate: ﬁrst, the computation of
the rectifying transformation H in this way does not require knowledge of any of the
camera’s parameters or the pose of the plane; second, it is not always necessary to

36

image 1

x

2 Projective Geometry and Transformations of 2D
X

image 2

R,t

x

image 1

x
x

X

a

planar surface

b

image 2

c

x

x

/

Fig. 2.5. Examples of a projective transformation, x′ = Hx, arising in perspective images. (a)
The projective transformation between two images induced by a world plane (the concatenation of two
projective transformations is a projective transformation); (b) The projective transformation between
two images with the same camera centre (e.g. a camera rotating about its centre or a camera varying its
focal length); (c) The projective transformation between the image of a plane (the end of the building)
and the image of its shadow onto another plane (the ground plane). Figure (c) courtesy of Luc Van Gool.

know coordinates for four points in order to remove projective distortion: alternative
approaches, which are described in section 2.7, require less, and different types of,
information; third, superior (and preferred) methods for computing projective transfor-
mations are described in chapter 4.
Projective transformations are important mappings representing many more situa-
tions than the perspective imaging of a world plane. A number of other examples are
illustrated in ﬁgure 2.5. Each of these situations is covered in more detail later in the
book.

2.3.1 Transformations of lines and conics
Transformation of lines.
It was shown in the proof of theorem 2.10 that if points xi
lie on a line l, then the transformed points x′i = Hxi under a projective transformation
lie on the line l′ = H−Tl. In this way, incidence of points on lines is preserved, since
l′Tx′i = lTH−1Hxi = 0. This gives the transformation rule for lines:
Under the point transformation x′ = Hx, a line transforms as

l′ = H−Tl.

(2.6)
One may alternatively write l′T = lTH−1. Note the fundamentally different way
in which lines and points transform. Points transform according to H, whereas lines
(as rows) transform according to H−1. This may be explained in terms of “covariant”
or “contravariant” behaviour. One says that points transform contravariantly and lines
transform covariantly. This distinction will be taken up again, when we discuss tensors
in chapter 15 and is fully explained in appendix 1(p562).

Transformation of conics. Under a point transformation x′ = Hx, (2.2) becomes

xTCx = x′T[H−1]TCH−1x′

= x′TH−TCH−1x′

2.4 A hierarchy of transformations

37

a

b

c

Fig. 2.6. Distortions arising under central projection. Images of a tiled ﬂoor. (a) Similarity: the
circular pattern is imaged as a circle. A square tile is imaged as a square. Lines which are parallel or
perpendicular have the same relative orientation in the image. (b) Afﬁne: The circle is imaged as an
ellipse. Orthogonal world lines are not imaged as orthogonal lines. However, the sides of the square
tiles, which are parallel in the world are parallel in the image. (c) Projective: Parallel world lines are
imaged as converging lines. Tiles closer to the camera have a larger image than those further away.

transformation x′ = Hx, a conic C transforms to

which is a quadratic form x′TC′x′ with C′ = H−TCH−1. This gives the transformation
rule for a conic:
Result2.13. Under a point
C′ = H−TCH−1.
The presence of H−1 in this equation may be expressed by saying that a conic transforms
covariantly. The transformation rule for a dual conic is derived in a similar manner.
This gives:
Result2.14. Under a point transformation x′ = Hx, a dual conic C∗ transforms to
C∗′ = HC∗HT.

2.4 A hierarchy of transformations

In this section we describe the important specializations of a projective transformation
and their geometric properties. It was shown in section 2.3 that projective transforma-
tions form a group. This group is called the projective linear group, and it will be seen
that these specializations are subgroups of this group.
The group of invertible n × n matrices with real elements is the (real) general linear
group on n dimensions, or GL(n). To obtain the projective linear group the matrices
related by a scalar multiplier are identiﬁed, giving P L(n) (this is a quotient group of
GL(n)). In the case of projective transformations of the plane n = 3.
The important subgroups of P L(3) include the afﬁne group, which is the subgroup
of P L(3) consisting of matrices for which the last row is (0, 0, 1), and the Euclidean
group, which is a subgroup of the afﬁne group for which in addition the upper left hand
2 × 2 matrix is orthogonal. One may also identify the oriented Euclidean group in
which the upper left hand 2 × 2 matrix has determinant 1.
We will introduce these transformations starting from the most specialized, the
isometries, and progressively generalizing until projective transformations are reached.

2 Projective Geometry and Transformations of 2D

38
This deﬁnes a hierarchy of transformations. The distortion effects of various transfor-
mations in this hierarchy are shown in ﬁgure 2.6.
Some transformations of interest are not groups, for example, perspectivities (be-
cause the composition of two perspectivities is a projectivity, not a perspectivity). This
point is covered in section A7.4(p632).
Invariants. An alternative to describing the transformation algebraically, i.e. as a ma-
trix acting on coordinates of a point or curve, is to describe the transformation in terms
of those elements or quantities that are preserved or invariant. A (scalar) invariant of a
geometric conﬁguration is a function of the conﬁguration whose value is unchanged by
a particular transformation. For example, the separation of two points is unchanged by
a Euclidean transformation (translation and rotation), but not by a similarity (e.g. trans-
lation, rotation and isotropic scaling). Distance is thus a Euclidean, but not similarity
invariant. The angle between two lines is both a Euclidean and a similarity invariant.
2.4.1 Class I: Isometries
Isometries are transformations of the plane IR2 that preserve Euclidean distance (from
iso = same, metric = measure). An isometry is represented as
x
y
1

ϵ cos θ − sin θt
cos θt
ϵ sin θ

x′
y′
1

y
1

0

0

where ϵ = ±1. If ϵ = 1 then the isometry is orientation-preserving and is a Euclidean
transformation (a composition of a translation and rotation). If ϵ = −1 then the isome-
try reverses orientation. An example is the composition of a reﬂection, represented by
the matrix diag(−1, 1, 1), with a Euclidean transformation.
Euclidean transformations model the motion of a rigid object. They are by far the
most important isometries in practice, and we will concentrate on these. However, the
orientation reversing isometries often arise as ambiguities in structure recovery.
A planar Euclidean transformation can be written more concisely in block form as
(2.7)
where R is a 2 × 2 rotation matrix (an orthogonal matrix such that RTR = RRT = I),
t a translation 2-vector, and 0 a null 2-vector. Special cases are a pure rotation (when
t = 0) and a pure translation (when R = I). A Euclidean transformation is also known
as a displacement.
A planar Euclidean transformation has three degrees of freedom, one for the rotation
and two for the translation. Thus three parameters must be speciﬁed in order to deﬁne
the transformation. The transformation can be computed from two point correspon-
dences.
Invariants. The invariants are very familiar, for instance: length (the distance be-
tween two points), angle (the angle between two lines), and area.

x′ = HEx =1 R

0T 1 2 x

t

x

⎤⎥⎦

⎛⎜⎝

⎞⎟⎠

⎛⎜⎝

⎞⎟⎠ =⎡⎢⎣

2.4 A hierarchy of transformations

39
Groups and orientation. An isometry is orientation-preserving if the upper left
hand 2 × 2 matrix has determinant 1. Orientation-preserving isometries form a group,
orientation-reversing ones do not. This distinction applies also in the case of similarity
and afﬁne transformations which now follow.

2.4.2 Class II: Similarity transformations
A similarity transformation (or more simply a similarity) is an isometry composed with
an isotropic scaling. In the case of a Euclidean transformation composed with a scaling
(i.e. no reﬂection) the similarity has matrix representation

x′
y′
1

⎛⎜⎝

s cos θ −s sin θt
cos θt
s sin θs
0

⎞⎟⎠ =⎡⎢⎣
This can be written more concisely in block form as
x′ = HSx =1 sR t
0T 1 2 x

0

x

y
1

⎤⎥⎦

⎛⎜⎝

x
y
1

⎞⎟⎠ .

(2.8)

(2.9)

where the scalar s represents the isotropic scaling. A similarity transformation is also
known as an equi-form transformation, because it preserves “shape” (form). A planar
similarity transformation has four degrees of freedom, the scaling accounting for one
more degree of freedom than a Euclidean transformation. A similarity can be computed
from two point correspondences.

Invariants. The invariants can be constructed from Euclidean invariants with suitable
provision being made for the additional scaling degree of freedom. Angles between
lines are not affected by rotation, translation or isotropic scaling, and so are similarity
invariants. In particular parallel lines are mapped to parallel lines. The length between
two points is not a similarity invariant, but the ratio of two lengths is an invariant,
because the scaling of the lengths cancels out. Similarly a ratio of areas is an invariant
because the scaling (squared) cancels out.

Metric structure. A term that will be used frequently in the discussion on reconstruc-
tion (chapter 10) is metric. The description metric structure implies that the structure
is deﬁned up to a similarity.

2.4.3 Class III: Afﬁne transformations
An afﬁne transformation (or more simply an afﬁnity) is a non-singular linear transfor-
mation followed by a translation. It has the matrix representation

x′
y′
1

⎛⎜⎝

⎞⎟⎠ =⎡⎢⎣

a11 a12
a21 a22
0
0

tx
ty
1

⎤⎥⎦

⎛⎜⎝

x
y
1

⎞⎟⎠

(2.10)

40

2 Projective Geometry and Transformations of 2D

(cid:84)
rotation
a

(cid:73)

deformation

b

Fig. 2.7. Distortions arising from a planar afﬁne transformation. (a) Rotation by R(θ). (b) A defor-
mation R(−φ) D R(φ). Note, the scaling directions in the deformation are orthogonal.
or in block form

t

x′ = HAx =1 A

0T 1 2 x

(2.11)
with A a 2 × 2 non-singular matrix. A planar afﬁne transformation has six degrees of
freedom corresponding to the six matrix elements. The transformation can be com-
puted from three point correspondences.
A helpful way to understand the geometric effects of the linear component A of
an afﬁne transformation is as the composition of two fundamental transformations,
namely rotations and non-isotropic scalings. The afﬁne matrix A can always be decom-
posed as

(2.12)
where R(θ) and R(φ) are rotations by θ and φ respectively, and D is a diagonal matrix:

A = R(θ) R(−φ) D R(φ)

D =1 λ1

0 λ2 2 .

0

This decomposition follows directly from the SVD (section A4.4(p585)): writing A =
UDVT = (UVT)(VDVT) = R(θ) (R(−φ) D R(φ)), since U and V are orthogonal matrices.
The afﬁne matrix A is hence seen to be the concatenation of a rotation (by φ); a
scaling by λ1 and λ2 respectively in the (rotated) x and y directions; a rotation back
(by −φ); and ﬁnally another rotation (by θ). The only “new” geometry, compared to
a similarity, is the non-isotropic scaling. This accounts for the two extra degrees of
freedom possessed by an afﬁnity over a similarity. They are the angle φ specifying the
scaling direction, and the ratio of the scaling parameters λ1 : λ2. The essence of an
afﬁnity is this scaling in orthogonal directions, oriented at a particular angle. Schematic
examples are given in ﬁgure 2.7.

2.4 A hierarchy of transformations

41
Invariants. Because an afﬁne transformation includes non-isotropic scaling, the sim-
ilarity invariants of length ratios and angles between lines are not preserved under an
afﬁnity. Three important invariants are:

(i) Parallel lines. Consider two parallel lines. These intersect at a point
(x1, x2, 0)T at inﬁnity. Under an afﬁne transformation this point is mapped
to another point at inﬁnity. Consequently, the parallel lines are mapped to lines
which still intersect at inﬁnity, and so are parallel after the transformation.

(ii) Ratio of lengths of parallel line segments. The length scaling of a line seg-
ment depends only on the angle between the line direction and scaling direc-
tions. Suppose the line is at angle α to the x-axis of the orthogonal scaling
direction, then the scaling magnitude is3λ2
2 sin2 α. This scaling is
common to all lines with the same direction, and so cancels out in a ratio of
parallel segment lengths.

1 cos2 α + λ2

(iii) Ratio of areas. This invariance can be deduced directly from the decomposi-
tion (2.12). Rotations and translations do not affect area, so only the scalings by
λ1 and λ2 matter here. The effect is that area is scaled by λ1λ2 which is equal to
det A. Thus the area of any shape is scaled by det A, and so the scaling cancels
out for a ratio of areas. It will be seen that this does not hold for a projective
transformation.

An afﬁnity is orientation-preserving or -reversing according to whether det A is positive
or negative respectively. Since det A = λ1λ2 the property depends only on the sign of
the scalings.

2.4.4 Class IV: Projective transformations
A projective transformation was deﬁned in (2.5). It is a general non-singular linear
transformation of homogeneous coordinates. This generalizes an afﬁne transformation,
which is the composition of a general non-singular linear transformation of inhomoge-
neous coordinates and a translation. We have earlier seen the action of a projective
transformation (in section 2.3). Here we examine its block form

x′ = HPx =1 A

vT v 2 x

t

(2.13)

where the vector v = (v1, v2)T. The matrix has nine elements with only their ratio
signiﬁcant, so the transformation is speciﬁed by eight parameters. Note, it is not always
possible to scale the matrix such that v is unity since v might be zero. A projective
transformation between two planes can be computed from four point correspondences,
with no three collinear on either plane. See ﬁgure 2.4.
Unlike the case of afﬁnities, it is not possible to distinguish between orientation
preserving and orientation reversing projectivities in IP2. We will return to this point
in section 2.6.

2 Projective Geometry and Transformations of 2D

42
Invariants.
The most fundamental projective invariant is the cross ratio of four
collinear points: a ratio of lengths on a line is invariant under afﬁnities, but not un-
der projectivities. However, a ratio of ratios or cross ratio of lengths on a line is a
projective invariant. We return to properties of this invariant in section 2.5.
2.4.5 Summary and comparison
Afﬁnities (6 dof) occupy the middle ground between similarities (4 dof) and projectivi-
ties (8 dof). They generalize similarities in that angles are not preserved, so that shapes
are skewed under the transformation. On the other hand their action is homogeneous
over the plane: for a given afﬁnity the det A scaling in area of an object (e.g. a square)
is the same anywhere on the plane; and the orientation of a transformed line depends
only on its initial orientation, not on its position on the plane. In contrast, for a given
projective transformation, area scaling varies with position (e.g. under perspective a
more distant square on the plane has a smaller image than one that is nearer, as in
ﬁgure 2.6); and the orientation of a transformed line depends on both the orientation
and position of the source line (however, it will be seen later in section 8.6(p213) that
a line’s vanishing point depends only on line orientation, not position).
The key difference between a projective and afﬁne transformation is that the vector
v is not null for a projectivity. This is responsible for the non-linear effects of the
projectivity. Compare the mapping of an ideal point (x1, x2, 0)T under an afﬁnity and
projectivity: First the afﬁne transformation

A4 x1
x2 5

0

A4 x1
x2 5

v1x1 + v2x2

⎞⎟⎠ .
⎞⎟⎠ .

(2.14)

(2.15)

t

0T 1 2⎛⎜⎝
1 A
vT v 2⎛⎜⎝
1 A

x1
x2
0

⎞⎟⎠ =⎛⎜⎝
⎞⎟⎠ =⎛⎜⎝

Second the projective transformation
x1
x2
0

t

In the ﬁrst case the ideal point remains ideal (i.e. at inﬁnity). In the second it is mapped
to a ﬁnite point. It is this ability which allows a projective transformation to model
vanishing points.
2.4.6 Decomposition of a projective transformation
A projective transformation can be decomposed into a chain of transformations, where
each matrix in the chain represents a transformation higher in the hierarchy than the
previous one.

H = HS HA HP =1 sR t

(2.16)
with A a non-singular matrix given by A = sRK + tvT, and K an upper-triangular matrix
normalized as det K = 1. This decomposition is valid provided v ̸= 0, and is unique if
s is chosen positive.

vT v 2

0T 1 21 K 0

0T 1 21 I

vT v 2 =1 A

0

t

2.4 A hierarchy of transformations

43
Each of the matrices HS, HA, HP is the “essence” of a transformation of that type (as
indicated by the subscripts S, A, P). Consider the process of rectifying the perspective
image of a plane as in example 2.12: HP (2 dof) moves the line at inﬁnity; HA (2 dof)
affects the afﬁne properties, but does not move the line at inﬁnity; and ﬁnally, HS is a
general similarity transformation (4 dof) which does not affect the afﬁne or projective
properties. The transformation HP is an elation, described in section A7.3(p631).
Example2.15. The projective transformation

H =⎡⎢⎣

1.707 0.586 1.0
2.707 8.242 2.0
1.0
1.0

2.0

⎤⎥⎦

may be decomposed as

H =⎡⎢⎣

⎤⎥⎦

⎡⎢⎣

⎤⎥⎦ .

2 cos 45◦ −2 sin 45◦ 1
2 sin 45◦
2
1

2 cos 45◦

0

0

0.5 1 0
2 0
0
0
0 1

1 0 0
0 1 0
1 2 1

⎤⎥⎦

⎡⎢⎣

△
This decomposition can be employed when the objective is to only partially deter-
mine the transformation. For example, if one wants to measure length ratios from the
perspective image of a plane, then it is only necessary to determine (rectify) the trans-
formation up to a similarity. We return to this approach in section 2.7.
Taking the inverse of H in (2.16) gives H−1 = H−1
S are
S . Since H−1
still projective, afﬁne and similarity transformations respectively, a general projective
transformation may also be decomposed in the form
vT 1 21 K 0

H = HP HA HS =1 I

0T 1 21 sR t
0T 1 2

A and H−1

P H−1

A H−1

(2.17)

P , H−1

0

Note that the actual values of K, R, t and v will be different from those of (2.16).

2.4.7 The number of invariants
The question naturally arises as to how many invariants there are for a given geometric
conﬁguration under a particular transformation. First the term “number” needs to be
made more precise, for if a quantity is invariant, such as length under Euclidean trans-
formations, then any function of that quantity is invariant. Consequently, we seek a
counting argument for the number of functionally independent invariants. By consid-
ering the number of transformation parameters that must be eliminated in order to form
an invariant, it can be seen that:
Result2.16. The number of functionally independent invariants is equal to, or greater
than, the number of degrees of freedom of the conﬁguration less the number of degrees
of freedom of the transformation.

44

2 Projective Geometry and Transformations of 2D

Group

Matrix

Distortion

Projective
8 dof

Afﬁne
6 dof

Similarity
4 dof

Euclidean
3 dof

h21 h22 h23

a21 a22
0
0

1 h11 h12 h13
h31 h32 h33 2
1 a11 a12
1 2
1 sr11
1 2
1 r11
1 2

sr12
sr22
0

r12
r22
0

sr21
0

r21
0

tx
ty

tx
ty

tx
ty

Invariant properties

Concurrency, collinearity, order of contact:
intersection (1 pt contact); tangency (2 pt con-
tact); inﬂections
(3 pt contact with line); tangent discontinuities
and cusps. cross ratio (ratio of ratio of lengths).
Parallelism, ratio of areas, ratio of lengths on
collinear or parallel lines (e.g. midpoints), lin-
ear combinations of vectors (e.g. centroids).
The line at inﬁnity, l∞.
Ratio of lengths, angle. The circular points, I, J
(see section 2.7.3).

Length, area

Table 2.1. Geometric properties invariant to commonly occurring planar transformations. The
matrix A = [aij] is an invertible 2 × 2 matrix, R = [rij] is a 2D rotation matrix, and (tx, ty) a 2D trans-
lation. The distortion column shows typical effects of the transformations on a square. Transformations
higher in the table can produce all the actions of the ones below. These range from Euclidean, where
only translations and rotations occur, to projective where the square can be transformed to any arbitrary
quadrilateral (provided no three points are collinear).

For example, a conﬁguration of four points in general position has 8 degrees of freedom
(2 for each point), and so 4 similarity, 2 afﬁnity and zero projective invariants since
these transformations have respectively 4, 6 and 8 degrees of freedom.

Table 2.1 summarizes the 2D transformation groups and their invariant properties.
Transformations lower in the table are specializations of those above. A transformation
lower in the table inherits the invariants of those above.

2.5 The projective geometry of 1D

The development of the projective geometry of a line, IP1, proceeds in much the same
way as that of the plane. A point x on the line is represented by homogeneous coordi-
nates (x1, x2)T, and a point for which x2 = 0 is an ideal point of the line. We will use
the notation ¯x to represent the 2-vector (x1, x2)T. A projective transformation of a line
is represented by a 2 × 2 homogeneous matrix,
¯x′ = H2×2¯x

and has 3 degrees of freedom corresponding to the four elements of the matrix less one
for overall scaling. A projective transformation of a line may be determined from three
corresponding points.

2.5 The projective geometry of 1D

45

Fig. 2.8. Projective transformations between lines. There are four sets of four collinear points in this
ﬁgure. Each set is related to the others by a line-to-line projectivity. Since the cross ratio is an invariant
under a projectivity, the cross ratio has the same value for all the sets shown.

The cross ratio. The cross ratio is the basic projective invariant of IP1. Given 4 points
¯xi the cross ratio is deﬁned as

Cross(¯x1, ¯x2, ¯x3, ¯x4) = |¯x1¯x2||¯x3¯x4|
|¯x1¯x3||¯x2¯x4|

|¯xi¯xj| = det1 xi1 xj1

xi2 xj2 2 .

where

A few comments on the cross ratio:

(i) The value of the cross ratio is not dependent on which particular homogeneous
representative of a point ¯xi is used, since the scale cancels between numerator
and denominator.
(ii) If each point ¯xi is a ﬁnite point and the homogeneous representative is chosen
such that x2 = 1, then |¯xi¯xj| represents the signed distance from ¯xi to ¯xj.
(iii) The deﬁnition of the cross ratio is also valid if one of the points ¯xi is an ideal
point.
(iv) The value of the cross ratio is invariant under any projective transformation of
the line: if ¯x′ = H2×2¯x then

Cross(¯x′1, ¯x′2, ¯x′3, ¯x′4) = Cross(¯x1, ¯x2, ¯x3, ¯x4).

(2.18)
The proof is left as an exercise. Equivalently stated, the cross ratio is invariant
to the projective coordinate frame chosen for the line.

Figure 2.8 illustrates a number of projective transformations between lines with equiv-
alent cross ratios.
Under a projective transformation of the plane, a 1D projective transformation is
induced on any line in the plane.
Concurrent lines. A conﬁguration of concurrent lines is dual to collinear points on
a line. This means that concurrent lines on a plane also have the geometry IP1. In
particular four concurrent lines have a cross ratio as illustrated in ﬁgure 2.9a.

46

l

2 Projective Geometry and Transformations of 2D
x 1

l

l

1

x 1
x

2

l

2

x

3

x

4

a

l

3

l

4

c

x

1

x

2

x

3

x

4

b

x2

x3

x 4

Fig. 2.9. Concurrent lines. (a) Four concurrent lines li intersect the line l in the four points ¯xi. The
cross ratio of these lines is an invariant to projective transformations of the plane. Its value is given
by the cross ratio of the points, Cross(¯x1, ¯x2, ¯x3, ¯x4). (b) Coplanar points xi are imaged onto a line l
(also in the plane) by a projection with centre c. The cross ratio of the image points ¯xi is invariant to
the position of the image line l.

Note how ﬁgure 2.9b may be thought of as representing projection of points in IP2
into a 1-dimensional image. In particular, if c represents a camera centre, and the line
l represents an image line (1D analogue of the image plane), then the points ¯xi are the
projections of points xi into the image. The cross ratio of the points ¯xi characterizes
the projective conﬁguration of the four image points. Note that the actual position
of the image line is irrelevant as far as the projective conﬁguration of the four image
points is concerned – different choices of image line give rise to projectively equivalent
conﬁgurations of image points.
The projective geometry of concurrent lines is important to the understanding of the
projective geometry of epipolar lines in chapter 9.

2.6 Topology of the projective plane

We make brief mention of the topology of IP2. Understanding of this section is not
required for following the rest of the book.

1 + x2

2 + x2

We have seen that the projective plane IP2 may be thought of as the set of all ho-
mogeneous 3-vectors. A vector of this type x = (x1, x2, x3)T may be normalized by
multiplication by a non-zero factor so that x2
3 = 1. Such a point lies on the
unit sphere in IR3. However, any vector x and −x represent the same point in IP2, since
they differ by a multiplicative factor, −1. Thus, there is a two-to-one correspondence
between the unit sphere S2 in IR3 and the projective plane IP2. The projective plane
may be pictured as the unit sphere with opposite points identiﬁed. In this representa-
tion, a line in IP2 is modelled as a great circle on the unit sphere (as ever, with opposite
points identiﬁed). One may verify that any two distinct (non-antipodal) points on the
sphere lie on exactly one great circle, and any two great circles intersect in one point
(since antipodal points are identiﬁed).
In the language of topology, the sphere S2 is a 2-sheeted covering space of IP2. This
implies that IP2 is not simply-connected, which means that there are loops in IP2 which
cannot be contracted to a point inside IP2. To be technical, the fundamental group of
IP2 is the cyclic group of order 2.

2.7 Recovery of afﬁne and metric properties from images

47

a

b

c

d

Fig. 2.10. Topology of surfaces. Common surfaces may be constructed from a paper square (topo-
logically a disk) with edges glued together. In each case, the matching arrow edges of the square are to
be glued together in such a way that the directions of the arrows match. One obtains (a) a sphere, (b)
a torus, (c) a Klein bottle and (d) a projective plane. Only the sphere and torus are actually realizable
with a real sheet of paper. The sphere and torus are orientable but the projective plane and Klein bottle
are not.

In the model for the projective plane as a sphere with opposite points identiﬁed one
may dispense with the lower hemisphere of S2, since points in this hemisphere are
In this case, IP2 may be
the same as the opposite points in the upper hemisphere.
constructed from the upper hemisphere by identifying opposite points on the equator.
Since the upper hemisphere of S2 is topologically the same as a disk, IP2 is simply
a disk with opposite points on its boundary identiﬁed, or glued together. This is not
physically possible. Constructing topological spaces by gluing the boundary of a disk
is a common method in topology, and in fact any 2-manifold may be constructed in this
way. This is illustrated in ﬁgure 2.10.
A notable feature of the projective plane IP2 is that it is non-orientable. This means
that it is impossible to deﬁne a local orientation (represented for instance by a pair of
oriented coordinate axes) that is consistent over the whole surface. This is illustrated
in ﬁgure 2.11 in which it is shown that the projective plane contains an orientation-
reversing path.

The topology of IP1.
In a similar manner, the 1-dimensional projective line may be
identiﬁed as a 1-sphere S1 (that is, a circle) with opposite points identiﬁed. If we omit
the lower half of the circle, as being duplicated by the top half, then the top half of a
circle is topologically equivalent to a line segment. Thus IP1 is topologically equivalent
to a line segment with the two endpoints identiﬁed – namely a circle, S1.

2.7 Recovery of afﬁne and metric properties from images

We return to the example of projective rectiﬁcation of example 2.12(p34) where the
aim was to remove the projective distortion in the perspective image of a plane to the
extent that similarity properties (angles, ratios of lengths) could be measured on the
original plane. In that example the projective distortion was completely removed by
specifying the position of four reference points on the plane (a total of 8 degrees of
freedom), and explicitly computing the transformation mapping the reference points to
their images. In fact this overspeciﬁes the geometry – a projective transformation has
only 4 degrees of freedom more than a similarity, so it is only necessary to specify 4

48

2 Projective Geometry and Transformations of 2D

a

b

Fig. 2.11. Orientation of surfaces. A coordinate frame (represented by an L in the diagram) may
be transported along a path in the surface eventually coming back to the point where it started. (a)
represents a projective plane. In the path shown, the coordinate frame (represented by a pair of axes) is
reversed when it returns to the same point, since the identiﬁcation at the boundary of the square swaps
the direction of one of the axes. Such a path is called an orientation-reversing path, and a surface that
contains such a path is called non-orientable. (b) shows the well known example of a M¨obius strip
obtained by joining two opposite edges of a rectangle (M.C. Escher’s “Moebius Strip II [Red Ants]”,
1963. c⃝2000 Cordon Art B.V. – Baarn-Holland. All rights reserved). As can be veriﬁed, a path once
around the strip is orientation-reversing.

degrees of freedom (not 8) in order to determine metric properties. In projective geom-
etry these 4 degrees of freedom are given “physical substance” by being associated with
geometric objects: the line at inﬁnity l∞ (2 dof), and the two circular points (2 dof)
on l∞. This association is often a more intuitive way of reasoning about the problem
than the equivalent description in terms of specifying matrices in the decomposition
chain (2.16).
In the following it is shown that the projective distortion may be removed once the
image of l∞ is speciﬁed, and the afﬁne distortion removed once the image of the circu-
lar points is speciﬁed. Then the only remaining distortion is a similarity.
2.7.1 The line at inﬁnity
Under a projective transformation ideal points may be mapped to ﬁnite points (2.15),
and consequently l∞ is mapped to a ﬁnite line. However, if the transformation is an
afﬁnity, then l∞ is not mapped to a ﬁnite line, but remains at inﬁnity. This is evident
directly from the line transformation (2.6–p36):

l′
∞ = H−T

A l∞ =1

0
0
1

⎞⎟⎠ = l∞.

0

A−T

−tTA−T 1 2⎛⎜⎝

0
0
1

⎞⎟⎠ =⎛⎜⎝

The converse is also true, i.e. an afﬁne transformation is the most general linear trans-
formation that ﬁxes l∞, and may be seen as follows. We require that a point at inﬁnity,
say x = (1, 0, 0)T, be mapped to a point at inﬁnity. This requires that h31 = 0. Simi-
larly, h32 = 0, so the transformation is an afﬁnity. To summarize,
Result2.17. The line at inﬁnity, l∞, is a ﬁxed line under the projective transformation
H if and only if H is an afﬁnity.
However, l∞ is not ﬁxed pointwise under an afﬁne transformation: (2.14) showed
that under an afﬁnity a point on l∞ (an ideal point) is mapped to a point on l∞, but

2.7 Recovery of afﬁne and metric properties from images

H

P

l = H  (    )

l

P

/
H
P

49

(cid:83)

1

(cid:83)

2

(cid:83)

3

H
A

Fig. 2.12. Afﬁne rectiﬁcation. A projective transformation maps l∞ from (0, 0, 1)T on a Euclidean
plane π1 to a ﬁnite line l on the plane π2. If a projective transformation is constructed such that l is
mapped back to (0, 0, 1)T then from result 2.17 the transformation between the ﬁrst and third planes
must be an afﬁne transformation since the canonical position of l∞ is preserved. This means that afﬁne
properties of the ﬁrst plane can be measured from the third, i.e. the third plane is within an afﬁnity of the
ﬁrst.

it is not the same point unless A(x1, x2)T = k(x1, x2)T. It will now be shown that
identifying l∞ allows the recovery of afﬁne properties (parallelism, ratio of areas).
2.7.2 Recovery of afﬁne properties from images
Once the imaged line at inﬁnity is identiﬁed in an image of a plane, it is then possible to
make afﬁne measurements on the original plane. For example, lines may be identiﬁed
as parallel on the original plane if the imaged lines intersect on the imaged l∞. This
follows because parallel lines on the Euclidean plane intersect on l∞, and after a pro-
jective transformation the lines still intersect on the imaged l∞ since intersections are
preserved by projectivities. Similarly, once l∞ is identiﬁed a length ratio on a line may
be computed from the cross ratio of the three points specifying the lengths together
with the intersection of the line with l∞ (which provides the fourth point for the cross
ratio), and so forth.
However, a less tortuous path which is better suited to computational algorithms is
simply to transform the identiﬁed l∞ to its canonical position of l∞ = (0, 0, 1)T. The
(projective) matrix which achieves this transformation can be applied to every point
in the image in order to afﬁnely rectify the image, i.e. after the transformation, afﬁne
measurements can be made directly from the rectiﬁed image. The key idea here is
illustrated in ﬁgure 2.12.
If the imaged line at inﬁnity is the line l = (l1, l2, l3)T, then provided l3 ̸= 0 a suitable
projective point transformation which will map l back to l∞ = (0, 0, 1)T is

H = HA⎡⎢⎣

1
0
l1

0
1
l2

0
0
l3

⎤⎥⎦

(2.19)

50

2 Projective Geometry and Transformations of 2D

a

b

c

Fig. 2.13. Afﬁne rectiﬁcation via the vanishing line. The vanishing line of the plane imaged in (a) is
computed (c) from the intersection of two sets of imaged parallel lines. The image is then projectively
warped to produce the afﬁnely rectiﬁed image (b). In the afﬁnely rectiﬁed image parallel lines are now
parallel. However, angles do not have their veridical world value since they are afﬁnely distorted. See
also ﬁgure 2.17.

where HA is any afﬁne transformation (the last row of H is lT). One can verify that under
the line transformation (2.6–p36) H−T(l1, l2, l3)T = (0, 0, 1)T = l∞.
Example2.18. Afﬁne rectiﬁcation
In a perspective image of a plane, the line at inﬁnity on the world plane is imaged as the
vanishing line of the plane. This is discussed in more detail in chapter 8. As illustrated
in ﬁgure 2.13 the vanishing line l may be computed by intersecting imaged parallel
lines. The image is then rectiﬁed by applying a projective warping (2.19) such that l is
mapped to its canonical position l∞ = (0, 0, 1)T.
△
This example shows that afﬁne properties may be recovered by simply specifying a
line (2 dof). It is equivalent to specifying only the projective component of the trans-
formation decomposition chain (2.16). Conversely if afﬁne properties are known, these
may be used to determine points and the line at inﬁnity. This is illustrated in the fol-
lowing example.
Example2.19. Computing a vanishing point from a length ratio. Given two in-
tervals on a line with a known length ratio, the point at inﬁnity on the line may be
determined. A typical case is where three points a′, b′ and c′ are identiﬁed on a line in
an image. Suppose a, b and c are the corresponding collinear points on the world line,
and the length ratio d(a, b) : d(b, c) = a : b is known (where d(x, y) is the Euclidean

2.7 Recovery of afﬁne and metric properties from images

51

Fig. 2.14. Two examples of using equal length ratios on a line to determine the point at inﬁnity. The
line intervals used are shown as the thin and thick white lines delineated by points. This construction
determines the vanishing line of the plane. Compare with ﬁgure 2.13c.

distance between the points x and y). It is possible to ﬁnd the vanishing point using
the cross ratio. Equivalently, one may proceed as follows:

(i) Measure the distance ratio in the image, d(a′, b′) : d(b′, c′) = a′ : b′.
(ii) Points a, b and c may be represented as coordinates 0, a and a+b in a coordinate
frame on the line ⟨a, b, c⟩. For computational purposes, these points are rep-
resented by homogeneous 2-vectors (0, 1)T, (a, 1)T and (a + b, 1)T. Similarly,
a′, b′ and c′ have coordinates 0, a′ and a′ + b′, which may also be expressed as
homogeneous vectors.
(iii) Relative to these coordinate frames, compute the 1D projective transformation
H2×2 mapping a ’→ a′, b ’→ b′ and c ’→ c′.
(iv) The image of the point at inﬁnity (with coordinates (1, 0)T) under H2×2 is the
vanishing point on the line ⟨a′, b′, c′⟩.
An example of vanishing points computed in this manner is shown in ﬁgure 2.14. △
Example2.20. Geometric construction of vanishing points from a length ratio.
The vanishing points shown in ﬁgure 2.14 may also be computed by a purely geometric
construction consisting of the following steps:

(i) Given:
three collinear points, a′, b′ and c′, in an image corresponding to
collinear world points with interval ratio a : b.
(ii) Draw any line l through a′ (not coincident with the line a′c′), and mark off
points a = a′, b and c such that the line segments ⟨ab⟩, ⟨bc⟩ have length ratio
a : b.

(iii) Join bb′ and cc′ and intersect in o.
(iv) The line through o parallel to l meets the line a′c′ in the vanishing point v′.

This construction is illustrated in ﬁgure 2.15.

△

52

2 Projective Geometry and Transformations of 2D

o

v/

b/

b

a/
a

a

c /

b

c

l

Fig. 2.15. A geometric construction to determine the image of the point at inﬁnity on a line given a
known length ratio. The details are given in the text.

2.7.3 The circular points and their dual
Under any similarity transformation there are two points on l∞ which are ﬁxed. These
are the circular points (also called the absolute points) I, J, with canonical coordinates

I =⎛⎜⎝

1
i
0

⎞⎟⎠

J =⎛⎜⎝

1
−i
0

⎞⎟⎠ .

The circular points are a pair of complex conjugate ideal points. To see that they are
ﬁxed under an orientation-preserving similarity:

s cos θ −s sin θt
cos θt
s sin θs
0

x

y
1

⎤⎥⎦

⎛⎜⎝

1
i
0

⎞⎟⎠

I′ = HSI

0

= ⎡⎢⎣
= se−iθ⎛⎜⎝

1
i
0

⎞⎟⎠ = I

with an analogous proof for J. A reﬂection swaps I and J. The converse is also true,
i.e. if the circular points are ﬁxed then the linear transformation is a similarity. The
proof is left as an exercise. To summarize,
Result2.21. The circular points, I, J, are ﬁxed points under the projective transforma-
tion H if and only if H is a similarity.
The name “circular points” arises because every circle intersects l∞ at the circular
points. To see this, start from equation (2.1–p30) for a conic. In the case that the conic
is a circle: a = c and b = 0. Then

x2
1 + x2

2 + dx1x3 + ex2x3 + f x2

3 = 0

2.7 Recovery of afﬁne and metric properties from images

53
where a has been set to unity. This conic intersects l∞ in the (ideal) points for which
x3 = 0, namely

x2
1 + x2

2 = 0

with solution I = (1, i, 0)T, J = (1,−i, 0)T, i.e. any circle intersects l∞ in the circular
points. In Euclidean geometry it is well known that a circle is speciﬁed by three points.
The circular points enable an alternative computation. A circle can be computed using
the general formula for a conic deﬁned by ﬁve points (2.4–p31), where the ﬁve points
are the three points augmented with the two circular points.
In section 2.7.5 it will be shown that identifying the circular points (or equivalently
their dual, see below) allows the recovery of similarity properties (angles, ratios of
lengths). Algebraically, the circular points are the orthogonal directions of Euclidean
geometry, (1, 0, 0)T and (0, 1, 0)T, packaged into a single complex conjugate entity,
e.g.

I = (1, 0, 0)T + i(0, 1, 0)T.

Consequently, it is not so surprising that once the circular points are identiﬁed, orthog-
onality, and other metric properties, are then determined.
The conic dual to the circular points. The conic
C∗
∞ = IJT + JIT

(2.20)
is a degenerate (rank 2) line conic
is dual to the circular points. The conic C∗
∞
(see section 2.2.3), which consists of the two circular points. In a Euclidean coordinate
system it is given by
1
i
0
is ﬁxed under similarity transformations in an analogous fashion to
the ﬁxed properties of circular points. A conic is ﬁxed if the same matrix results (up to
scale) under the transformation rule. Since C∗
is a dual conic it transforms according to
∞
result 2.14(p37) (C∗′ = HC∗HT), and one can verify that under the point transformation
x′ = HSx,

⎞⎟⎠/ 1 −i 0 0 +⎛⎜⎝

⎞⎟⎠/ 1 i 0 0 =⎡⎢⎣

∞ =⎛⎜⎝

The conic C∗
∞

1 0 0
0 1 0
0 0 0

⎤⎥⎦ .

1
−i
0

C∗

C∗
∞

′ = HSC∗

∞HT

S = C∗
∞.

The converse is also true, and we have
Result2.22. The dual conic C∗
∞
only if H is a similarity.
Some properties of C∗
∞

in any projective frame:

is ﬁxed under the projective transformation H if and

(i) C∗
∞
5 degrees of freedom, but the constraint det C∗
freedom by 1.

has 4 degrees of freedom: a 3 × 3 homogeneous symmetric matrix has
∞ = 0 reduces the degrees of

54

2 Projective Geometry and Transformations of 2D

(ii) l∞ is the null vector of C∗
∞

lie on l∞, so that ITl∞ = JTl∞ = 0; then

. This is clear from the deﬁnition: the circular points

C∗
∞l∞ = (IJT + JIT)l∞ = I(JTl∞) + J(ITl∞) = 0.

2.7.4 Angles on the projective plane
In Euclidean geometry the angle between two lines is computed from the dot product
of their normals. For the lines l = (l1, l2, l3)T and m = (m1, m2, m3)T with normals
parallel to (l1, l2)T, (m1, m2)T respectively, the angle is
l1m1 + l2m2
1 + l2

1 + m2
2)

(2.21)

cos θ =

2)(m2

.

The problem with this expression is that the ﬁrst two components of l and m do not
have well deﬁned transformation properties under projective transformations (they are
not tensors), and so (2.21) cannot be applied after an afﬁne or projective transforma-
tion of the plane. However, an analogous expression to (2.21) which is invariant to
projective transformations is

3(l2

cos θ =

(2.22)

lTC∗

∞m

3(lTC∗∞l)(mTC∗∞m)

lTC∗

∞m.

is the conic dual to the circular points. It is clear that in a Euclidean co-
where C∗
∞
ordinate system (2.22) reduces to (2.21).
It may be veriﬁed that (2.22) is invariant
to projective transformations by using the transformation rules for lines (2.6–p36)
(l′ = H−Tl) and dual conics (result 2.14(p37)) (C∗′ = HC∗HT) under the point trans-
formation x′ = Hx. For example, the numerator transforms as
∞HTH−Tm = lTC∗

∞m ’→ lTH−1HC∗

is identiﬁed on the projective plane then Euclidean

It may also be veriﬁed that the scale of the homogeneous objects cancels between the
numerator and denominator. Thus (2.22) is indeed invariant to the projective frame. To
summarize, we have shown
Result2.23. Once the conic C∗
∞
angles may be measured by (2.22).
Note, as a corollary,
Result2.24. Lines l and m are orthogonal if lTC∗
Geometrically,
(see section 2.8.1) with respect to the conic C∗
.
∞
Length ratios may also be measured once C∗
is identiﬁed. Consider the triangle
∞
shown in ﬁgure 2.16 with vertices a, b, c. From the standard trigonometric sine rule
the ratio of lengths d(b, c) : d(a, c) = sin α : sin β, where d(x, y) denotes the Eu-
clidean distance between the points x and y. Using (2.22), both cos α and cos β may
be computed from the lines l′ = a′ × b′, m′ = c′ × a′ and n′ = b′ × c′ for any

then the lines are conjugate

if l and m satisfy lTC∗

∞m = 0,

∞m = 0.

2.7 Recovery of afﬁne and metric properties from images

c

55

/

c

(cid:68)

a

(cid:69)

b

m

/

n

/

/

a

l /

b
/

Fig. 2.16. Length ratios. Once C∗∞
measured from the projectively distorted ﬁgure. See text for details.

is identiﬁed the Euclidean length ratio d(b, c) : d(a, c) may be

is speciﬁed. Consequently both sin α, sin β, and thence

projective frame in which C∗
∞
the ratio d(a, b) : d(c, a), may be determined from the projectively mapped points.
2.7.5 Recovery of metric properties from images
A completely analogous approach to that of section 2.7.2 and ﬁgure 2.12, where afﬁne
properties are recovered by specifying l∞, enables metric properties to be recovered
from an image of a plane by transforming the circular points to their canonical position.
Suppose the circular points are identiﬁed in an image, and the image is then rectiﬁed
by a projective transformation H that maps the imaged circular points to their canonical
position (at (1,±i, 0)T) on l∞. From result 2.21 the transformation between the world
plane and the rectiﬁed image is then a similarity since it is projective and the circular
points are ﬁxed.
Metric rectiﬁcation using C∗
neatly packages all the information
∞
required for a metric rectiﬁcation. It enables both the projective and afﬁne components
of a projective transformation to be determined, leaving only similarity distortions.
This is evident from its transformation under a projectivity. If the point transformation
is x′ = Hx, where the x-coordinate frame is Euclidean and x′ projective, C∗
transforms
∞
according to result 2.14(p37) (C∗′ = HC∗HT). Using the decomposition chain (2.17–
p43) for H

. The dual conic C∗
∞

′ = (HP HA HS) C∗

C∗
∞

= (HP HA) C∗

S0/HT
∞ (HP HA HS)T = (HP HA)/HS C∗
∞HT
∞/HT

A HT

P0

P0
vTKKT vTKKTv 2 .

A HT
KKTv

= 1 KKT
(2.23)
It is clear that the projective (v) and afﬁne (K) components are determined directly from
the image of C∗
is invariant to similarity transformation by result 2.22)
, but (since C∗
∞
∞
the similarity component is undetermined. Consequently,
Result2.25. Once the conic C∗
∞
distortion may be rectiﬁed up to a similarity.

is identiﬁed on the projective plane then projective

Actually, a suitable rectifying homography may be obtained directly from the iden-
′ in an image using the SVD (section A4.4(p585)): writing the SVD of C∗
′
∞

tiﬁed C∗
∞

56
as

2 Projective Geometry and Transformations of 2D

C∗
∞

′ = U⎡⎢⎣

1 0 0
0 1 0
0 0 0

⎤⎥⎦ UT

may be identiﬁed in

The following two examples show typical situations where C∗
∞

then by inspection from (2.23) the rectifying projectivity is H = U up to a similarity.
an image, and thence a metric rectiﬁcation obtained.
Example2.26. Metric rectiﬁcation I
Suppose an image has been afﬁnely rectiﬁed (as in example 2.18 above), then we re-
quire two constraints to specify the 2 degrees of freedom of the circular points in order
to determine a metric rectiﬁcation. These two constraints may be obtained from two
imaged right angles on the world plane.
Suppose the lines l′, m′ in the afﬁnely rectiﬁed image correspond to an orthogonal
line pair l, m on the world plane. From result 2.24 l′TC∗
′m′ = 0, and using (2.23)
∞
with v = 0

/ l′1

l′2

0 2⎛⎜⎝
l′3 01 KKT 0

0T

m′1
m′2
m′3

⎞⎟⎠ = 0

which is a linear constraint on the 2 × 2 matrix S = KKT. The matrix S = KKT is
symmetric with three independent elements, and thus 2 degrees of freedom (as the
overall scaling is unimportant). The orthogonality condition reduces to the equation
(l′1, l′2)S(m′1, m′2)T = 0 which may be written as

(l′1m′1, l′1m′2 + l′2m′1, l′2m′2) s = 0,

where s = (s11, s12, s22)T is S written as a 3-vector. Two such orthogonal line pairs
provide two constraints which may be stacked to give a 2 × 3 matrix with s deter-
mined as the null vector. Thus S, and hence K, is obtained up to scale (by Cholesky
decomposition, section A4.2.1(p582)). Figure 2.17 shows an example of two orthog-
onal line pairs being used to metrically rectify the afﬁnely rectiﬁed image computed
in ﬁgure 2.13.
△
Alternatively, the two constraints required for metric rectiﬁcation may be obtained from
an imaged circle or two known length ratios. In the case of a circle, the image conic
is an ellipse in the afﬁnely rectiﬁed image, and the intersection of this ellipse with the
(known) l∞ directly determines the imaged circular points.
The conic C∗
can alternatively be identiﬁed directly in a perspective image, without
∞
ﬁrst identifying l∞, as is illustrated in the following example.
Example2.27. Metric rectiﬁcation II
We start here from the original perspective image of the plane (not the afﬁnely rectiﬁed
image of example 2.26). Suppose lines l and m are images of orthogonal lines on the
world plane; then from result 2.24 lTC∗
∞m = 0, and in a similar manner to constraining

2.7 Recovery of afﬁne and metric properties from images

57

a

b

Fig. 2.17. Metric rectiﬁcation via orthogonal lines I. The afﬁne transformation required to metrically
rectify an afﬁne image may be computed from imaged orthogonal lines. (a) Two (non-parallel) line pairs
identiﬁed on the afﬁnely rectiﬁed image (ﬁgure 2.13) correspond to orthogonal lines on the world plane.
(b) The metrically rectiﬁed image. Note that in the metrically rectiﬁed image all lines orthogonal in the
world are orthogonal, world squares have unit aspect ratio, and world circles are circular.

a

b
Fig. 2.18. Metric rectiﬁcation via orthogonal lines II. (a) The conic C∗∞
is determined on the per-
spectively imaged plane (the front wall of the building) using the ﬁve orthogonal line pairs shown. The
conic C∗∞
determines the circular points, and equivalently the projective transformation necessary to
metrically rectify the image (b). The image shown in (a) is the same perspective image as that of ﬁgure
2.4(p35), where the perspective distortion was removed by specifying the world position of four image
points.

, namely

a conic to contain a point (2.4–p31), this provides a linear constraint on the elements
of C∗
∞
(l1m1, (l1m2 + l2m1)/2, l2m2, (l1m3 + l3m1)/2, (l2m3 + l3m2)/2, l3m3) c = 0

where c = (a, b, c, d, e, f )T is the conic matrix (2.3–p30) of C∗
written as a 6-vector.
∞
Five such constraints can be stacked to form a 5 × 6 matrix, and c, and hence C∗
,
∞
is obtained as the null vector. This shows that C∗
can be determined linearly from
∞
the images of ﬁve line pairs which are orthogonal on the world plane. An example of
metric rectiﬁcation using such line pair constraints is shown in ﬁgure 2.18.
△
Stratiﬁcation. Note, in example 2.27 the afﬁne and projective distortions are deter-
mined in one step by specifying C∗
. In the previous example 2.26 ﬁrst the projec-
∞
tive and subsequently the afﬁne distortions were removed. This two-step approach is
termed stratiﬁed. Analogous approaches apply in 3D, and are employed in chapter 10

58

2 Projective Geometry and Transformations of 2D

C

y

l

x

Fig. 2.19. The pole–polar relationship. The line l = Cx is the polar of the point x with respect to the
conic C, and the point x = C−1l is the pole of l with respect to C. The polar of x intersects the conic at
the points of tangency of lines from x. If y is on l then yTl = yTCx = 0. Points x and y which satisfy
yTCx = 0 are conjugate.

on 3D reconstruction and chapter 19 on auto-calibration, when obtaining a metric from
a 3D projective reconstruction.

2.8 More properties of conics

We now introduce an important geometric relation between a point, line and conic,
which is termed polarity. Applications of this relation (to the representation of orthog-
onality) are given in chapter 8.

2.8.1 The pole–polar relationship
A point x and conic C deﬁne a line l = Cx. The line l is called the polar of x with
respect to C, and the point x is the pole of l with respect to C.
• The polar line l = Cx of the point x with respect to a conic C intersects the conic in
two points. The two lines tangent to C at these points intersect at x.
This relationship is illustrated in ﬁgure 2.19.
Proof. Consider a point y on C. The tangent line at y is Cy, and this line contains x
if xTCy = 0. Using the symmetry of C, the condition xTCy = (Cx)Ty = 0 is that the
point y lies on the line Cx. Thus the polar line Cx intersects the conic in the point y at
which the tangent line contains x.
As the point x approaches the conic the tangent lines become closer to collinear, and
their contact points on the conic also become closer. In the limit that x lies on C, the
polar line has two-point contact at x, and we have:
• If the point x is on C then the polar is the tangent line to the conic at x.
See result 2.7(p31).

C =⎡⎢⎣

0
1

−a
1
0
0
−a 0 a2 − r2

⎤⎥⎦ .

59
Example2.28. A circle of radius r centred on the x-axis at x = a has the equation
(x − a)2 + y2 = r2, and is represented by the conic matrix

2.8 More properties of conics

The polar line of the origin is given by l = C(0, 0, 1)T = (−a, 0, a2 − r2)T. This is a
vertical line at x = (a2 − r2)/a. If r = a the origin lies on the circle. In this case the
polar line is the y-axis and is tangent to the circle.
△
It is evident that the conic induces a map between points and lines of IP2. This map is
a projective construction since it involves only intersections and tangency, both prop-
erties that are preserved under projective transformations. A projective map between
points and lines is termed a correlation (an unfortunate name, given its more common
usage).
Deﬁnition2.29. A correlation is an invertible mapping from points of IP2 to lines of
IP2. It is represented by a 3 × 3 non-singular matrix A as l = Ax.
A correlation provides a systematic way to dualize relations involving points and lines.
It need not be represented by a symmetric matrix, but we will only consider symmetric
correlations here, because of the association with conics.
• Conjugate points. If the point y is on the line l = Cx then yTl = yTCx = 0. Any
two points x, y satisfying yTCx = 0 are conjugate with respect to the conic C.
The conjugacy relation is symmetric:
• If x is on the polar of y then y is on the polar of x.
This follows simply because of the symmetry of the conic matrix – the point x is on
the polar of y if xTCy = 0, and the point y is on the polar of x if yTCx = 0. Since
xTCy = yTCx, if one form is zero, then so is the other. There is a dual conjugacy
relationship for lines: two lines l and m are conjugate if lTC∗m = 0.
2.8.2 Classiﬁcation of conics
This section describes the projective and afﬁne classiﬁcation of conics.
Projective normal form for a conic. Since C is a symmetric matrix it has real eigen-
values, and may be decomposed as a product C = UTDU (see section A4.2(p580)),
where U is an orthogonal matrix, and D is diagonal. Applying the projective trans-
formation represented by U, conic C is transformed to another conic C′ = U−TCU−1 =
U−TUTDUU−1 = D. This shows that any conic is equivalent under projective transforma-
tion to one with a diagonal matrix. Let D = diag(ϵ1d1,ϵ 2d2,ϵ 3d3) where ϵi = ±1 or 0
and each di > 0. Thus, D may be written in the form

D = diag(s1, s2, s3)Tdiag(ϵ1,ϵ 2,ϵ 3)diag(s1, s2, s3)

60

2 Projective Geometry and Transformations of 2D

a

l

l

b

l

c

Fig. 2.20. Afﬁne classiﬁcation of point conics. A conic is an (a) ellipse, (b) parabola, or (c) hyperbola;
according to whether it (a) has no real intersection, (b) is tangent to (2-point contact), or (c) has 2 real
intersections with l∞. Under an afﬁne transformation l∞ is a ﬁxed line, and intersections are preserved.
Thus this classiﬁcation is unaltered by an afﬁnity.

where s2
i = di. Note that diag(s1, s2, s3)T = diag(s1, s2, s3). Now, transforming once
more by the transformation diag(s1, s2, s3), the conic D is transformed to a conic with
matrix diag(ϵ1,ϵ 2,ϵ 3), with each ϵi = ±1 or 0. Further transformation by permutation
matrices may be carried out to ensure that values ϵi = 1 occur before values ϵi = −1
which in turn precede values ϵi = 0. Finally, by multiplying by −1 if necessary, one
may ensure that there are at least as many +1 entries as −1. The various types of conics
may now be enumerated, and are shown in table 2.2.

Diagonal
(1, 1, 1)
(1, 1,−1)
(1, 1, 0)
(1,−1, 0)
(1, 0, 0)

Equation

Conic type

x2 + y2 + w2 = 0
x2 + y2 − w2 = 0

x2 + y2 = 0
x2 − y2 = 0

x2 = 0

Improper conic – no real points.

Circle

Single real point (0, 0, 1)T

Two lines x = ±y

Single line x = 0 counted twice.

Table 2.2. Projective classiﬁcation of point conics. Any plane conic is projectively equivalent to one
of the types shown in this table. Those conics for which ϵi = 0 for some i are known as degenerate
conics, and are represented by a matrix of rank less than 3. The conic type column only describes the
real points of the conics – for example as a complex conic x2 + y2 = 0 consists of the line pair x = ±iy.

Afﬁne classiﬁcation of conics. The classiﬁcation of (non-degenerate, proper) conics
in Euclidean geometry into hyperbola, ellipse and parabola is well known. As shown
above in projective geometry these three types of conic are projectively equivalent to
a circle. However, in afﬁne geometry the Euclidean classiﬁcation is still valid because
it depends only on the relation of l∞ to the conic. The relation for the three types of
conic is illustrated in ﬁgure 2.20.

2.9 Fixed points and lines

61

H

e

1

e

2

e

3

x

e

1

e

2

e

3

x/

Fig. 2.21. Fixed points and lines of a plane projective transformation. There are three ﬁxed points,
and three ﬁxed lines through these points. The ﬁxed lines and points may be complex. Algebraically,
the ﬁxed points are the eigenvectors, ei, of the point transformation (x′ = Hx), and the ﬁxed lines
eigenvectors of the line transformation ( l′ = H−Tl). Note, the ﬁxed line is not ﬁxed pointwise: under
the transformation, points on the line are mapped to other points on the line; only the ﬁxed points are
mapped to themselves.

2.9 Fixed points and lines

We have seen, by the examples of l∞ and the circular points, that points and lines may
be ﬁxed under a projective transformation. In this section the idea is investigated more
thoroughly.
Here, the source and destination planes are identiﬁed (the same) so that the trans-
formation maps points x to points x′ in the same coordinate system. The key idea
is that an eigenvector corresponds to a ﬁxed point of the transformation, since for an
eigenvector e with eigenvalue λ,

He = λe

and e and λe represent the same point. Often the eigenvector and eigenvalue have
physical or geometric signiﬁcance in computer vision applications.
A 3×3 matrix has three eigenvalues and consequently a plane projective transforma-
tion has up to three ﬁxed points, if the eigenvalues are distinct. Since the characteristic
equation is a cubic in this case, one or three of the eigenvalues, and corresponding
eigenvectors, is real. A similar development can be given for ﬁxed lines, which, since
lines transform as (2.6–p36) l′ = H−Tl, correspond to the eigenvectors of HT.
The relationship between the ﬁxed points and ﬁxed lines is shown in ﬁgure 2.21.
Note the lines are ﬁxed as a set, not ﬁxed pointwise, i.e. a point on the line is mapped
to another point on the line, but in general the source and destination points will differ.
There is nothing mysterious here: The projective transformation of the plane induces a
1D projective transformation on the line. A 1D projective transformation is represented
by a 2× 2 homogeneous matrix (section 2.5). This 1D projectivity has two ﬁxed points
corresponding to the two eigenvectors of the 2× 2 matrix. These ﬁxed points are those
of the 2D projective transformation.
A further specialization concerns repeated eigenvalues. Suppose two of the eigen-
values (λ2,λ 3 say) are identical, and that there are two distinct eigenvectors (e2, e3),
corresponding to λ2 = λ3. Then the line containing the eigenvectors e2, e3 will be
ﬁxed pointwise, i.e. it is a line of ﬁxed points. For suppose x = αe2 + βe3; then

Hx = λ2αe2 + λ2βe3 = λ2x

2 Projective Geometry and Transformations of 2D

62
i.e. a point on the line through two degenerate eigenvectors is mapped to itself (only
differing by scale). Another possibility is that λ2 = λ3, but that there is only one
corresponding eigenvector. In this case, the eigenvector has algebraic dimension equal
to two, but geometric dimension equal to one. Then there is one fewer ﬁxed point (2
instead of 3). Various cases of repeated eigenvalues are discussed further in appendix
7(p628).
We now examine the ﬁxed points and lines of the hierarchy of projective transforma-
tion subgroups of section 2.4. Afﬁne transformations, and the more specialized forms,
have two eigenvectors which are ideal points (x3 = 0), and which correspond to the
eigenvectors of the upper left 2 × 2 matrix. The third eigenvector is ﬁnite in general.
A Euclidean matrix. The two ideal ﬁxed points are the complex conjugate pair of cir-
cular points I, J, with corresponding eigenvalues {eiθ, e−iθ}, where θ is the rotation an-
gle. The third eigenvector, which has unit eigenvalue, is called the pole. The Euclidean
transformation is equal to a pure rotation by θ about this point with no translation.
A special case is that of a pure translation (i.e. where θ = 0). Here the eigenvalues
are triply degenerate. The line at inﬁnity is ﬁxed pointwise, and there is a pencil of
ﬁxed lines through the point (tx, ty, 0)T which corresponds to the translation direction.
Consequently lines parallel to t are ﬁxed. This is an example of an elation (see section
A7.3(p631)).

A similarity matrix. The two ideal ﬁxed points are again the circular points. The
eigenvalues are {1, seiθ, se−iθ}. The action can be understood as a rotation and
isotropic scaling by s about the ﬁnite ﬁxed point. Note that the eigenvalues of the
circular points again encode the angle of rotation.

An afﬁne matrix. The two ideal ﬁxed points can be real or complex conjugates, but
the ﬁxed line l∞ = (0, 0, 1)T through these points is real in either case.

2.10 Closure

2.10.1 The literature
A gentle introduction to plane projective geometry, written for computer vision re-
searchers, is given in the appendix of Mundy and Zisserman [Mundy-92]. A more
formal approach is that of Semple and Kneebone [Semple-79], but [Springer-64] is
more readable.
On the recovery of afﬁne and metric scene properties for an imaged plane, Collins
and Beveridge [Collins-93] use the vanishing line to recover afﬁne properties from
satellite images, and Liebowitz and Zisserman [Liebowitz-98] use metric information
on the plane, such as right angles, to recover the metric geometry.

2.10.2 Notes and exercises

(i) Afﬁne transformations.

2.10 Closure

63
(a) Show that an afﬁne transformation can map a circle to an ellipse, but
cannot map an ellipse to a hyperbola or parabola.
(b) Prove that under an afﬁne transformation the ratio of lengths on parallel
line segments is an invariant, but that the ratio of two lengths that are
not parallel is not.

(ii) Projective transformations. Show that there is a three-parameter family of
projective transformations which ﬁx (as a set) a unit circle at the origin, i.e. a
unit circle at the origin is mapped to a unit circle at the origin (hint, use result
2.13(p37) to compute the transformation). What is the geometric interpretation
of this family?
(iii) Isotropies. Show that two lines have an invariant under a similarity transfor-
mation; and that two lines and two points have an invariant under a projective
transformation. In both cases the equality case of the counting argument (result
2.16(p43)) is violated. Show that for these two cases the respective transforma-
tion cannot be fully determined, although it is partially determined.
(iv) Invariants. Using the transformation rules for points, lines and conics show:
(a) Two lines, l1, l2, and two points, x1, x2, not lying on the lines have the

invariant

I =

(lT
(lT

1 x1)(lT
1 x2)(lT

2 x2)
2 x1)

(b) A conic C and two points, x1 and x2, in general position have the invari-

(see the previous question).
ant

I =

(xT
1 Cx2)2
1 Cx1)(xT

(xT

.

2 Cx2)

(c) Show that the projectively invariant expression for measuring an-
gles (2.22) is equivalent to Laguerre’s projectively invariant expression
involving a cross ratio with the circular points (see [Springer-64]).

(v) The cross ratio. Prove the invariance of the cross ratio of four collinear
points under projective transformations of the line (2.18–p45). Hint, start with
the transformation of two points on the line written as ¯x′i = λiH2×2¯xi and
¯x′j = λjH2×2¯xj, where equality is not up to scale, then from the properties of
determinants show that |¯x′i¯x′j| = λiλj det H2×2|¯xi¯xj| and continue from here.
An alternative derivation method is given in [Semple-79].
(vi) Polarity. Figure 2.19 shows the geometric construction of the polar line for a
point x outside an ellipse. Give a geometric construction for the polar when the
point is inside. Hint, start by choosing any line through x. The pole of this line
is a point on the polar of x.
(vii) Conics. If the sign of the conic matrix C is chosen such that two eigenvalues
are positive and one negative, then internal and external points may be distin-
guished according to the sign of xTCx: the point x is inside/on/outside the conic

64

2 Projective Geometry and Transformations of 2D

C if xTCx is negative/zero/positive respectively. This can seen by example from
a circle C = diag(1, 1,−1). Under projective transformations internality is in-
variant, though its interpretation requires care in the case of an ellipse being
transformed to a hyperbola (see ﬁgure 2.20).
(viii) Dual conics. Show that the matrix [l]×C[l]× represents a rank 2 dual conic
which consists of the two points at which the line l intersects the (point) conic
C (the notation [l]× is deﬁned in (A4.5–p581)).
(ix) Special projective transformations. Suppose points on a scene plane are re-
lated by reﬂection in a line: for example, a plane object with bilateral symmetry.
Show that in a perspective image of the plane the points are related by a pro-
jectivity H satisfying H2 = I. Furthermore, show that under H there is a line
of ﬁxed points corresponding to the imaged reﬂection line, and that H has an
eigenvector, not lying on this line, which is the vanishing point of the reﬂection
direction (H is a planar harmonic homology, see section A7.2(p629)).
Now suppose that the points are related by a ﬁnite rotational symmetry: for
example, points on a hexagonal bolt head. Show in this case that Hn = I,
where n is the order of rotational symmetry (6 for a hexagonal symmetry),
that the eigenvalues of H determine the rotation angle, and that the eigenvector
corresponding to the real eigenvalue is the image of the centre of the rotational
symmetry.

3

Projective Geometry and Transformations of 3D

This chapter describes the properties and entities of projective 3-space, or IP3. Many
of these are straightforward generalizations of those of the projective plane, described
in chapter 2. For example, in IP3 Euclidean 3-space is augmented with a set of ideal
points which are on a plane at inﬁnity, π∞. This is the analogue of l∞ in IP2. Par-
allel lines, and now parallel planes, intersect on π∞. Not surprisingly, homogeneous
coordinates again play an important role, here with all dimensions increased by one.
However, additional properties appear by virtue of the extra dimension. For example,
two lines always intersect on the projective plane, but they need not intersect in 3-space.
The reader should be familiar with the ideas and notation of chapter 2 before read-
ing this chapter. We will concentrate here on the differences and additional geometry
introduced by adding the extra dimension, and will not repeat the bulk of the material
of the previous chapter.

3.1 Points and projective transformations

A point X in 3-space is represented in homogeneous coordinates as a 4-vector. Specif-
ically, the homogeneous vector X = (X1, X2, X3, X4)T with X4 ̸= 0 represents the point
(X, Y, Z)T of IR3 with inhomogeneous coordinates

X = X1/X4, Y = X2/X4, Z = X3/X4.

For example, a homogeneous representation of (X, Y, Z)T is X = (X, Y, Z, 1)T. Homo-
geneous points with X4 = 0 represent points at inﬁnity.
A projective transformation acting on IP3 is a linear transformation on homogeneous
4-vectors represented by a non-singular 4×4 matrix: X′ = HX. The matrix H represent-
ing the transformation is homogeneous and has 15 degrees of freedom. The degrees of
freedom follow from the 16 elements of the matrix less one for overall scaling.
As in the case of planar projective transformations, the map is a collineation (lines
are mapped to lines), which preserves incidence relations such as the intersection point
of a line with a plane, and order of contact.
65

66

3 Projective Geometry and Transformations of 3D

3.2 Representing and transforming planes, lines and quadrics

In IP3 points and planes are dual, and their representation and development is analogous
to the point–line duality in IP2. Lines are self-dual in IP3.
3.2.1 Planes
A plane in 3-space may be written as

π1X + π2Y + π3Z + π4 = 0.

(3.1)
Clearly this equation is unaffected by multiplication by a non-zero scalar, so only the
three independent ratios {π1 : π2 : π3 : π4} of the plane coefﬁcients are signiﬁcant. It
follows that a plane has 3 degrees of freedom in 3-space. The homogeneous represen-
tation of the plane is the 4-vector π = (π1,π 2,π 3,π 4)T.
Homogenizing (3.1) by the replacements X ’→ X1/X4, Y ’→ X2/X4, Z ’→ X3/X4 gives

π1X1 + π2X2 + π3X3 + π4X4 = 0

or more concisely

πTX = 0

(3.2)

which expresses that the point X is on the plane π.
The ﬁrst 3 components of π correspond to the plane normal of Euclidean geometry
– using inhomogeneous notation (3.2) becomes the familiar plane equation written in
3-vector notation as n.6X + d = 0, where n = (π1,π 2,π 3)T, 6X = (X, Y, Z)T, X4 = 1
and d = π4. In this form d/∥n∥ is the distance of the plane from the origin.
Join and incidence relations.
planes and points and lines. For example,

In IP3 there are numerous geometric relations between

(i) A plane is deﬁned uniquely by the join of three points, or the join of a line and
point, in general position (i.e. the points are not collinear or incident with the
line in the latter case).

(ii) Two distinct planes intersect in a unique line.
(iii) Three distinct planes intersect in a unique point.
These relations have algebraic representations which will now be developed in the
case of points and planes. The representations of the relations involving lines are not
as simple as those arising from 3D vector algebra of IP2 (e.g. l = x × y), and are
postponed until line representations are introduced in section 3.2.2.
Three points deﬁne a plane. Suppose three points Xi are incident with the plane
π. Then each point satisﬁes (3.2) and thus πTXi = 0,
i = 1, . . . , 3. Stacking these
equations into a matrix gives

(3.3)

XT
1
XT
2
XT
3

⎡⎢⎣

⎤⎥⎦ π = 0.

3.2 Representing and transforming planes, lines and quadrics

67
Since three points X1, X2 and X3 in general position are linearly independent, it fol-
lows that the 3 × 4 matrix composed of the points as rows has rank 3. The plane
π deﬁned by the points is thus obtained uniquely (up to scale) as the 1-dimensional
(right) null-space. If the matrix has only a rank of 2, and consequently the null-space
is 2-dimensional, then the points are collinear, and deﬁne a pencil of planes with the
line of collinear points as axis.
In IP2, where points are dual to lines, a line l through two points x, y can similarly
be obtained as the null-space of the 2 × 3 matrix with xT and yT as rows. However, a
more convenient direct formula l = x × y is also available from vector algebra. In IP3
the analogous expression is obtained from properties of determinants and minors.
We start from the matrix M = [X, X1, X2, X3] which is composed of a general point
X and the three points Xi which deﬁne the plane π. The determinant det M = 0 when
X lies on π since the point X is then expressible as a linear combination of the points
Xi, i = 1, . . . , 3. Expanding the determinant about the column X we obtain

det M = X1D234 − X2D134 + X3D124 − X4D123

where Djkl is the determinant formed from the jkl rows of the 4×3 matrix [X1, X2, X3].
Since det M = 0 for points on π we can then read off the plane coefﬁcients as
(3.4)

π = (D234,−D134, D124,−D123)T .

This is the solution vector (the null-space) of (3.3) above.
Example3.1. Suppose the three points deﬁning the plane are

Z2 − Z3
0
and similarly for the other components, giving

Z2
1

0

Y1 Y2 Y3
Z3
Z1
1
1

1 5 X3 =4 6X3
1 5

1 5 X2 =4 6X2
Y1 − Y3 Y2 − Y3 Y3
Z3
Z1 − Z3
1

X1 =4 6X1
where 6X = (X, Y, Z)T. Then
=(((((((
(((((((
D234 =(((((((
(((((((
π =4 (6X1 − 6X3) × (6X2 − 6X3)
−6XT
3 (6X1 × 6X2)
This is the familiar result from Euclidean vector geometry where, for example, the
plane normal is computed as (6X1 − 6X3) × (6X2 − 6X3).
△
Three planes deﬁne a point.
The development here is dual to the case of three
points deﬁning a plane. The intersection point X of three planes πi can be computed
straightforwardly as the (right) null-space of the 3 × 4 matrix composed of the planes
as rows:

=/(6X1 − 6X3) × (6X2 − 6X3)01
5 .

πT
1
πT
2
πT
3

⎡⎢⎣

⎤⎥⎦ X = 0.

(3.5)

68

3 Projective Geometry and Transformations of 3D

Fig. 3.1. A line may be speciﬁed by its points of intersection with two orthogonal planes. Each inter-
section point has 2 degrees of freedom, which demonstrates that a line in IP3 has a total of 4 degrees of
freedom.
A direct solution for X, in terms of determinants of 3 × 3 submatrices, is obtained as
an analogue of (3.4), though computationally a numerical solution would be obtained
by algorithm A5.1(p589).
The two following results are direct analogues of their 2D counterparts.
Projective transformation. Under the point transformation X′ = HX, a plane trans-
forms as

π′ = H−Tπ.

(3.6)

Parametrized points on a plane. The points X on the plane π may be written as

X = Mx

(3.7)
where the columns of the 4×3 matrix M generate the rank 3 null-space of πT, i.e. πTM =
0, and the 3-vector x (which is a point on the projective plane IP2) parametrizes points
on the plane π. M is not unique, of course. Suppose the plane is π = (a, b, c, d)T and a is
non-zero, then MT can be written as MT = [p| I3×3], where p = (−b/a,−c/a,−d/a)T.
This parametrized representation is simply the analogue in 3D of a line l in IP2
deﬁned as a linear combination of its 2D null-space as x = µa + λb, where lTa =
lTb = 0.
3.2.2 Lines
A line is deﬁned by the join of two points or the intersection of two planes. Lines
have 4 degrees of freedom in 3-space. A convincing way to count these degrees of
freedom is to think of a line as deﬁned by its intersection with two orthogonal planes,
as in ﬁgure 3.1. The point of intersection on each plane is speciﬁed by two parameters,
producing a total of 4 degrees of freedom for the line.
Lines are very awkward to represent in 3-space since a natural representation for an
object with 4 degrees of freedom would be a homogeneous 5-vector. The problem is
that a homogeneous 5 vector cannot easily be used in mathematical expressions to-
gether with the 4-vectors representing points and planes. To overcome this problem

3.2 Representing and transforming planes, lines and quadrics

69
a number of line representations have been proposed, and these differ in their math-
ematical complexity. We survey three of these representations. In each case the rep-
resentation provides mechanisms for a line to be deﬁned by: the join of two points,
a dual version where the line is deﬁned by the intersection of two planes, and also a
map between the two deﬁnitions. The representations also enable join and incidence
relations to be computed, for example the point at which a line intersects a plane.
I. Null-space and span representation. This representation builds on the intuitive
geometric notion that a line is a pencil (one-parameter family) of collinear points, and is
deﬁned by any two of these points. Similarly, a line is the axis of a pencil of planes, and
is deﬁned by the intersection of any two planes from the pencil. In both cases the actual
points or planes are not important (in fact two points have 6 degrees of freedom and
are represented by two 4-vectors – far too many parameters). This notion is captured
mathematically by representing a line as the span of two vectors. Suppose A, B are two
(non-coincident) space points. Then the line joining these points is represented by the
span of the row space of the 2 × 4 matrix W composed of AT and BT as rows:

W =1 AT
BT 2 .

Then:

(i) The span of WT is the pencil of points λA + µB on the line.
(ii) The span of the 2-dimensional right null-space of W is the pencil of planes with

the line as axis.

It is evident that two other points, A′T and B′T, on the line will generate a matrix W′
with the same span as W, so that the span, and hence the representation, is independent
of the particular points used to deﬁne it.
To prove the null-space property, suppose that P and Q are a basis for the null-space.
Then WP = 0 and consequently ATP = BTP = 0, so that P is a plane containing the
points A and B. Similarly, Q is a distinct plane also containing the points A and B.
Thus A and B lie on both the (linearly independent) planes P and Q, so the line deﬁned
by W is the plane intersection. Any plane of the pencil, with the line as axis, is given by
the span λ′P + µ′Q.
The dual representation of a line as the intersection of two planes, P, Q, follows in
a similar manner. The line is represented as the span (of the row space) of the 2 × 4
matrix W∗ composed of PT and QT as rows:

W∗ =1 PT
QT 2

with the properties

(i) The span of W∗T is the pencil of planes λ′P + µ′Q with the line as axis.
(ii) The span of the 2-dimensional null-space of W∗ is the pencil of points on the

line.

3 Projective Geometry and Transformations of 3D

70
The two representations are related by W∗ WT = W W∗T = 02×2, where 02×2 is a 2 × 2
null matrix.
Example3.2. The X-axis is represented as

W =1 0 0 0 1
1 0 0 0 2

W∗ =1 0 0 1 0
0 1 0 0 2

where the points A and B are here the origin and ideal point in the X-direction, and the
planes P and Q are the XY- and XZ-planes respectively.
△
Join and incidence relations are also computed from null-spaces.

(i) The plane π deﬁned by the join of the point X and line W is obtained from the

null-space of

M =1 W

XT 2 .

(ii) The point X deﬁned by the intersection of the line W with the plane π is obtained

If the null-space of M is 2-dimensional then X is on W, otherwise Mπ = 0.
from the null-space of

M =1 W∗
πT 2 .

If the null-space of M is 2-dimensional then the line W is on π, otherwise MX = 0.
These properties can be derived almost by inspection. For example, the ﬁrst is equiva-
lent to three points deﬁning a plane (3.3).
The span representation is very useful in practical numerical implementations where
null-spaces can be computed simply by using the SVD algorithm (see section A4.4-
(p585)) available with most matrix packages. The representation is also useful in es-
timation problems, where it is often not a problem that the entity being estimated is
over-parametrized (see the discussion of section 4.5(p110)).
II. Pl¨ucker matrices. Here a line is represented by a 4 × 4 skew-symmetric homo-
geneous matrix. In particular, the line joining the two points A, B is represented by the
matrix L with elements

or equivalently in vector notation as

lij = AiBj − BiAj

First a few properties of L:

L = ABT − BAT

(3.8)

(i) L has rank 2. Its 2-dimensional null-space is spanned by the pencil of planes

with the line as axis (in fact LW∗T = 0, with 0 a 4 × 2 null-matrix).

3.2 Representing and transforming planes, lines and quadrics

71
(ii) The representation has the required 4 degrees of freedom for a line. This is ac-
counted as follows: the skew-symmetric matrix has 6 independent non-zero ele-
ments, but only their 5 ratios are signiﬁcant, and furthermore because det L = 0
the elements satisfy a (quadratic) constraint (see below). The net number of de-
grees of freedom is then 4.
(iii) The relation L = ABT − BAT is the generalization to 4-space of the vector
product formula l = x × y of IP2 for a line l deﬁned by two points x, y all
represented by 3-vectors.
(iv) The matrix L is independent of the points A, B used to deﬁne it, since if a
different point C on the line is used, with C = A + µB, then the resulting
matrix is

ˆL = ACT − CAT = A(AT + µBT) − (A + µB)AT

= ABT − BAT = L.

(v) Under the point transformation X′ = HX, the matrix transforms as L′ = HLHT,

i.e. it is a valency-2 tensor (see appendix 1(p562)).

Example3.3. From (3.8) the X-axis is represented as

L =⎛⎜⎜⎜⎝

0
0
0
1

⎞⎟⎟⎟⎠/ 1 0 0 0 0 −

⎛⎜⎜⎜⎝

1
0
0
0

⎞⎟⎟⎟⎠/ 0 0 0 1 0 =⎡⎢⎢⎢⎣

0 0 0 −1
0
0 0 0
0 0 0
0
0
1 0 0

⎤⎥⎥⎥⎦

where the points A and B are (as in the previous example) the origin and ideal point in
the X-direction respectively.
△
A dual Pl¨ucker representation L∗ is obtained for a line formed by the intersection of
two planes P, Q,

(3.9)
and has similar properties to L. Under the point transformation X′ = HX, the matrix
L∗ transforms as L∗′ = H−TLH−1. The matrix L∗ can be obtained directly from L by a
simple rewrite rule:

L∗ = PQT − QPT

l12 : l13 : l14 : l23 : l42 : l34 = l∗34 : l∗42 : l∗23 : l∗14 : l∗13 : l∗12.

(3.10)
The correspondence rule is very simple: the indices of the dual and original component
always include all the numbers {1, 2, 3, 4}, so if the original is ij then the dual is those
numbers of {1, 2, 3, 4} which are not ij. For example 12 ’→ 34.
Join and incidence properties are very nicely represented in this notation:
(i) The plane deﬁned by the join of the point X and line L is

and L∗X = 0 if, and only if, X is on L.

π = L∗X

X =⎡⎢⎢⎢⎣

0 0 0 −1
0
0 0 0
0
0 0 0
1 0 0
0

⎤⎥⎥⎥⎦

⎛⎜⎜⎜⎝

1
0
0
−1

⎞⎟⎟⎟⎠

=⎛⎜⎜⎜⎝

1
0
0
1

⎞⎟⎟⎟⎠

72

3 Projective Geometry and Transformations of 3D

(ii) The point deﬁned by the intersection of the line L with the plane π is

and Lπ = 0 if, and only if, L is on π.

X = Lπ

The properties of two (or more) lines L1, L2, . . . can be obtained from the null-space
of the matrix M = [L1, L2, . . .]. For example if the lines are coplanar then MT has a
1-dimensional null-space corresponding to the plane π of the lines.
Example3.4. The intersection of the X-axis with the plane X = 1 is given by X = Lπ
as

△
The Pl¨ucker line coordinates are the six non-zero

which is the inhomogeneous point (X, Y, Z)T = (1, 0, 0)T.
III. Pl¨ucker line coordinates.
elements of the 4 × 4 skew-symmetric Pl¨ucker matrix (3.8) L, namely1
(3.11)
This is a homogeneous 6-vector, and thus is an element of IP5. It follows from evaluat-
ing det L = 0 that the coordinates satisfy the equation

L = {l12, l13, l14, l23, l42, l34}.

l12l34 + l13l42 + l14l23 = 0.

(3.12)
A 6-vector L only corresponds to a line in 3-space if it satisﬁes (3.12). The geometric
interpretation of this constraint is that the lines of IP3 deﬁne a (co-dimension 1) surface
in IP5 which is known as the Klein quadric, a quadric because the terms of (3.12) are
quadratic in the Pl¨ucker line coordinates.
lines intersect if and only if the four points are coplanar. A necessary and sufﬁcient
expands as

Suppose two lines L, ˆL are the joins of the points A, B and 7A,7B respectively. The
condition for this is that det[A, B,7A,7B] = 0. It can be shown that the determinant

= (L| ˆL).

det[A, B,7A,7B] = l12ˆl34 + ˆl12l34 + l13ˆl42 + ˆl13l42 + l14ˆl23 + ˆl14l23

(3.13)
Since the Pl¨ucker coordinates are independent of the particular points used to deﬁne
them, the bilinear product (L| ˆL) is independent of the points used in the derivation and
only depends on the lines L and ˆL. Then we have
Result3.5. Two lines L and ˆL are coplanar (and thus intersect) if and only if (L| ˆL) =
0.
This product appears in a number of useful formulae:
1 The element l42 is conventionally used instead of l24 as it eliminates negatives in many of the subsequent formulae.

3.2 Representing and transforming planes, lines and quadrics

the Klein quadric constraint (3.12) above.
tively. Then

73
(i) A 6-vector L only represents a line in IP3 if (L|L) = 0. This is simply repeating
(ii) Suppose two lines L, ˆL are the intersections of the planes P, Q and 7P,7Q respec-
(L| ˆL) = det[P, Q,7P,7Q]
and again the lines intersect if and only if (L| ˆL) = 0.
and B, then

(iii) If L is the intersection of two planes P and Q and ˆL is the join of two points A
(3.14)
Pl¨ucker coordinates are useful in algebraic derivations. They will be used in deﬁning

(L| ˆL) = (PTA)(QTB) − (QTA)(PTB).

the map from a line in 3-space to its image in chapter 8.
3.2.3 Quadrics and dual quadrics
A quadric is a surface in IP3 deﬁned by the equation

(3.15)
where Q is a symmetric 4 × 4 matrix. Often the matrix Q and the quadric surface it
deﬁnes are not distinguished, and we will simply refer to the quadric Q.
Many of the properties of quadrics follow directly from those of conics in section
2.2.3(p30). To highlight a few:

XTQX = 0

elements of a 4 × 4 symmetric matrix less one for scale.

(i) A quadric has 9 degrees of freedom. These correspond to the ten independent
(ii) Nine points in general position deﬁne a quadric.
(iii) If the matrix Q is singular, then the quadric is degenerate, and may be deﬁned
by fewer points.
(iv) A quadric deﬁnes a polarity between a point and a plane, in a similar manner
to the polarity deﬁned by a conic between a point and a line (section 2.8.1).
The plane π = QX is the polar plane of X with respect to Q. In the case that Q
is non-singular and X is outside the quadric, the polar plane is deﬁned by the
points of contact with Q of the cone of rays through X tangent to Q. If X lies on
Q, then QX is the tangent plane to Q at X.
(v) The intersection of a plane π with a quadric Q is a conic C. Computing the
conic can be tricky because it requires a coordinate system for the plane. Recall
from (3.7) that a coordinate system for the plane can be deﬁned by the comple-
ment space to π as X = Mx. Points on π are on Q if XTQX = xTMTQMx = 0.
These points lie on a conic C, since xTCx = 0, with C = MTQM.

(vi) Under the point transformation X′ = HX, a (point) quadric transforms as

(3.16)
The dual of a quadric is also a quadric. Dual quadrics are equations on planes: the
tangent planes π to the point quadric Q satisfy πTQ∗π = 0, where Q∗ = adjoint Q,

Q′ = H−TQH−1.

3 Projective Geometry and Transformations of 3D

74
or Q−1 if Q is invertible. Under the point transformation X′ = HX, a dual quadric
transforms as

(3.17)
The algebra of imaging a quadric is far simpler for a dual quadric than a point quadric.
This is detailed in chapter 8.

Q∗′ = HQ∗HT.

3.2.4 Classiﬁcation of quadrics
Since the matrix, Q, representing a quadric is symmetric, it may be decomposed as
Q = UTDU where U is a real orthogonal matrix and D is a real diagonal matrix. Further,
by appropriate scaling of the rows of U, one may write Q = HTDH where D is diagonal
with entries equal to 0, 1, or −1. We may further ensure that the zero entries of D
appear last along the diagonal, and that the +1 entries appear ﬁrst. Now, replacement
of Q = HTDH by D is equivalent to a projective transformation effected by the matrix
H (see (3.16)). Thus, up to projective equivalence, we may assume that the quadric is
represented by a matrix D of the given simple form.
The signature of a diagonal matrix D, denoted σ(D), is deﬁned to be the number of
+1 entries minus the number of −1 entries. This deﬁnition is extended to arbitrary
real symmetric matrices Q by deﬁning σ(Q) = σ(D) such that Q = HTDH, where H is
a real matrix. It may be proved that the signature is well deﬁned, being independent
of the particular choice of H. Since the matrix representing a quadric is deﬁned only
up to sign, we may assume that its signature is non-negative. Then, the projective type
of a quadric is uniquely determined by its rank and signature. This will allow us to
enumerate the different projective equivalence classes of quadrics.
A quadric represented by a diagonal matrix diag(d1, d2, d3, d4) corresponds to a set
of points satisfying an equation d1X2 + d2Y2 + d3Z2 + d4T2 = 0. One may set T = 1 to
get an equation for the non-inﬁnite points on the quadric. See table 3.1. Examples of
quadric surfaces are shown in ﬁgure 3.2 – ﬁgure 3.4.

Rank
4

3

2

1

Diagonal
(1, 1, 1, 1)
(1, 1, 1,−1)
(1, 1,−1,−1)
(1, 1, 1, 0)
(1, 1,−1, 0)
(1, 1, 0, 0)
(1,−1, 0, 0)
(1, 0, 0, 0)

σ
4
2
0
3
1
2
0
1

Equation

X2 + Y2 + Z2 + 1 = 0

X2 + Y2 + Z2 = 1
X2 + Y2 = Z2 + 1
X2 + Y2 + Z2 = 0

X2 + Y2 = Z2
X2 + Y2 = 0

X2 = Y2
X2 = 0

Realization
No real points

Sphere

Hyperboloid of one sheet
One point (0, 0, 0, 1)T
Cone at the origin
Single line (Z-axis)
Two planes X = ±Y
The plane X = 0

Table 3.1. Categorization of point quadrics.

3.3 Twisted cubics

75

Fig. 3.2. Non-ruled quadrics. This shows plots of a sphere, ellipsoid, hyperboloid of two sheets and
paraboloid. They are all projectively equivalent.

Fig. 3.3. Ruled quadrics. Two examples of a hyperboloid of one sheet are given. These surfaces are
given by equations X2 + Y2 = Z2 + 1 and XY = Z respectively, and are projectively equivalent. Note
that these two surfaces are made up of two sets of disjoint straight lines, and that each line from one set
meets each line from the other set. The two quadrics shown here are projectively (though not afﬁnely)
equivalent.

Ruled quadrics. Quadrics fall into two classes – ruled and unruled quadrics. A
ruled quadric is one that contains a straight line. More particularly, as shown in
ﬁgure 3.3, the non-degenerate ruled quadric (hyperboloid of one sheet) contains two
families of straight lines called generators. For more properties of ruled quadrics, refer
to [Semple-79].
The most interesting of the quadrics are the two quadrics of rank 4. Note that these
two quadrics differ even in their topological type. The quadric of signature 2 (the
sphere) is (obviously enough) topologically a sphere. On the other hand, the hyper-
boloid of 1 sheet is not topologically equivalent (homeomorphic) to a sphere. In fact,
it is topologically a torus (topologically equivalent to S1 × S1). This gives the clearest
indication that they are not projectively equivalent.

3.3 Twisted cubics

The twisted cubic may be considered to be a 3-dimensional analogue of a 2D conic
(although in other ways it is a quadric surface which is the 3-dimensional analogue of
a 2D conic.)

76

3 Projective Geometry and Transformations of 3D

Fig. 3.4. Degenerate quadrics. The two most important degenerate quadrics are shown, the cone and
two planes. Both these quadrics are ruled. The matrix representing the cone has rank 3, and the null-
vector represents the nodal point of the cone. The matrix representing the two (non-coincident) planes
has rank 2, and the two generators of the rank 2 null-space are two points on the intersection line of the
planes.

A conic in the 2-dimensional projective plane may be described as a parametrized

curve given by the equation

⎛⎜⎝

x1
x2
x3

⎞⎟⎠ = A⎛⎜⎝

1
θ
θ2

⎞⎟⎠ =⎛⎜⎝

a11 + a12θ + a13θ2
a21 + a22θ + a23θ2
a31 + a32θ + a33θ2

⎞⎟⎠

(3.18)

where A is a non-singular 3 × 3 matrix.
In an analogous manner, a twisted cubic is deﬁned to be a curve in IP3 given in
parametric form as
X1
X2
X3
X4

a11 + a12θ + a13θ2 + a14θ3
a21 + a22θ + a23θ2 + a24θ3
a31 + a32θ + a33θ2 + a34θ3
a41 + a42θ + a43θ2 + a44θ3

(3.19)

1
θ
θ2
θ3

where A is a non-singular 4 × 4 matrix.
Since a twisted cubic is perhaps an unfamiliar object, various views of the curve are
shown in ﬁgure 3.5. In fact, a twisted cubic is a quite benign space curve.

⎞⎟⎟⎟⎠

= A⎛⎜⎜⎜⎝

⎞⎟⎟⎟⎠

=⎛⎜⎜⎜⎝

⎞⎟⎟⎟⎠

⎛⎜⎜⎜⎝

Properties of a twisted cubic. Let c be a non-singular twisted cubic. Then c is not
contained within any plane of IP3; it intersects a general plane at three distinct points. A
twisted cubic has 12 degrees of freedom (counted as 15 for the matrix A, less 3 for a 1D
projectivity on the parametrization θ, which leaves the curve unaltered). Requiring the
curve to pass through a point X places two constraints on c, since X = A(1,θ,θ 2,θ 3)T
is three independent ratios, but only two constraints once θ is eliminated. Thus, there
is a unique c through six points in general position. Finally, all non-degenerate twisted
cubics are projectively equivalent. This is clear from the deﬁnition (3.19): a projective
transformation A−1 maps c to the standard form c(θ′) = (1,θ ′,θ ′2,θ ′3)T, and since

3.4 The hierarchy of transformations

77

Fig. 3.5. Various views of the twisted cubic (t3, t2, t, )T. The curve is thickened to a tube to aid in
visualization.

all twisted cubics can be mapped to this curve, it follows that all twisted cubics are
projectively equivalent.
A classiﬁcation of the various special cases of a twisted cubic, such as a conic and
coincident line, are given in [Semple-79]. The twisted cubic makes an appearance as
the horopter for two-view geometry (chapter 9), and plays the central role in deﬁning
the degenerate set for camera resectioning (chapter 22).

3.4 The hierarchy of transformations

There are a number of specializations of a projective transformation of 3-space which
will appear frequently throughout this book. The specializations are analogous to the
strata of section 2.4(p37) for planar transformations. Each specialization is a sub-
group, and is identiﬁed by its matrix form, or equivalently by its invariants. These are
summarized in table 3.2. This table lists only the additional properties of the 3-space
transformations over their 2-space counterparts – the transformations of 3-space also
have the invariants listed in table 2.1(p44) for the corresponding 2-space transforma-
tions.
The 15 degrees of freedom of a projective transformation are accounted for as seven
for a similarity (three for rotation, three for translation, one for isotropic scaling), ﬁve
for afﬁne scalings, and three for the projective part of the transformation.
Two of the most important characterizations of these transformations are parallelism
and angles. For example, after an afﬁne transformation lines which were originally
parallel remain parallel, but angles are skewed; and after a projective transformation
parallelism is lost.
In the following we brieﬂy describe a decomposition of a Euclidean transformation
that will be useful when discussing special motions later in this book.
3.4.1 The screw decomposition
A Euclidean transformation on the plane may be considered as a specialization of a
Euclidean transformation of 3-space with the restrictions that the translation vector t
lies in the plane, and the rotation axis is perpendicular to the plane. However, Euclidean
actions on 3-space are more general than this because the rotation axis and translation
are not perpendicular in general. The screw decomposition enables any Euclidean

78

3 Projective Geometry and Transformations of 3D

Group

Matrix

Distortion

Invariant properties

Projective
15 dof

8 A

vT

t

v 9

Afﬁne
12 dof

8 A

0T

t

1 9

Similarity
7 dof

8 sR

0T

t

1 9

Euclidean
6 dof

8 R

0T

t

1 9

Intersection and tangency of sur-
faces in contact. Sign of Gaussian
curvature.

Parallelism of planes, volume ra-
tios, centroids. The plane at inﬁn-
ity, π∞, (see section 3.5).

The absolute conic, Ω∞,
(see section 3.6).

Volume.

Table 3.2. Geometric properties invariant to commonly occurring transformations of 3-space. The
matrix A is an invertible 3 × 3 matrix, R is a 3D rotation matrix, t = (tX, tY, tZ)T a 3D translation, v
a general 3-vector, v a scalar, and 0 = (0, 0, 0)T a null 3-vector. The distortion column shows typical
effects of the transformations on a cube. Transformations higher in the table can produce all the actions
of the ones below. These range from Euclidean, where only translations and rotations occur, to projective
where ﬁve points can be transformed to any other ﬁve points (provided no three points are collinear, or
four coplanar).

action (a rotation composed with a translation) to be reduced to a situation almost as
simple as the 2D case. The screw decomposition is that
Result3.6. Any particular translation and rotation is equivalent to a rotation about a
screw axis together with a translation along the screw axis. The screw axis is parallel
to the rotation axis.
In the case of a translation and an orthogonal rotation axis (termed planar motion), the
motion is equivalent to a rotation alone about the screw axis.
Proof. We will sketch a constructive geometric proof that can easily be visualized.
Consider ﬁrst the 2D case – a Euclidean transformation on the plane.
It is evident
from ﬁgure 3.6 that a screw axis exists for such 2D transformations. For the 3D case,
decompose the translation t into two components t = t∥ + t⊥, parallel and orthogonal
respectively to the rotation axis direction (t∥ = (t.a)a, t⊥ = t − (t.a)a).
Then the Euclidean motion is partitioned into two parts: ﬁrst a rotation about the screw

3.5 The plane at inﬁnity

79

y

/

x

/

O /

t

y

O

a

R(   )(cid:84)

x

y

/

(cid:84)

S

x

/

O /

y

O

b

x

Fig. 3.6. 2D Euclidean motion and a “screw” axis. (a) The frame {x, y} undergoes a translation t⊥
and a rotation by θ to reach the frame {x′, y′}. The motion is in the plane orthogonal to the rotation
axis. (b) This motion is equivalent to a single rotation about the screw axis S. The screw axis lies on the
perpendicular bisector of the line joining corresponding points, such that the angle between the lines
joining S to the corresponding points is θ. In the ﬁgure the corresponding points are the two frame
origins and θ has the value 90◦.

screw
axis

O

t

a

S
(cid:84)

a

O /

screwaxis

O

a

S /

O/
t

S

O /

b

Fig. 3.7. 3D Euclidean motion and the screw decomposition. Any Euclidean rotation R and trans-
lation t may be achieved by (a) a rotation about the screw axis, followed by (b) a translation along the
screw axis by t∥. Here a is the (unit) direction of the rotation axis (so that Ra = a), and t is decomposed
as t = t∥ + t⊥, which are vector components parallel and orthogonal respectively to the rotation axis
direction The point S is closest to O on the screw axis (so that the line from S to O is perpendicular to
the direction of a). Similarly S′ is the point on the screw axis closest to O′.

axis, which covers the rotation and t⊥; second a translation by t∥ along the screw axis.
The complete motion is illustrated in ﬁgure 3.7.
The screw decomposition can be determined from the ﬁxed points of the 4×4 matrix
representing the Euclidean transformation. This idea is examined in the exercises at the
end of the chapter.

3.5 The plane at inﬁnity

In planar projective geometry identifying the line at inﬁnity, l∞, allowed afﬁne prop-
erties of the plane to be measured. Identifying the circular points on l∞ then allowed

3 Projective Geometry and Transformations of 3D

80
the measurement of metric properties. In the projective geometry of 3-space the corre-
sponding geometric entities are the plane at inﬁnity, π∞, and the absolute conic, Ω∞.
The plane at inﬁnity has the canonical position π∞ = (0, 0, 0, 1)T in afﬁne 3-space.
It contains the directions D = (X1, X2, X3, 0)T, and enables the identiﬁcation of afﬁne
properties such as parallelism. In particular:
• Two planes are parallel if, and only if, their line of intersection is on π∞.
• A line is parallel to another line, or to a plane, if the point of intersection is on π∞.
We then have in IP3 that any pair of planes intersect in a line, with parallel planes
intersecting in a line on the plane at inﬁnity.
The plane π∞ is a geometric representation of the 3 degrees of freedom required
to specify afﬁne properties in a projective coordinate frame. In loose terms, the plane
at inﬁnity is a ﬁxed plane under any afﬁne transformation, but “sees” (is moved by) a
projective transformation. The 3 degrees of freedom of π∞ thus measure the projective
component of a general homography – they account for the 15 degrees of freedom of
this general transformation compared to an afﬁnity (12 dof). More formally:
Result3.7. The plane at inﬁnity, π∞, is a ﬁxed plane under the projective transforma-
tion H if, and only if, H is an afﬁnity.
The proof is the analogue of the derivation of result 2.17(p48). It is worth clarifying
two points:

(i) The plane π∞ is, in general, only ﬁxed as a set under an afﬁnity; it is not ﬁxed
pointwise.
(ii) Under a particular afﬁnity (for example a Euclidean motion) there may be
planes in addition to π∞ which are ﬁxed. However, only π∞ is ﬁxed under
any afﬁnity.

These points are illustrated in more detail by the following example.
Example3.8. Consider the Euclidean transformation represented by the matrix

0T 1 2 =⎡⎢⎢⎢⎣
HE =1 R 0

cos θ

cos θ − sin θ 0 0
0 0
sin θ
0
1 0
0 1
0

0
0

.

(3.20)

⎤⎥⎥⎥⎦

This is a rotation by θ about the Z-axis with a zero translation (it is a planar screw
motion, see section 3.4.1). Geometrically it is evident that the family of XY-planes or-
thogonal to the rotation axis are simply rotated about the Z-axis by this transformation.
This means that there is a pencil of ﬁxed planes orthogonal to the Z-axis. The planes
are ﬁxed as sets, but not pointwise as any (ﬁnite) point (not on the axis) is rotated in
horizontal circles by this Euclidean action. Algebraically, the ﬁxed planes of H are the
eigenvectors of HT (refer to section 2.9). In this case the eigenvalues are {eiθ, e−iθ, 1, 1}

and the corresponding eigenvectors of HT

E are

3.6 The absolute conic

81

E1 =⎛⎜⎜⎜⎝

1
i
0
0

⎞⎟⎟⎟⎠

E2 =⎛⎜⎜⎜⎝

1
−i
0
0

⎞⎟⎟⎟⎠

E3 =⎛⎜⎜⎜⎝

0
0
1
0

⎞⎟⎟⎟⎠

E4 =⎛⎜⎜⎜⎝

0
0
0
1

.

⎞⎟⎟⎟⎠

The eigenvectors E1 and E2 do not correspond to real planes, and will not be discussed
further here. The eigenvectors E3 and E4 are degenerate. Thus there is a pencil of
ﬁxed planes which is spanned by these eigenvectors. The axis of this pencil is the line
of intersection of the the planes (perpendicular to the Z-axis) with π∞, and the pencil
includes π∞.
△
The example also illustrates the connection between the geometry of the projective
plane, IP2, and projective 3-space, IP3. A plane π intersects π∞ in a line which is
the line at inﬁnity, l∞, of the plane π. A projective transformation of IP3 induces a
subordinate plane projective transformation on π.
Afﬁne properties of a reconstruction.
In later chapters on reconstruction, for exam-
ple chapter 10, it will be seen that the projective coordinates of the (Euclidean) scene
can be reconstructed from multiple views. Once π∞ is identiﬁed in projective 3-space,
i.e. its projective coordinates are known, it is then possible to determine afﬁne prop-
erties of the reconstruction such as whether geometric entities are parallel – they are
parallel if they intersect on π∞.
A more algorithmic approach is to transform IP3 so that the identiﬁed π∞ is moved
to its canonical position at π∞ = (0, 0, 0, 1)T. After this mapping we then have the
situation that the Euclidean scene, where π∞ has the coordinates (0, 0, 0, 1)T, and our
reconstruction are related by a projective transformation that ﬁxes π∞ at (0, 0, 0, 1)T. It
follows from result 3.7 that the scene and reconstruction are related by an afﬁne trans-
formation. Thus afﬁne properties can now be measured directly from the coordinates
of the entities.

3.6 The absolute conic

The absolute conic, Ω∞, is a (point) conic on π∞. In a metric frame π∞ = (0, 0, 0, 1)T,
and points on Ω∞ satisfy

X2
1 + X2

2 + X2

3X4 : = 0.

(3.21)

Note that two equations are required to deﬁne Ω∞.
For directions on π∞ (i.e. points with X4 = 0 ) the deﬁning equation can be written

(X1, X2, X3)I(X1, X2, X3)T = 0

so that Ω∞ corresponds to a conic C with matrix C = I. It is thus a conic of purely
imaginary points on π∞.

82

3 Projective Geometry and Transformations of 3D

The conic Ω∞ is a geometric representation of the 5 additional degrees of freedom
that are required to specify metric properties in an afﬁne coordinate frame. A key
property of Ω∞ is that it is a ﬁxed conic under any similarity transformation. More
formally:
Result3.9. The absolute conic, Ω∞, is a ﬁxed conic under the projective transformation
H if, and only if, H is a similarity transformation.
Proof. Since the absolute conic lies in the plane at inﬁnity, a transformation ﬁxing it
must ﬁx the plane at inﬁnity, and hence must be afﬁne. Such a transformation is of the
form

HA =1 A

0T 1 2 .

t

Restricting to the plane at inﬁnity, the absolute conic is represented by the matrix I3×3,
and since it is ﬁxed by HA, one has A−TIA−1 = I (up to scale), and taking inverses gives
AAT = I. This means that A is orthogonal, hence a scaled rotation, or scaled rotation
with reﬂection. This completes the proof.
Even though Ω∞ does not have any real points, it shares the properties of any conic –
such as that a line intersects a conic in two points; the pole–polar relationship etc. Here
are a few particular properties of Ω∞:

(i) Ω∞ is only ﬁxed as a set by a general similarity; it is not ﬁxed pointwise. This
means that under a similarity a point on Ω∞ may travel to another point on Ω∞,
but it is not mapped to a point off the conic.
(ii) All circles intersect Ω∞ in two points. Suppose the support plane of the circle
is π. Then π intersects π∞ in a line, and this line intersects Ω∞ in two points.
These two points are the circular points of π.

(iii) All spheres intersect π∞ in Ω∞.
Metric properties. Once Ω∞ (and its support plane π∞) have been identiﬁed in
projective 3-space then metric properties, such as angles and relative lengths, can be
measured.
Consider two lines with directions (3-vectors) d1 and d2. The angle between these
directions in a Euclidean world frame is given by
(dT
1 d2)
1 d1)(dT

(3.22)

cos θ =

.

2 d2)

3(dT

This may be written as

cos θ =

(dT
1 Ω∞d2)
1 Ω∞d1)(dT

3(dT

2 Ω∞d2)

(3.23)

where d1 and d2 are the points of intersection of the lines with the plane π∞ containing
the conic Ω∞, and Ω∞ is the matrix representation of the absolute conic in that plane.

