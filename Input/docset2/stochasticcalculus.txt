To my wife, Betsy and my mother, Vicky 

Mircea Grigoriu 

Stochastic Calculus 

Applications in Science 

and Engineering 

Springer Science+Business Media, LLC 

Mircea Grigoriu 
Cornell University 
School of Civil 

Ithaca, NY 14853 
U.S.A. 

and Environmental Engineering 

Library of Congress Cataloging-in-Publication Data 

Grigoriu, Mircea. 

Stochastic calculus : applications in science and engineering I Mircea Grigoriu. 

p.cm. 

Includes bibliographical references and index. 
ISBN 978-1-4612-6501-6 
1. Stochastic analysis.  I. Title. 

QA274.2.G75 2002 
519.2-dc21 

2002074386 

CIP 

ISBN 978-1-4612-6501-6 
DOI 10.1007/978-0-8176-8228-6 

ISBN 978-0-8176-8228-6 (eBook) 

AMS Subject Oassifications: 37 A50, 60GXX, 35SXX, 35QXX 

Printed on acid-free paper. 
© 2002 Springer Science+Business Media New York 
Originally published by Birkhiiuser Boston in 2002 
Softcover reprint of the hardcover 1st edition 2002 

\:ti)® 
Birkhiiuser  ao» 

All rights reserved.  This work may not be translated or copied in whole or in part without the written 
permission of the publisher  (Springer Science+ Business Media, LLC), 
except for  brief excerpts  in  connection  with  reviews  or 
scholarly analysis. Use in connection with any form of information storage and retrieval, electronic 
adaptation, computer software, or by  similar or dissimilar methodology now known or hereafter 
developed is forbidden. 
The use of general descriptive names, trade names, trademarks, etc., in this publication, even if the 
former are not especially identified, is not to be taken as a sign that such names, as understood by the 
Trade Marks and Merchandise Marks Act, may accordingly be used freely by anyone. 

SPIN  10835902 

Typeset by the author. 

9  8 7  6  5 4  3  2  1 

Contents 

1  Introduction 

2  Probability Theory 
Introduction  .  . 

2.1 
2.2  Probability space  .. 
2.2.1  Sample space  . 
2.2.2 
2.2.3  Probability measure 

a-field  • •   0 

• 

2.3  Construction of probability spaces 

2.3.1  Countable sample space 
2.3.2  Product probability space . 
2.3.3  Extension of probability measure 
2.3.4  Conditional probability  . 
2.3.5  Sequence of sets 
2.3.6  Sequence of events 
2.4  Measurable functions  .  .  . 
Properties  .  .  .  .  . 

2.4.1 
2.4.2  Definition of random variable 
2.4.3  Measurable transformations 
Integration and expectation  .  .  .  .  .  . 
2.5.1  Expectation operator  .  .  .  .  . 

2.5 

2.5.1.1 
2.5.1.2 
2.5.1.3  Arbitrary random variables  .... 

Finite-valued simple random variables 
Positive random variables  .  .  .  . 

2.5.2  Properties of integrals of random variables 

2.5.2.1 
Finite number of random variables 
2.5.2.2 
Sequence of random variables  . 
2.5.2.3  Expectation  ............ 

2.6  The Lq (Q, F, P) space .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
2.7 

Independence  .  .  .  .  .  .  .  .  .  .  . 
2.7.1 
Independence of a-fields  . 
2.7.2 
Independence of events  . 

v 

1 

5 
5 
5 
5 
6 
8 
12 
13 
13 
16 
16 
18 
20 
21 
22 
22 
24 
26 
28 
28 
29 
29 
30 
30 
32 
33 
34 
36 
36 
36 

v1 

Contents 

2.7.3 

Independence of random variables 

2.8  The Fubini theorem  .  .  .  . 
2.9  Radon-Nikodym derivative  . 
2.10  Random variables  .  .  .  .  .  . 
2.10.1  Distribution function 
.  . 
2.10.2  Density function 
2.10.3  Characteristic function 

2.10.3.1  Properties 
2.10.3.2  Infinitely divisible characteristic function  . 
2.10.3.3  a-Stable random variable 

.  . 
2.11  Random vectors  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
2.11.1  Joint distribution and density functions 
2.11.2  Independence  .  .  .  .  . 
2.11.3  Characteristic function 
2.11.4  Moments 
2.11.5  Gaussian vector .  .  .  . 
.  .  .  .  .  . 

.  .  .  . 

2.12  U sefu1 inequalities 
2.13  Convergence of random variables . 
2.14  Random walk 
.  .  .  .  .  .  .  . 
2.15  Filtration 
2.16  Stopping time  .  .  .  .  .  . 
2.17  Conditional expectation  . 

2.17.1  a-field generated by a countable partition of Q 
2.17.2  General a-field 

2.18  Martingales  . . . . . . . .  . 
2.18.1  Properties  ..... . 
2.18.2  Stopped martingales 
2.18.3  Inequalities 

2.19  Problems  ... 

3  Stochastic Processes 
Introduction  . 

3.1 
3.2  Definitions .  .  . 
3.3  Continuity  .  .  . 
3.4  Stopping times 
3.5  Finite dimensional distributions and densities 
3.6  Classes of stochastic processes 

3.6.1  Stationary processes 
3.6.2  Ergodic processes .  .  . 
3.6.3  Markov processes .  .  . 
Independent increment processes 
3.6.4 
3.6.5  Gaussian processes  ...... . 
3.6.6  Translation processes  ..... . 
3.6.7  Mixture of translation processes 

38 
39 
41 
42 
43 
45 
47 
47 
52 
57 
58 
59 
61 
62 
64 
65 
68 
70 
75 
78 
78 
82 
84 
87 
92 
94 
96 
98 
99 

103 
103 
104 
110 
114 
117 
119 
119 
120 
120 
122 
124 
125 
126 

Contents 

3.7  Second moment properties  .......... . 

3. 7.1  Properties of the correlation function 
3.7.2  Power spectral density  ........ . 
3.7.2.1  Bochner's theorem ..... . 
stochastic processes  . 
3.7.2.2 
3.7.2.3  C-valued stochastic processes  . 
3.7.2.4 
-valued stochastic processes 

3.8  Equivalent stochastic processes  . 
3.9  Second moment calculus 
3.9.1  Continuity  .. 
3.9.2  Differentiation 
3.9.3 

. 
.  .  . 

Integration 
3.9.3.1  Variation functions. 
3.9.3.2  Conditions of existence 
3.9.3.3  Properties for calculations  . 
3.9.4  Spectral representation  .  .  .  .  .  .  .  . 

stochastic processes  . 

3.9.4.1  C- and 
3.9.4.2 
3.9.4.3  Random fields  .  .  .  .  .  .  .  .  .  .  . 
3.9.4.4  Karhunen-Loeverepresentation  . 

-valued stochastic processes  .  .  .  .  . 

3.10  Extremes of stochastic processes  . 
3.10.1  Mean crossing rate  .  .  .  . 
3.10.2  First passage time density 

3.11  Martingales  .  .  .  .  .  .  .  .  . 
3.11.1  Properties  .  .  .  .  .  . 
3 .11.2  Stopped martingales 
3 .11.3  Inequalities  .  .  .  .  . 
3.11.4  Quadratic variation and covariation processes 

3.12  Poisson processes  .  .  .  .  . 
3.13  Brownian motion process  . 
3.14  Levy processes 
.  .  .  .  .  . 
3.14.1  Properties  .  .  .  .  . 
3.14.2  The Levy decomposition  . 
.  .  .  .  .  .  .  .  .  .  .  .  . 

3.15  Problems 

4 

Ito's Formula and Stochastic Differential Equations 
4.1 
Introduction  .  .  .  .  .  .  .  .  .  .  .  .  . 
4.2  Riemann-Stieltjes integrals  .  .  .  .  . 
4.3  Preliminaries on stochastic integrals 
4.4  Stochastic integrals  .  .  .  .  .  .  .  .  . 
4.4.1  Semimartingales 
.  .  .  .  .  . 
4.4.2  Simple predictable integrands 
4.4.3  Adapted caglad integrands  .  . 
4.4.4  Properties of stochastic integrals  . 

vii 

127 
130 
132 
132 
132 
134 
135 
137 
139 
141 
142 
145 
146 
149 
151 
153 
154 
157 
158 
161 
165 
165 
168 
169 
173 
17 5 
17 6 
179 
182 
186 
189 
191 
193 
201 

205 
205 
206 
208 
216 
217 
221 
223 
224 

viii 

Contents 

4.6 

4.5  Quadratic variation and covariation . 
4.5.1  Definition  .  .  .  .  .  .  .  .  .  . 
4.5.2  Properties  .  .  .  .  .  .  .  .  .  . 
4.5.3  Stochastic integrals and covariation processes  . 
Ito's formula .  .  .  .  .  .  .  .  .  .  . 
4.6.1  One-dimensional case 
.  .  . 
4.6.2  Multi-dimensional case .  .  . 
4.6.3  Fisk-Stratonovich's integral 
.  . 
4.7.1  Brownian motion input  .  .  . 

4.7  Stochastic differential equations 

4.7.1.1  Existence and uniqueness of a solution 
4.7.1.2  Properties of diffusion processes 
4.7.1.3  Moments and other properties of 

diffusion processes 

4.7.2  Semimartingale input  . 
4.7.3  Numerical Solutions 

.  .  .  .  . 
4.7.3.1  Definitions  .  .  .  .  . 
4.7.3.2  Euler and Milstein numerical solutions 

4.8  Problems 

.  .  . 

.  228 
228 
229 
234 
237 
238 
247 
249 
253 
256 
258 
262 

267 
271 
275 
276 
277 
284 

5  Monte Carlo Simulation 
5.1 
Introduction  .  .  .  .  . 
5.2  Random variables  .  . 

5.2.1  Gaussian variables 
5.2.2  Non-Gaussian variables 

5.3  Stochastic processes and random fields  . 

5.3.1  Stationary Gaussian processes and fields. 

5.3.1.1 
5.3.1.2  Spectral representation. Random fields  . 
5.3.1.3  Sampling theorem.  Stochastic processes 
5.3.1.4  Sampling theorem. Random fields 

287 
287 
288 
288 
289 
293 
293 
Spectral representation. Stochastic processes  .  293 
299 
304 
309 
310 
310 
312 
315 
316 
316 
320 
325 
329 
330 
334 
334 
337 

5.3.2  Non-stationary Gaussian processes and fields  . 
5.3.2.1  Linear differential equations.  .  .  .  . 
5.3.2.2  Fourier series. Stochastic processes  . 
5.3.2.3  Fourier series. Random fields 

5.3.3  Non-Gaussian processes and fields  .  .  .  . 
. 

5.3.3.1  Memoryless transformations 
5.3.3.2  Transformations with memory 
5.3.3.3  Point and related processes 

5.4 

Improved Monte Carlo simulation 
5.4.1  Time change 
5.4.2  Measure change 

.  .  .  .  .  .  .  .  .  .  .  . 
.  .  .  .  .  .  .  .  .  . 
5.4.2.1  Time invariant problems  . 
5.4.2.2  Time variant problems  .  . 

Contents 

5.5  Problems 

IX 

341 

6  Deterministic Systems and Input 

6.2.3  Mixed boundary conditions 

6.1 
Introduction  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
6.2  Random walk method  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
6.2.1  Dirichlet boundary conditions (q  =  0)  . 

6.2.1.1  Local solution  .  .  .  .  . 
6.2.1.2  Monte Carlo algorithm 
6.2.1.3  The Laplace equation 
. 
6.2.1.4  The Poisson equation 
. 
6.2.1.5  Heat and transport equations 
6.2.2  Dirichlet boundary conditions (q  ::/=  0)  . 
6.2.2.1  The Feynman-Kac functional 
6.2.2.2  The inhomogeneous Schrodinger equation 
6.2.2.3  The homogeneous Schrodinger equation 

343 
343 
345 
346 
346 
353 
355 
359 
361 
364 
364 
367 
370 
.  .  .  .  .  .  .  .  .  .  .  .  . 
371 
6.2.3.1  Brownian motion reflected at zero.  .  .  .  . 
372 
6.2.3.2  Brownian motion reflected at two thresholds 
383 
6.2.3.3  Brownian motion in the first orthant of IR2  . . .  387 
6.2.3.4  General case 
.  390 
394 
395 
396 
399 
402 
403 
.  406 
407 
413 
416 
418 
421 
425 

6.3.1  The Green function  .. 
6.3.2  Mean value property  . 
6.3.3  Dirichlet boundary conditions 
6.3.4  Mixed boundary conditions 
6.4  Boundary walk method  .  .  .  .  .  . 
6.5  Algebraic equations  .  .  .  .  .  .  .  . 
6.5 .1 
Inhomogeneous equations 
6.5.2  Homogeneous equations  . 
Integral equations  .  .  .  .  .  .  .  .  . 
6.6.1 
Inhomogeneous equations 
6.6.2  Homogeneous equations 

6.3  Sphere walk method 

.  .  .  . 

6. 7  Problems 

.  .  .  .  .  .  .  .  .  .  .  .  . 

6.6 

7  Deterministic Systems and Stochastic Input 

7.1 
7.2  Linear systems 

Introduction  .  .  .  .  .  .  .  .  .  .  . 

.  .  .  .  .  .  .  .  .  .  .  .  .  . 
7 .2.1  Brownian motion input  .  .  .  .  .  . 

429 
429 
.  432 
.  432 
.  433 
.  437 
449 
452 
455 
State augmentation method  .  .  .  .  .  .  .  .  .  .  460 

7 .2.2.1  Direct method. Square integrable martingales 
7.2.2.2  Direct method. General martingales. 
7 .2.2.3 

7.2.1.1  Mean and correlation equations 
7.2.1.2  Linear random vibration  .  .  .  . 
7 .2.2  Semimartingale input  .  .  .  .  .  .  .  .  .  .  . 

x 

Contents 

7.4  Applications  .  . 
7.4.1  Models 

7.3 .2.1  Direct method.  Square integrable martingales 
7 .3.2.2  Direct method. General martingales . 
7.3.2.3  State augmentation method 

473 
7.3  Nonlinear systems .  .  .  .  .  .  .  .  .  .  . 
475 
7.3.1  Brownian motion input  .  .  .  . 
475 
7.3.1.1  Moment equations  . 
7.3.1.2  Differential equation for characteristic function  478 
.  481 
7.3.1.3  Fokker-Planck-Kolmogorovequations 
.  492 
7.3.1.4  Exact solutions.  .  .  .  .  .  .  .  . 
7.3.1.5  Nonlinear random vibration  .  .  .  .  .  . 
.  494 
7.3 .2  Semimartingale input  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
508 
508 
509 
512 
513 
513 
514 
515 
.  518 
.  522 
.  523 
.  527 
534 
539 
539 
541 
543 
546 

7 .4.2  Materials science  .  .  .  .  . 
7 .4.3  Reliability analysis  .  .  .  .  . 
7.4.3.1  Crossing theory 
. 
7.4.3.2  First passage time 
7.4.4  Finance  .......... . 
.  .  .  .  .  .  .  .  . 
7 .4.5  Estimation 

7.4.5.1  Time invariant problems  . 
7.4.5.2  Time dependent problems. Discrete time 
7 .4.5.3  Time dependent problems. Continuous time 

7.4.1.1  Earth climate .  .  .  . 
7.4.1.2  Non-Gaussian input 

7.5  Problems 

.  .  . 

8  Stochastic Systems and Deterministic Input 

8.3 .1 

Introduction  ..... 

8.1 
8.2  Local solutions 
.  .  .  .  .  .  .  .  .  . 
8.3  Algebraic equations  .  .  .  .  .  .  .  . 
Inhomogeneous equations 
8.3.1.1  Monte Carlo simulation method . 
8.3.1.2  Taylor series method .. . 
8.3.1.3  Perturbation method  .. . 
8.3.1.4  Neumann series method  . 
8.3.1.5  Decomposition method 
. 
8.3.1.6  Equivalent linearization method . 
8.3.1.7 
Iteration method  ........ . 
8.3.2  Homogeneous equations  .  .  .  .  .  .  .  .  .  . 

8.3.2.1  Deterministic eigenvalue problem . 
8.3.2.2  Exact expressions and bounds  . 
8.3.2.3  Taylor series method . 
8.3.2.4  Perturbation method  . 
8.3.2.5 
Iteration method  .  .  . 

549 
549 
550 
551 
552 
552 
554 
558 
561 
563 
564 
565 
566 
567 
569 
570 
572 
574 

Contents 

8.4 

8.3.2.6  Level crossing for stochastic processes 

Differential and integral equations 
8.4.1 

.  .  .  .  .  .  .  .  . 
Inhomogeneous equations  ........ . 
8.4.1.1  Monte Carlo simulation method . 
8.4.1.2 
Taylor series method .  .  . 
8.4.1.3 
Perturbation method  .  .  . 
8.4.1.4  Neumann series method  . 
8.4.1.5  Other methods  .  .  .  .  .  . 
8.4.2  Homogeneous equations  .  .  .  .  .  . 

8.4.2.1  Deterministic eigenvalue problem . 
8.4.2.2  Exact expressions and bounds  . 
8.4.2.3 
8.4.2.4 

Perturbation method  . 
Iteration method 

8.5  Effective material properties 

8.5.1  Conductivity 

.  .  .  .  .  . 
.  .  .  .  .  .  .  .  .  . 
8.5.1.1  Homogeneous media 
8.5.1.2  Heterogeneous media 
8.5.1.3  Effective conductivity 
.  .  .  .  .  .  .  .  .  .  .  . 

8.5.2  Elasticity 

8.5.2.1  Displacement controlled experiment. 
Voigt's average.  .  .  .  .  .  .  .  .  .  .  . 

8.5.2.2  Stress controlled experiment. Reuss's average 
8.5.2.3 
. 
8.5.2.4  Analytically based approximations 

Physically based approximations 

8.6  Evolution and pattern formation 

8.6.1  Elasticity 
.  .  .  .  .  .  .  .  .  .  . 
8.6.2  Crystal plasticity  .  .  .  .  .  .  . 
Planar single crystal 

8.6.2.1 
8.6.2.2  Polycrystals 

8.7  Stochastic stability 
.  .  .  . 
8.8  Localization phenomenon . 
8.8.1  Soilliquefaction 
. 
8.8.2  Mode localization. 
.  .  .  .  .  .  .  .  . 

8.9  Problems 

9  Stochastic Systems and Input 

Introduction  .  .  .  .  .  . 

9.1 
9.2  Methods of analysis  .  .  .  . 
9.2.1  Local solutions  .  . 
9.2.2  Monte Carlo simulation 
9.2.3 
9.2.4 
9.2.5 
9.2.6 

Conditional analysis 
State augmentation  .  .  . 
Liouville equation 
.  .  . 
Taylor, perturbation, and Neumann series methods 

xi 

575 
582 
583 
584 
584 
587 
591 
598 
599 
600 
602 
603 
604 
605 
610 
610 
611 
613 
617 

619 
622 
624 
629 
633 
633 
645 
645 
652 
655 
663 
663 
666 
670 

673 
673 
674 
676 
677 
678 
682 
687 
.  690 

xii 

Contents 

9.4  Physics 

9.3.4.1  Classical methods 
9.3.4.2  Polynomial chaos 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  . 
9.4.1  Boltzmann transport equation 
9.4.2 
Ising model  .  .  .  .  .  .  .  .  .  . 
9.4.3  Noise induced transitions  .  .  . 

9.2.7  Galerkin method 
.  .  .  . 
9.2.8  Finite difference method 
9.3  Mechanics  .  .  .  .  .  .  .  .  .  .  .  . 
9.3.1  Variational principles  .  . 
9.3.2  Deterministic problems  . 
.  . 
9.3.3  Stochastic problems 
9.3.4  Methods of analysis 
.  . 

.  694 
.  700 
.  701 
.  701 
.  703 
.  704 
.  706 
.  707 
.  709 
.  714 
.  714 
.  715 
.  720 
9.5  Environment and ecology  ...................... 725 
9.5.1  Rainfallrunoffmodel .................... 726 
9.5.2  Water quality in streams  .................. 729 
.  732 
9.5.3  Subsurface flow and transport 
.  736 
.  741 
.  741 
.  743 
.  745 
.  745 
.  748 
.  754 

9.6  Waves in random media . 
9.7  Seismology  .  .  .  .  .  .  .  .  .  .  . 
9.7.1  Physical model  .  .  .  .  . 
9.7.2  Cellular automata model 
9.8  Model selection  .  .  .  .  .  .  .  .  . 
9.8.1  Partially known input  .  . 
9.8.2  Partially known system and input 
.  .  .  .  .  .  .  .  .  .  .  .  .  .  .  .  . 

9.9  Problems 

Bibliography 

Index 

757 

771 

Stochastic Calculus 

Applications in Science 

and Engineering 

Chapter 1 

Introduction 

Algebraic, differential, and integral equations are used in the applied sciences, en-
gineering, economics, and the social sciences to characterize the current state of a 
physical, economic, or social system and forecast its evolution in time.  Generally, 
the coefficients of and/or the input to these equations are not precisely known be-
cause of insufficient information, limited understanding of some underlying phe-
nomena,  and inherent randonmess.  For example,  the orientation of the  atomic 
lattice in the grains of a polycrystal varies randomly from grain to grain, the spa-
tial distribution of a phase of a composite material is  not known precisely for a 
particular specimen,  bone properties needed to  develop reliable artificial joints 
vary significantly with individual and age, forces acting on a plane from takeoff to 
landing depend in a complex manner on the environmental conditions and flight 
pattern, and stock prices and their evolution in time depend on a large number of 
factors that cannot be described by deterministic models.  Problems that can be 
defined by algebraic, differential, and integral equations with random coefficients 
and/or input are referred to as stochastic problems. 

The main objective of this book is the solution of stochastic problems, that 
is,  the determination of the probability law,  moments, and/or other probabilistic 
properties of the state of a physical, economic, or social system. It is assumed that 
the operators and inputs defining a  stochastic problem are  specified.  We  do not 
discuss the mathematical formulation of a stochastic problem, that is, the selection 
of the functional form of the equation and of the probability laws of its random 
coefficients and input for a particular stochastic problem. 

The book is addressed to researchers and graduate students.  It is intended 
to serve as a bridge between heuristic arguments used at times in the applied sci-
ences and the very rich mathematical literature that is largely inaccessible to many 
applied scientists. Mathematicians will find interesting unresolved technical prob-
lems currently solved by heuristic assumptions. 

1 

2 

Organization 

Chapter 1.  Introduction 

The book is largely self-contained and has two parts. The first part includes 
Chapters 2-5,  and develops the probabilistic tools needed for the analysis of the 
stochastic problems considered in the book.  Essentials of probability theory are 
reviewed in Chapter 2.  An extensive review of stochastic processes, elements of 
stochastic integrals,  Ito's formula,  and a primer on stochastic differential equa-
tions and their numerical solution is presented in Chapters 3 and 4.  Numerous ref-
erences are provided that contain details and material not included in Chapters 2, 
3,  and 4.  Methods of Monte Carlo  simulation for  random variables,  stochastic 
processes, and random fields  are discussed in Chapter 5.  These methods provide 
useful illustrations for some of the theoretical concepts in Chapters 2-4 and are 
essential for the solution of many of the stochastic problems in this book. 

The second part of the book, Chapters 6-9,  develops methods for solving 
stochastic problems.  In this book stochastic problems are characterized by type 

Table 1.1: Stochastic problems 

INPUT 

Deterministic  Chapter6 
Chapter7 
Stochastic 

rather than by the particular field  of application.  Table  1 shows the  four types 
of problems considered in the book.  Chapter 6 is  concerned with deterministic 
problems, that is, problems in which both the governing differential equations are 
deterministic,  but  whose  solution utilizes concepts  of the  theory  of probability 
and stochastic  processes.  Such problems  arise  in physics,  mechanics,  material 
science, heat conduction, and many other fields.  For example, consider a Laplace 
equation "£f=1 a2u (x) 1 axf =  0 with Dirichlet boundary conditions defined on an 
open bounded subset D  of Rd . The solution of this equation at an arbitrary point 
x  E  Dis equal to the expectation of u(Y), where Y denotes the exit point from D 
of an Rd-valued Brownian motion starting at x.  Numerical algorithms based on 
this approach are simpler and more efficient, though less general, than current fi-
nite element and finite difference based algorithms. Chapter 7 discusses problems 
in which the equations describing a system have deterministic coefficients and the 
input to these equations is  stochastic.  Such problems arise in the description of 
various types  of physical,  economic,  and ecological systems.  Chapter 8 covers 
problems defined by equations with random coefficients and deterministic input. 
Examples include the derivation of macroscopic properties of a material from the 
attributes of its constituents and phenomena, such as localization and pattern for-
mation, relevant in physics and mechanics. Chapter 9 is concerned with problems 
characterized by equations with random coefficients and inputs.  An example is 

Chapter 1. 

Introduction 

3 

the  system describing the propagation of pollutants through a soil deposit with 
uncertain properties for which no realistic deterministic description is possible. 

We now briefly describe the presentation of the material. Essential facts are 
in boxes throughout the book.  The book contains numerous examples that have 
two purposes:  to state consequences of the essential facts and to illustrate the use 
of the stated facts in the solution of stochastic problems.  The statements of the 
facts and examples are followed by proofs or notes printed in smaller characters. 
Complete proofs are given if they are not very technical.  The notes include the 
idea and/or the essential steps of technical proofs and references where complete 
proofs can be found. 

The advanced topics on probability theory and stochastic processes in the 
first part of the book are essential for Chapters 6 and 7. Many of the developments 
in  Chapters  8  and  9  are  largely based on the  second  moment calculus.  How-
ever, extensions of the methods in Chapters 6 and 7 to the problems considered in 
Chapters 8 and 9 require most of the advanced topics in Chapters 2-4. 

Classroom use 

The book can be used as a text for four different one-semester courses or 
one two-semester course.  The four one-semester courses can  differ depending 
on the applications they emphasize.  The first,  second, third,  and fourth courses 
emphasize the applications in Chapter 6, 7, 8, and 9, respectively, and require the 
following background. 

•  The first course:  properties of the conditional expectation (Chapter 2),  stop-
ping times and martingales (Chapter 3), the Ito calculus and diffusion processes 
(Chapter 4), and Monte Carlo techniques (Chapter 5). 

•  The  second  course:  facts  on stochastic  processes  (Chapter 3),  the  stochas-
tic  integral,  the Ito  calculus,  and the  theory of stochastic differential equations 
(Chapter 4), and Monte Carlo techniques (Chapter 5). 

•  The third course:  a review of probabilistic concepts (Chapter 2),  second mo-
ment calculus for stochastic processes (Chapter 3), and Monte Carlo techniques 
(Chapter 5). 

•  The fourth  course:  essential probability concepts (Chapter 2),  properties of 
Brownian motion and second moment calculus for  stochastic processes  (Chap-
ter 3), use of Ito  's formula (Chapter 4), and Monte Carlo simulation techniques 
(Chapter 5). 

Owing to  time  limitations,  the  one-semester courses  need  to  be focused 
on applications.  The presentation of the book, summarizing facts on probability 
theory and stochastic processes that are essential for calculations and illustrating 
these facts by numerous examples, facilitates the course development. 

4 

Chapter 1. 

Introduction 

A  two-semester course can include most of the topics  discussed  in  this 
book. A good part of the first semester needs to be spent on a review of the topics 
in Chapters 2-4. Depending on students' interest and background, the lectures can 
focus  on understanding and use of the essential facts  given in these chapters or 
they may incorporate proofs of some of these facts based on the material and ref-
erences in the book.  The Monte Carlo simulation techniques in Chapter 5 can be 
used during lectures on Chapters 2-4 to illustrate various probabilistic concepts. 
Most students in my classes on stochastic problems are in favor of this approach, 
which facilitates the understanding of some technical concepts of probability the-
ory.  This approach also contributes to  the development of computational skills 
needed for solving realistic stochastic problems that,  generally, do not have ana-
lytical solutions.  The remainder of the  first  semester can be used to discuss the 
solution of problems defined by deterministic equations and inputs (Chapter 6). 
The second semester of the course can include analysis of the stochastic problems 
discussed in Chapters 7-9 and/or other problems that are relevant to the instruc-
tor's  field.  The addition of field  specific  applications is  strongly recommended 
and is  consistent with the goal of this book:  to use a unified framework for the 
solution of stochastic problems arising in applications. 

Acknowledgements 

This book could not have been completed without the contributions of many 
individuals. In particular, I wish to express my deepest appreciation to Professors 
S.  I. Resnick and G.  Samorodnitsky of Cornell University for their technical ad-
vice and comments on various topics in the book, Dr.  E. Simiu of National Insti-
tute of Standards and Technology for reviewing the entire manuscript, Professor 
S.  T.  Ariaratnam of the University of Waterloo,  Canada, for numerous stimulat-
ing discussions,  as  well  as  Professors  P.  R.  Dawson,  J.  Jenkins,  S.  Mukherjee, 
and Dr.  C.  Myers of Cornell University and Professor 0. Ditlevsen of Denmark 
Technical University, Lyngby, for their useful comments. I also wish to thank my 
doctoral students S.  Arwade,  E.  Mostafa,  and C.  Roth for  their many contribu-
tions,  and Mr.  C.  Willkens  for his enthusiastic  and professional support of the 
computer hardware and software used in this project. Finally, I am grateful to my 
wife Betsy for understanding, encouragement, and support.  During this project, 
she became an accomplished sculptor and pilot. 

My research on stochastic problems, some of which is incorporated in this 
book, has been supported by the National Science Foundation, National Institute 
of Standards and Technology, Electric Power Research Institute,  Jet Propulsion 
Laboratory, Air Force Office of Scientific Research,  Federal Aviation Adminis-
tration,  AON Financial Products, and other institutions.  I am indebted to these 
organizations and their continued support. 

Chapter 2 

Probability Theory 

2.1 

Introduction 

Essential concepts  of probability theory needed in  this  text  are  reviewed 
and  are  illustrated  by  examples.  The  review  includes  the  concepts  of events, 
sample  space,  a-field,  measure,  probability measure,  probability  space,  condi-
tional probability, independence, random variable and vector, integral of random 
variables,  expectation, distribution,  density,  and characteristic functions,  second 
moment properties,  convergence of sequences of random variables,  conditional 
expectation, and martingales.  The readers familiar with these concepts can skip 
this chapter entirely.  However, some of those readers may benefit from using this 
chapter as a summary of facts and examples needed in the rest of the book. 

2.2  Probability space 

The three components of probability space, the sample space n, the a-field 

:F, and the probability measure P, are defined and illustrated. 

2.2.1  Sample space 

Consider an experiment and let n be the set of outcomes of this experiment, 
called the sample space.  For example, n =  {1, 2, 3, 4, 5, 6}  for the experiment 
of rolling a die and n =  [a, b]  c  [0, oo), 0  <  a  <  b  <  oo, for the experiment 
consisting of strength tests of nominally identical steel specimens.  The first  and 
second sample spaces have a finite  and an uncountable number of elements, re-
spectively.  If n has a finite,  countable, or uncountable number of elements, it is 
referred to as a finite, countable, or uncountable sample space, respectively. The 
elements of n are denoted by (J). 

5 

6 

Chapter 2.  Probability Theory 

Example 2.1:  Consider the experiment of rolling a die and two games associated 
with this experiment. In the first game, one loses $10 if w ::::  3 and wins $10 if w > 
3.  In the second game, one loses $10 if w  ::::  3 and wins $5, $10, or $15 if w  =  4, 
5,  or 6.  The relevant information for the first  and second games is given by the 
collections of subsets A1  = {{1, 2, 3}, {4, 5, 6}} and Az = {{1, 2, 3}, {4}, {5}, {6}} 
of Q,  respectively.  Playing these  games does  not  require knowing in  the  finest 
detail the outcome of each roll of the die.  Coarser information suffices.  To play 
the first game we need to know only if w  ::::  3 or w  >  3.  The second game requires 
a more refined description of the outcomes of the experiment because it has more 
options of interest.  ¢> 
Note: Similar considerations apply to the experiment of testing steel specimens for strength. 
Suppose that each steel specimen is  subjected to  the same force  of magnitude x  >  0 and 
the  objective is to  design  a safe  steel structure.  There are two relevant outcomes for this 
x}  and failure B  =  A c.  The precise value of the strength w of a 
"game", survival A =  { w 
particular specimen is not essential.  To assess the likelihood of survival of steel specimens 
subjected to action x  it is sufficient to know whether w  <  x  or w 

x.  A 

2.2.2  a-field 

Let F  be a collection of subsets of Q relevant to a particular experiment. It 
that F  has at least two pro_rerties:  (1) If A  E  F, then the 
seems natural to 
outcomes corresponding to the non-occurrence of$ should also be in F, that is, 
and (2) If A i  E  F, 
A  E  F  implies A c  E  F, so that F  is closed to 
i  E  I, that is, if the subsets Ai occur individually, then UiEJ Ai should also be in F 
for any subset J  of the index set I.  These heuristic considerations are consistent 
with the following properties defining F. 

A non-empty collection of subsets F of Q is called a a-field on Q if 

1.  0 E  F. 
2.  A  E  F  ===}AcE F. 
3.  Ai  E  F, 

i  E  I,  I=  a countable set  ===?- UiE/ Ai  E  F. 

(2.1) 

Note:  The first condition in the  definition of the a-field :F can be replaced with 0  E  :F 
because :F is closed to complements. The last conditions imply that countable intersections 
of events are events.  We have  UiE/ Ai  E  :F for Ai  E  :F (condition 3) so that (UiEI Ai)c  E 
:F (condition 2) and (UiE/ Ai)c = niE/ Af E  F  by De Morgan's formulas. 

If the last condition in the definition of a a-field F  is replaced with the requirement 
that F  is  closed  under  finite  union,  F  is  said to  be  a field.  Hence,  a  a-field is  a field. 
However, a field may not be a a-field.  There is no difference between a field and a a-field 
for finite sample spaces.  A 

The members ofF are called events, or F-measurable subsets of Q, or just 
measurable subsets of Q if there is no confusion regarding the reference a -field. 
The pair (Q, F) is said to be a measurable space. 

2.2.  Probability space 

7 

Example 2.2:  The collections Ai, i 
fields.  However, 

1, 2,  defined in Example 2.1  are not a-

:F1  =  {members of A1, 0, Q}  and 
:F2 = {members of A2. {4, 5, 6}, {1, 2, 3, 5, 6}, {1, 2, 3, 4, 6}, {1, 2, 3, 4, 5}, 0, Q} 
are a-fields. They are the smallest a-fields including Ai. ¢ 
Note: A 1 is not closed to union while  A2 is not closed to both union and complements so 
that neither is au -field. 

Let A be a collection of subsets of Q and define 

a(A) = n Q, 

Q2A 

(2.2) 

where g are a-fields on n.  Then a(A) is a unique a-field, called the a-field 
generated by A. There is no a-field smaller than a(A) that includes A. 

•  The Borel a-field is generated by the collection of open sets of a topological 
space. The members of this a -field are called Borel sets. 

•  The Borel a-fields on JRd, d  >  1, and lR are generated by the intervals in these 
spaces and are denoted by B(JRd)  =Ed and B = .61 = B(JR),  respectively. The 
Borel a-fields on the intervals [a, b], [a, b), (a, b], and (a, b) of the real line are 
denoted by B([a, b]), B([a, b)), B((a, b]), and B((a, b)), respectively. 

Note:  The Borel  u-field constitutes  a  special case of u(A) in Eq.  2.2 that is generated 
by the collection of open sets  D  of a space  X.  This  collection is a topology  on  X  if it 
(1)  contains  the empty set and  the entire space,  (2)  is closed to finite  intersections,  and 
(3) is closed to uncountable unions.  There are notable similarities between a topology D 
and  a  u-field :F defined on a  space  X.  Both D  and :F include the entire space  and  the 
empty set and are closed to countable unions and finite intersections. However, D is closed 
to uncountable unions while :F is closed under complements and countable intersections. 
If X= lR,  B can be generated by any of the intervals (a, b), (a, b], [a, b), or [a, b] 

([151], Section 1.7, p.  17), that is, 

B = u((a, b), -oo:::; a:::; b:::;  +oo) = u([a, b), -oo <a:::; b:::; +oo) 

= u([a, b], -oo <a:::; b  <  +oo) = u((-oo, x], x  E  JR)  = u(open subsets oflR). 

The  Borel  u-field  Bd,  d  >  1,  can  be  generated,  for  example,  by  the  open  intervals 
xf=l (ai, bi) of JRd. 
Example 2.3:  Let  A  be  a  subset  of Q.  The a-field generated by  A  is  :F  = 
{0, A, Ac, Q}.  The a-fields :Fi  in Example 2.2 coincide with the a-fields gen-
erated by the collections of events Ai. ¢ 

8 

Chapter 2.  Probability Theory 

Example 2.4:  Let Q  =  lR  and A be the collection of finite unions of intervals of 
the form ( -oo, a], (b, c], and (d, oo). This collection is a field but is not au-field 
on the sample space Q. <> 
Proof:  The empty set is  a member of A  because the interval  (b, c]  is in A  and  (b, b]  = 
0.  The complements,  (a, oo),  (-oo, b] U (c, oo),  and  (-oo, d], of (-oo, a],  (b, c],  and 
(d, oo),  respectively,  are  in  A.  The  collection  A  is  also  closed  under  finite  unions  by 
definition.  Hence, A is a field.  However, A is not closed under countable intersections so 
that it is not a a-field.  For example,  the intersection nn(b- ljn, c]  = [b, c]  is not in A 
although the intervals (b- ljn, c] are in A  for each n.  • 

Example 2.5:  The intervals  (a, b],  [a, b), and  [a, b], a  <  b,  are Borel sets  al-
though they  are  not open intervals,  that is,  they  are  not members of the  usual 
topology V  on the real line. Singletons, that is, isolated points of the real line, are 
also Borel sets. <> 
Proof:  The intervals (a, b + 1/n), (a -ljn, b), and (a- 1jn, b + 1/m) are open intervals 
that are in B for each n  =  1, 2, ... , so that nn,m;::l (a- 1/n, b + 1/m)  =  [a, b] is in B. 
Similar calculations show that  [a, b),  and  (a, b]  are Borel sets.  That singletons are Borel 
sets follows from the equality {a}  = nn,m:::I (a-1jn, a+ 1/m) since (a-1jn, a+ 1/m)  E 
B holds for each n, m, and a  E lit • 

Example 2.6:  Let :F beau-field on a sample space Q. A member A of this field 
A  implies that either B  = 0  orB = A. 
is called an atom if A  ::j:.  0  and if B 
Hence, atoms are the finest members of a field.  For example, the atoms of the u-
fields  associated with the games of Example 2.1  are { 1, 2, 3}, { 4, 5, 6}  E  :F 1 and 
{1, 2, 3}, {4}, {5}, {6}  E  :Fz. <> 

2.2.3  Probability measure 

Consider a measurable space ( Q, :F).  We define two real-valued functions 
on :F, a measure f.J,  and a probability measure P, and give some of their properties. 

A set function f.,/,  :  :F 
that is, 

[0, oo] is said to be a measure if it is countably additive, 

00 

=  2:f.,l,(Ai) 

i=l 

for  Ai  E  :F,  Ai n Aj =  0,  i  ::j:.  j. 

(2.3) 

The triple ( Q , :F, f.J,)  is called a measure space. 

We now give four examples of measures. 

1. The Lebesgue measure, denoted by A. d and defined on (JRd, Ed), is 

Ad([at, bi] X··· X  [ad, ba]) = n (bi- ai), 

d 

i=l 

2.2.  Probability space 

9 

that is, the volume of the interval [a1, bl] x  ... x  [aa, ba]. 

2. The counting measure is used later in the book in conjunction with the Poisson 
process.  Suppose that :F  is  the  power set of the  sample  space  Q,  that is,  the 
collection of all subsets of Q.  The counting measure of A  E  :F is the cardinal of 
A if A is finite and infinity otherwise. 

3. The a-finite measure has  the  property that for  every  A  E  :F  there  exists  a 
sequence of disjoint events  Ai, i  =  1, 2, ... , such that J.t(Ai)  <  oo for every i, 
Q  = UiAi, and J.t(A)  = 
J.t(A n Ai). For example, the Lebesgue measure A 
on lR is a-finite because A(A) =  LieZ A(A n [i, i + 1)), where A  E  !3, Z denotes 
the set of integers, and A =  A 1 is the Lebesgue measure on the real line. 

4.  The finite  measure is  a measure  with the property J.t(Q)  <  oo.  The scaled 
version of this measure, J.t(A) 1 J.t(Q), takes values in [0,  1]. 

A set function P : :F--+  [0, 1] with the properties 

1.  P(Q) =  1, 

2. 

00 

Ai)  =  L P(Ai),  Ai  E  :F,  Ai n A1 =  0,  i  -=1=  j, 

(2.4) 

i=l 

is  said to be a probability measure or a probability.  The triple  (Q, :F,  P) is 
called a probability space. 

Note:  A probability space can be obtained from a measure space  (Q, F, J.l)  with a finite 
measure J.l  by setting  PO  = J.l01 J.l(Q).  A  set N  in :F with probability zero is called a 
null set. A property that is true on Q \  N  is said to hold almost everywhere (a.e.), almost 
surely (a.s.), for almost every w, or with probability one (w.p.1).  Because of the second 
condition in Eq. 2.4, we say that the probability measure is countably additive. 

The definition of P  is  consistent  with  our intuition.  Let A  and  B  be two  events 
associated with an experiment defining Q  and F. Suppose that the experiment is performed 
n times and denote by n A and n B the number of outcomes in which A and B  are observed, 
respectively.  For example, nA  and nB  may denote the number of outcomes {w  :::  3}  and 
{ w  >  3}  when a die is rolled n times.  The probabilities of A  and B  are given by the limits 
as n  --+  oo of the relative frequencies of occurrence, n A In and n BIn, of the events A and 
B.  The relative frequencies  have the properties (1)  P(Q)  =  liilln--+oo(noln)  =  1 since 
no  =  n for each nand (2) if A  and Bare disjoint events,  P(A U B) = liilln--+oo((nA + 
nB)/n) = limn--+oo(nA/n) + limn--+oo(nB/n) =  P(A) + P(B), consistent with Eq. 2.4. 
We also note that Eqs. 2.3 and 2.4 are meaningful because F  is closed to countable unions. 
Also, A  E  :F implies that A c is in the domain of P  since F  is a CJ' -field.  & 

We assume throughout the book that all probability spaces are complete. A 
probability space  (Q, F, P) is  complete if for every  A  c  B  such that  B  E  :F 
and P(B) =  0 we have A  E  :F so that P(A) =  0 (Eq.  2.5).  The following result 
shows that this assumption is not restrictive. 

10 

Chapter 2.  Probability Theory 

For any probability space  (Q, F, P)  there  exists  a complete  space  (Q, F, P) 
such that F 

f: and P  =  P on F  ([40], Theorem 2.2.5, p.  29). 

The formulas in Eqs.  2.5-2.8 give properties of the probability measure  P 

that are useful for calculations. 

B,  A, BE F. 

P(A):::::  P(B), 
P(A) =  1- P(Ae),  A  E  F. 
P(A U B) =  P(A) + P(B) - P(A n B),  A, B  E  F. 

(2.5) 

Proof:  The first  relationship follows  since  B  =  A  U (B  \  A),  A  and  B  \  A  are  disjoint 
events,  B  \  A  =  B n A e,  and the probability measure is a countably additive positive set 
function. 
We have  1 = P(Q) = P(A U A e)  = P(A) + P(Ae) by Eq.  2.4.  This also shows 

that the probability of the impossible event is zero because P(0) =  1 - P(Q) =  0. 

The  last relationship  results  from  Eq.  2.4  and  the  observations  that  A  U B  is  the 
union  of the  disjoint  sets  {A  n  Be, A  n  B, A e n  B},  A  is  the  union  of the  disjoint  sets 
{An Be, An B}, and B is the union of the disjoint sets {Ae  n  B, An B} .• 

If A;, BE F  and A;, i  =  1, ... , n, partition Q, we have 

n 

P(B) =  L P(B n A;). 

i=l 

(2.6) 

Proof:  This equality follows  from Eq.  2.4  since  Q  = Ut=l A;, A;  E  F,  A; n A J  = 0, 
i  =f- j, and B  =  U; (B n A;) is a union of disjoint events.  • 

If A;  E  F, i  =  1, 2,  ... , then 

00 

A;)::::: L P(A;). 

i=l 

(2.7) 

Proof:  Since 

A;= A 1 u (A]'  n  A2) u (AI n  A2  n  A3)  U  · · · 
and the events AJ, AI n  A2, AI n  A2  n  A3, ... are disjoints, we have 

which gives  Eq.  2.7  by using  the  first  relation in Eq.  2.5.  For example,  P(Aj  n  A2)  :::; 
P(A2), PC AI n A2 n A3)  :::;  P(A3), and so on.  A set function P  satisfying Eq. 2.7 is said 
to be subadditive.  • 

2.2.  Probability space 

11 

The probability measure satisfies the inclusion-exclusion formula 
P (uj=1 A;)= L P(A;)- L L P(A; n  Aj) 

i-1 

n 

n 

i=l 
n 

i=2 j=l 

i-! j-1 

+ L L L P(A; n AJ  n Ak)- ... + (-l)n+I p  ( 

i=3  j=2k=! 

(2.8) 

where A;  E  F, i =  1, ... , n, are arbitrary. 

Proof:  This formula extends the last equation in Eq. 2.5  and results from a repeated appli-
cation of this equation.  For example, the probability of P(A1 U Az U A 3) is equal to the 
probability of the union of A 1 U A 2  and A 3 so that 

P((A 1 U A2) U A3) = P(A 1 U A 2) + P(A 3)- P((A 1 U A2) n A 3) 

= P(A 1 U A2) + P(A 3)- P((A 1 n A3) U (A 2 n A3)) 
= P(A 1) + P(Az)- P(At n Az) + P(A3) 
- P(A 1 n A3)- P(Az n A3)) + P(At n A 2 n A3), 

which is the inclusion-exclusion formula for n  =  3.  • 

Example 2. 7:  Let F;  be the failure event of component i of a series system with n 
components, that is, a system that fails if at least one of its components fails.  The 
system probability of failure is P f  =  P(Uj=1 F;). If the events F;  are disjoint, the 
failure probability is  Pf =  Lt=l P(F;).  Otherwise, Lt=l P(F;) gives an upper 
bound on P f. <> 

Example 2.8:  The probability of failure  P f  = P(Uj=1 F;)  of the  series  system 
in the previous example can be calculated exactly by the inclusion-exclusion for-
mula.  However, the use of this formula is prohibitive for large values of n or even 
impossible if the probability of the events F;1  n · · · n F;m  is not known for m  2::  2. 
The calculation of the bounds 

Pt::::  Pf,u  = L P(F;)- L. max  P(Fj n F;)  and 

n 

n 

i=1 

i=2 j=l, ... ,l-l 

Pf 0>  Pf,1  P(FI) 

( 0, P(F;)-

P(FJ n F;)) 

(2.9) 

on Pf is relatively simple since it involves only the probability of the events  F; 
and F;  n Fj, i  =1=  j. 

12 

Chapter 2.  Probability Theory 

If P(Fi) = p and P(Fi n Fj) = p 2, i  =/=  j, theupperandlowerboundson 

the probability of failure P f  of this system are 

Pf,u = n p- (n- 1) p 2 

and  Pf,l = p +I: max (o. p- (i- 1) p 2). 

n 

i=2 

These bounds are shown in Fig. 2.1  for p  =  0.1  as a function of the system size 
n.  The bounds are relatively wide and deteriorate as n increases. <> 

1.2 

Figure 2.1. Bounds on the probability of failure for a series system 

Proof: The equality P(Fi n Fj) = p 2, i  =j:.  j, is valid if Fi  and F1 are independent events, 
as we will see later in this section (Eq. 2.54). We have (Eq. 2.7) 

Pt = P(U/=1 Fi) = P(F1) + P(F[ n Fz) + P  ((F1 U Fz)c n F3) + · · · 

+ P  ((F1  U .. · U Fn-1)c n Fn) 

so that 

Pt =  P(F1) + L P(S1 n · · · n si-1  1 Fi) P(Fj), 

n 

n  2::  2, 

i=2 

where  Si  = F{.  The conditional probabilities  P(S1  n · · · n Si-1  I Fi)  are smaller and 
larger than  P(Sj  I Fi ),  j  = 1, ... , i  - 1,  and 1 -
P(Fj  I Fi), respectively ([53], 
pp. 236-237).  These inequalities give the bounds ofEq. 2.9.  • 

2.3  Construction of probability spaces 

The starting point in many applications involving probabilistic models is an 
experiment rather than a probability space.  We  need to construct a probability 
space based on the available information.  This section illustrates three construc-
tions of a probability space. 

2.3.  Construction of probability spaces 

13 

2.3.1  Countable sample space 

Let Q = { w1 , wz, ... } be a sample space and consider a collection of num-
Pi  =  1.  Take :F to be the power set of 

bers Pi  2:  0, i  =  1, 2, ... , such that 
n, that is, the collection of all subsets of n. 

The function P  : :F 

[0, 1] defined by 

P(A) = L Pi·  A  E  :F 

WiEA 

(2.10) 

is a probability measure on (Q, :F). 

Proof: The set function  Pis positive for any A  E :F,  P(Q) = 
and is countably additive since 

Pi  =  1 by definition, 

provided that A j• j  = 1, 2, ... , are mutually disjoint events ([151], p. 41).  • 

2.3.2  Product probability space 

Let p  >  0 be the probability that maximum yearly wind speed V  2:  0 at 
a site exceeds a value Vcr  deemed critical for a facility,  that is,  the probability of 
the event A  =  {V  >  Vcr}.  The associated sample space, a-field, and probability 
measure are  Q  = [0, oo), :F = {0, A, Ac, Q}, and P(A)  = p, respectively.  To 
evaluate the probability that this facility performs satisfactorily during its design 
life of n years we need to construct a new probability space for an "experiment" 
consisting of n  repetitions  of the maximum yearly wind speed.  This engineer-
ing application resembles the experiment of tossing a loaded coin n times ([151], 
p. 41). 

Consider two  probability spaces  (Qk. :Fk,  Pk),  k  =  1, 2,  describing  two 
experiments. These two experiments can be characterized jointly by the product 
probability space (Q, :F, P) with the following components. 

Product sample space: 

Product a-field: 

:F = :F1  x  :Fz = a(R),  where 

R  = {A1  x  Az : A1  e  :F1, Az e  :Fz} = measurable rectangles. 

(2.11) 

(2.12) 

(2.13) 

14 

Chapter 2.  Probability Theory 

Product probability measure, P  =  Pt  x  Pz, on the measurable space (Q, F): 
The probability P  is unique and has the property 

(2.14) 

Note: The product sample space Q contains the outcomes of both experiments generating 
the sample spaces r.lt  and r.lz.  Let 

be two collections of subsets of Q. These collections are a-fields on r.l,  are included in :F, 
and :F =  a(R) =  a(91, 9z) since every member of n is the intersection of sets from 9t 
and 9z. 

The  construction  of the  product probability measure  is  less  simple.  It can  be 
shown  that there  exists  a unique  probability  P  on  (Q, :F)  such  that it satisfies  Eq.  2.14 
([40], Theorem 3.3.5, p. 59) . .& 

Example 2.9:  Let Qk  =  {1, 2, 3, 4, 5, 6}, k  =  1, 2, be sample spaces associated 
with the experiment of rolling two dice.  The a-fields Fk  on these spaces consist 
of all  subsets of Qk.  The probability measures  on  Qk  are  Pk({i})  =  1/6, i  = 
1, ... , 6. 

The product sample space Q, the product a-field :F, and the product prob-

ability measure P  are 

Q  =  n1  x  Qz =  {c:v  =  (i, })} = 

(1, 1) 
(2, 1) 
(3,  1) 
(4, 1) 
(5,  1) 
(6,  1) 

(1, 2) 
(2, 2) 
(3, 2) 
(4, 2) 
(5, 2) 
(6, 2) 

(1, 6) 
(2, 6) 
(3, 6) 
(4, 6) 
(5, 6) 
(6, 6) 

all subsets of Q, and P({c:v})  =  1/36, respectively.<> 

Note:  The sample  space  Q  corresponds to the experiment of rolling two dice.  The prod-
uct  a-field consists  of all  subsets  of Q  since  the  members  of n are  (i, j), Uieh (i, j), 
U je[z (i, j), Uieh ,je/z (i,  j), where  It, lz 
{1, 2, 3, 4, 5, 6}.  The product  probability 
measure can be defined for each outcome w  =  (i, j) and is  P({w})  =  1/36 because the 
members  of Q  are  equally likely.  Also,  P({w}  =  (i, j)) is equal  to  P1 ({i}) Pz({j})  = 
(1/6) (1/6) . .& 

Example 2.10:  Consider the same experiment as in the previous example but as-
sume that the a-fields on QI = Qz = {1, 2, 3, 4, 5, 6} are 

:Ft  ={At= {1, 2},  A}, 0, QI}  and  :Fz  =  {Az  =  {1, 2, 3}, A2, 0, Qz}. 

The probabilities of At and Az are Pt (At)= 2/6 and Pz(Az) =  3/6. 

2.3.  Construction of probability spaces 

15 

The product probability space is  Q  =  {w  =  (i, j), i, j  =  1, ... , 6}.  The 

product a -field coincides with the collection of measurable sets 

{AI  X  A2, AI  X  A2_,  A!  X  A2, A!  X  A2_}, 

unions of the members of this collection, and sets in which at least one component 
is the empty set, for example, the set 0 x  A2.  The product probability measure is 
given by Eq. 2.14. o 
Note:  The product sample space n is  as in Example 2.9 but the product cr-field is much 
coarser than in this example because fewer events are relevant. The definition of the product 
probability measure is consistent with our intuition. For example, P(A I x A2)  =  6/36 and 
coincides with the product of PI (AI) and P2(A2) . .& 

The formulas ofEqs. 2.11-2.14 can be generalized to define a product prob-
ability space for three or more probability spaces. Consider the probability spaces 
(Qk. :h, Pk), k =  1, 2, ... , n. 

• If n is finite, the product probability space (Q, :F, P) is defined by 

Q  = QI  X··· X  Qn, 
:F =  FI X  • • •  X  Fn, 
P  =PI X··· X  Pn. 

(2.15) 

• If n is infinity, the definition of Eq. 2.15 applies with n replaced by oo. 

Note: The last equalities in Eq. 2.15 are commonly used notations. If the probability spaces 
(Ok, :Fk,  Pk)  are identical, the product sample space, cr-field, and probability are denoted 
by O'j, :Ff, and Pf for n  <  oo and Of, :Ff, and Pf for n = oo . .& 
Example 2.11:  A loaded coin with sides {1}  and {0}  and probabilities p  E  (0, 1) 
and q =  1 - p, respectively, is tossed n times.  The probability space for a single 
toss  is  Q  =  {0,  1},  :F  =  {0,  Q, {0}, {1}},  P({l})  =  p, and  P({O})  =  q.  The 
corresponding elements of the product probability space for n tosses are 

Qn  =  {w= (WI,  ... ,Wn)  :wi  =0orl}, 

:Fn  =  all subsets of nn' and 

pn(A) =  L P({w})  =  L pn"' qn-nw' 

A  E  :Fn' 

weA 

weA 

where nw  =  .L:7=I Wi  gives the number of 1 'sin w  =  (WI, ... , Wn).  0 
Note:  We have 

pn(On) =  L  pn"' qn-nw  =  L  pn'w qn'-n'w  (pl qo +PO qi) = ... = 1 

W!, •.. ,Wn 

lVJ, •.. ,Wnf 

since pi q0 + p0 qi = 1, where n' = n- 1 and n:V  = 
set function  pn is also positive and countably additive ([151], Section 2.3) . .& 

wi  so that pncnn) = 1.  The 

16 

Chapter 2.  Probability Theory 

2.3.3  Extension of probability measure 

Consider an experiment with a sample space Q.  Assume that a set function 
R defined on a collection C of subsets  of Q is available and that this function is 
real-valued, positive, countably additive, and R(Q) =  1.  For calculation purposes 
we need to extend R to F  =  a (C)  such that its extension is a probability measure 
on the measurable space (Q, F). The following theorem states conditions under 
which the extension of R to F  is  a probability measure.  For proof and additional 
information on this topic, see [151]  (Section 2.4). 

If (1) Cis a field on Q and (2) R is a real-valued, positive, and countably additive 
function defined on C such that R(Q) =  1, then there exists a unique probability 
P on F  =  a(C) such that P(A) =  R(A) for each A  E  C, that is, the restriction 
of P  to Cis equal toR ([66], Theorem 14, p. 94). 

Example 2.12:  Let  Q  =  lR  and  let C be  the  collection  of all  finite  unions  of 
intervals of the type  (a, b]  for a  <  b,  (-oo, a], (a, oo), and  (-oo, oo)  to  which 
we add the empty set.  Let F  :  lR  -+  [0,  1] be a continuous increasing function 
such that Iimx-+-oo F(x)  = 0 and limx-+oo F(x)  = 1.  DefineR  :  C  -+  [0,  1] 
by R((a, b])  =  F(b)- F(a),  R((-oo, a])  =  F(a),  R((a, oo))  =  1 - F(a), 
and R((oo, oo))  =  1.  This set function can be extended uniquely to a probability 
measure on (JR, B).  <> 
Note:  The  collection  of subsets  Cis a field  and a(C)  = B.  The  set function  R is  well 
defined  because,  for  example,  R((a, b]  U (b,  c])  =  R((a, c])  and  R(R)  =  1,  and  it is 
finitely additive.  Moreover,  R is countably additive ([66], Proposition 9, p.  90).  The above 
theorem implies the stated result.  A 

2.3.4  Conditional probability 

Let (Q, F, P) be a probability space and B  E  Fan event with P(B)  >  0. 
We define a new probability measure on (Q, F) under the assumption that B  has 
occurred. 
The probability of A conditional on B  is 

P(A  I B) =  P(A n B) 

P(B) 

for A, B  E  F  and P(B)  >  0. 

(2.16) 

Note:  The set function  P(·  I B) is a probability because it is defined on :F, takes positive 
values,  P(Q I B) = P(B)/ P(B) =  1, and is countably additive, that is, 

P(Uiel Ai I B) =  P((Uie/ Ai) n B)/ P(B) =  P(Uiel (Ai n B))/ P(B) 

= L P(Ai n B)/ P(B) = L P(Ai  1  B) 

iel 

iel 

for any countable set I  and disjoint events Ai, i  E  I. A 

2.3.  Construction of probability spaces 

17 

If B  has not occurred in an experiment, then Be has occurred.  The proba-
bility of A given that Be has been observed is given by Eq. 2.16 with Be in place 
of B provided that P(Be)  >  0.  Hence, the conditional probability of A can take 
the values P(A n B)/ P(B) or P(A n Be)/ P(Be) depending on whether B or Be 
has been observed.  In Example 2.86 we extend the definition of Eq. 2.16 to give 
the probability of A given the information content of a sub-a-field g of :F. 
Let Ai  E  :F,  i  = 1, ... , n,  be a partition of n such that P(Ai)  >  0,  and 
let B  E  :F be an arbitrary event.  The following two properties of the conditional 
probability are very useful for calculations. 

The law of total probability: 

n 

P(B) = L P(B n Ai) = L P(B  1 Ai) P(Ai), 

n 

i=1 

i=1 

(2.17) 

P(B) >  0. 

and 

The Bayes formula: 

P(Aj I B)= 

P(Aj) P(B I Aj) 

P(B) 

P(Aj) P(B I Aj) 

= L7=1 P(Ai) P(B I Ai)' 

(2.18) 
Proof:  The events  Ai n B,  i  =  1, ... , n, are  disjoint  so  that Eqs.  2.17  and 2.18  result 
from  Eq.  2.6  and the  definition  of the  conditional  probability  (Eq.  2.16).  To  apply  the 
Bayes formula,  the  probability  P(B) must be strictly positive.  The probabilities  P(Ai) 
and  P(A j  I  B)  in Eq.  2.18  can be interpreted  as  the  prior probability of Ai  and  the 
posterior probability of Aj given the occurrence  of B, respectively.  P(B  I Ai)  is the 
probability of B conditional on Ai. • 

Example 2.13:  Consider the experiment of rolling two dice.  The sample space, 
the a-field :F, and the probability measure are n = {w = (i, j) : i, j  = 1, ... , 6}, 
the collection of all parts  of n,  and  P(w)  =  1/36, respectively.  Consider the 
events  A1  =  (6, 2)  and  A2  = {(6, 2), (4, 4), (1, 6)}.  The probabilities of these 
events given that B = {w E  n : i + j  = 8}  has occurred are P(A 1  I B)  =  1/5 
and P(A2 I B) =  2/5. <> 
Proof:  The event  B  is  {(6, 2), (5, 3), (4, 4), (3, 5), (2, 6)}.  The probability of A1  condi-
tional on B is  P(A1  I B) = 1/5 since A1  is one of the five equally likely members of B. 
The same result can be obtained from Eq. 2.16 since  P(A1  n B)  = P(A 1)  = 1/36 and 
P(B) = 5/36. The conditional probability of A1 given Be is zero.  Hence, the probability 
of occurrence of A 1 is 1/5 and zero if B and Be has occurred, respectively.  The conditional 
probabilities of A2  under B  and Be  are  P(A2  I B)  =  (2/36)/(5/36)  =  2/5 and P(A2  I 
Be) =  (1/36)/(31/36)  =  1/31 since P(B) =  5/36 and P(Be) =  1- P(B) =  31/36. We 
will see in Example 2.86 that the probabilities P(A2  I  B), P(A2  1  Be), P(B), and  P(Be) 
are sufficient to specify the conditional probability  P(A2  I 9), where 9 = {0, Q, B, Be} 
is the a-field generated by B. • 

18 

Chapter 2.  Probability Theory 

Example 2.14:  Let X  be the unknown strength of a physical system, that is,  the 
maximum load that  the  system  can  sustain.  Suppose that  the  system  survives 
without any damage if subjected to a proof load test of intensity x pr·  Consider the 
events A = {X >  x}  and B = {X >  Xpr}  that the system strength exceeds x  and 
Xpr. respectively. The probability that the system can sustain a load x given that B 
has occurred, 

P8 (x) = P(X >  max{Xpr. x})j P(X >  Xpr), 

is larger than the system reliability  P(X  >  x) calculated when the information 
provided by the proof load test is not available or is ignored. 

Example 2.15:  A  system is subjected to two actions described by the events  B 1 
and B2,  where P(B1)  =  0.8 and P(B2)  =  0.2.  Let P(A I BI) =  0.9 and P(A  I 
B2)  =  0. 7 be the system reliability under action B 1 and B2,  respectively, where 
A is the event that the system survives. By the law of total probability (Eq. 2.17), 
the system reliability is  Ps  = P(A) = P(A  I B1)P(B1) + P(A  I B2)P(B2) so 
that Ps  =  (0.9)(0.8) + (0.7)(0.2) =  0.86. 

2.3.5  Sequence of sets 

Let Ai. i  = 1, 2, ... , be subsets of a set n.  The limit supremum and the 

limit infimum of this sequence are 

lim supAi= 
i--+00 

Ai = 

Bj = 

..j.., 

(2.19) 

(2.20) 

Note: The limits in Eqs. 2.19-2.20 are subsets of n. The sequence of events Bj = 
and C j  = 
C j  is an increasing sequence, that is, C j 
by B j  -)..  and C j  t, respectively . .A 

Ai 
j Ai are monotone,  B j  is a decreasing sequence, that is, B j  2  B j + 1o  whjle 
C j + 1o  for all j. These properties are denoted 

The limits in Eqs. 2.19 and 2.20 have some notable properties. 

=  {Ai i.o.}  =  \w: f= 1A;(w) = oo} 

i=1 

1--+00 

=  {w: wE Aij' j  =  1, 2, ... } 

(2.21) 

for some subsequence i j  depending on w, where i.o. means infinitely often. 

Proof: Recall that the function  1A  : n -+ {0,  1}, called the indicator function, is defined 
by 1A (w) = 1 for w  E  A and 1A (w) = 0 for w  ¢ A. 

2.3.  Construction of probability spaces 

19 

If wE  lim sup; A;,  then wE  Bj  = 

that w  E  A;1,  j  =  1, 2, ... , and 
{w: 

1A; (w)  = oo}.  Therefore, we have lim sup; A;  c  {w: 

Vj, so that there exists iJ  2:  j  such 
1A; (w)  2:  Lj 1A;J  (w)  =  oo  implying that w  E 

If wE  {w: 

wE  A;r  Hence,  wE  Uk-:::_jAk  for  all  j's so that wE  lim sup;  or {w: 
oo}  c  lim sup; A;  ([151], Lemma 1.3.1, p.  6).  • 

=  oo},  there exists iJ  -+  oo,  j  =  1, 2,  ... ,  such that 
= 

lA; (w)  = oo}. 

lim inf A;  =  {w : w  E  An for all n except for a finite number} 
i---+oo 

=  /w: f 1Af(w)  <  oo}  =  {w: wE A;, Vi  :::  jo(w)}. 

!=1 

(2.22) 

Proof:  If w  E  liminf; A;,  there exists  jo(w)  such that w  E  Cia  = 
that is,  w 
belongs to all sets A; fori  2:  jo(w), or w  does  not belong to the sets  AJ, ... , Aio(w)  so 

is finite. 

If w is such that 

1 1 A c ( w) is finite, then w does not belong to a finite number of 

subsets A;.  Hence, there erlsts 

such that w  E A;  fori  2:  jo or w  E 

• 

liminfA;  =  (limsupAf)c 

l 

i 

1imsupA;. 

i 

(2.23) 

Proof:  If w  E  lim inf; A i,  there  exists  jo  such  that  w  E  C Jo,  that  is,  w  E  A i  for 
i  2:  jo.  Hence,  w  E  A;  infinitely  often,  that  is,  w  E  lim sup; A;.  De Morgan's  law 

A;r = 

Af yields Eq.  2.23 .• 

If the  limits  in Eqs.  2.19  and 2.20 coincide,  the  sequence  A i  is  said  to  be a 
convergent sequence with the limit 

lim  A;  =liminfA;  =limsupA;. 
i---+oo 

i---+oo 

i---+oo 

(2.24) 

Example2.16:  Let  A;  =  {(X!,X2)  E 
:X!  E  [O,i),x2  E  [0,  1/i)},  i  = 
1, 2, ... , be a sequence of sets in IR2 .  The sequences of events B 1 =  U;-:::_1 A;  and 
CJ  =  n;-:::_JAi  have the  same limit  [0, oo)  x  {0}  as  j  -+  oo.  Hence,  {A;}  is  a 
convergent sequence and lim;___,. 00 A;  =  [0, oo)  x  {0}. <> 
Example 2.17:  Consider a monotone sequence of subsets  A;.  This sequence is 
A;  if A;  t  and 
convergent with lim;___,. 00 A;  = 
A;  ,!.,,  respectively. <> 

A;  and lim;___,. 00 A;  = 

20 

Chapter 2.  Probability Theory 

Proof:  We  need to  show  that lim sup A;  and lim inf A;  are  equal.  If A;  t, then  B j  = 
U;::;:jAi  =  U;::;:tA;  sothatlimsupA; =  U;::;:tA;. The sequence Cj =  ni::;:jAi inEq. 2.20 
is  Aj so that liminfA;  =  U;::;:tA;  =limA;.  Similar considerations give the limit of a 
decreasing sequence of subsets.  • 

2.3.6  Sequence of events 

Let  (0, :F, P) be a  probability space  and consider a  sequence of events 
A;  E  :F,  i  =  1, 2, ... , on this  space.  The following three statements relate to 
the continuity of the probability measure.  The last result in  this  section is  the 
Borel-Cantelli lemma, a useful tool for proving almost sure convergence. 
Continuity of probability measure. If A; t  A or A;  .,!.  A, then P(A;) t  P(A) 
or P(A;).,!.  P(A), respectively, where A= limi--+oo A;. 

Proof: If A; is an increasing sequence, then Dt =At and D;  =A;\ Ai-l· i  =  1, 2, ... , 
provide a partition of 

A; so that 

P(lim  A;)= P(A) =  P 

1--+oo 

oo 

D;) = L P(D;) = 

i=l 

= 

lim  P {U7_1 D;) = 
n--+00 

-

lim  P(An) 
n--+oo 

n 

lim  L P(D;) 

n--+oo 

i=l 

since  P  is a countably additive function.  By the first property in Eq.  2.5,  the  numerical 
sequence P(An) is increasing.  Similar consideration can be applied for the case A;  ,J...  If A; 
is a decreasing sequence such that 
A;)= 
P(0) = 0 .• 

A;  =  0, we have li!Ilj--+00  P(A;) = 

If a sequence of events A i  is convergent with limit A =  lim; A;, then 

lim  P(A;) = P( lim  A;) = P(A), 
i--+oo 

i--+oo 

(2.25) 

that is, for a convergent sequence of events, probability and limit operations 
can be interchanged. 
Proof: A direct consequence of Eq. 2.25 is that for any sequence of events A;  the equalities 

i--+oo 

P(limsupA;) =  .lim  P(Bj) =  .lim 
J--+00 
P(ljminfA;) =  .lim  P(Cj) =  ,lim 
j--+00 

J--+OO 

J --+00 

1--+00 

and 

hold because Bj  = 
respectively, lim sup A;  =  limB j, and lim inf A;  =  lim C j. 

and Cj  = 

are decreasing and increasing sequences, 

Since  A;  is  a  convergent  sequence  of events,  the  decreasing  and  increasing  se-
quences  Dj  =  SUPi::;:j  A;  and  Ej  =  inf;::;:j  A; respectively,  converge to A.  The inequali-
ties P(Ej) :s  P(A j) :s  P(Dj) hold for each j  because Ej  Aj  Dj· By the continuity 
of the probability measure,  P ( E j) and  P ( D j) converge to  P (A)  as  j  --+  oo  so that the 
limit of P(A j) is P(A) . • 

2.4.  Measurable functions 

Fatou's lemma. The 

measure satisfies the inequalities 

P(liminfA;) 

i 

limidfP(A;) 

i 

' 

limsupP(A;)  P(limsupA;) 

i 

i 

21 

(2.26) 

for any sequence of events A i. 

Proof:  Because lim sup;  A;  and liminf; A;  are  events as  countable unions  and intersec-
tions of events (Eqs.  2.19 and 2.20),  we can calculate  P(limsup; A;) and  P(liminf; A;). 
P(limsup; A;) follows from Eqs. 2.5 and 2.23.  Because 
The inequality P(liminf; A;) 
P(A;) is  a numerical  series,  it satisfies the inequality liminf; P(A;) 
lim sup; P(A;). 
The proof of the remaining inequalities is left to the reader. 

If the sequence  A;  is convergent, lim sup;  A;  = lim inf; A;  = lim; A;  so that the 
left and right terms of Eq. 2.26 coincide. This observation provides an alternative proof for 
Eq. 2.25 .• 

Borel-Cantelli Lemma. If L; P(A;)  <  oo, then 

P(limsupA;) = P(A; i.o.) = 0. 

i 

(2.27) 

Proof:  Because lim sup; A;  Bj and Bj = U;:::jAi  (Eq. 2.19), we have 

P(lim_supA;)  P 

I 

00 

L P(A;), 

i=j 

j  = 1, 2, ... , 

by the monotonicity and subadditivity of the probability measure. The extreme right term in 
these inequalities converges to zero as j  --+  oo because it is assumed that Li P(A;) <  oo. 
Hence, P(limsup; A;)= 0.  • 

2.4  Measurable functions 

Let (Q, :F)  and  (\11,  Q)  be two measurable spaces and consider a function 

h : Q --+  \II with domain Q and range \II. 

The function h is said to be measurable from (Q, :F) to (\II, Q)  if 

h-1(B) =  {w: h(w)  E  B} E  :F,  VB  E  Q. 

(2.28) 

Note:  It is common to indicate this property of h by the notation h  :  (Q, :F)  --+  (Ill, 9), 
h  E  :F/9, or even h  E  :F provided that there can be no confusion about the a-field 9.  If 
the a-fields :F and 9 are not in doubt, it is sufficient to say that his measurable.  & 

22 

2.4.1  Properties 

Chapter 2.  Probability Theory 

If h  : (Q, :F)  -+  (\11,  Q) is measurable and Pis a probability measure on (Q, :F), 
then Q : Q -+  [0,  1], defined by 

Q(B) =  P(h- 1(B)),  BE Q, 

(2.29) 

is a probability measure on (\11,  Q), called the probability induced by h or the 
distribution of h. 

Proof:  The function  Q has  the  properties  Q(\11)  =  1 by  definition  and  Q(Uie/ Bi)  = 
Lie/ Q(Bi) for  any  countable  set  I  and  disjoint events  Bi  E  9, since the  sets  h- 1(Bi) 
are disjoint events in F  and  P is a probability.  Hence,  the  set function  Q is a probability 
measure on (\11,  Q).  • 

If C is  a  collection  of subsets  of  \II,  then  h - 1 (a (C))  =  a (h - 1 (C)),  where 
h- 1(a(C))  and a(h- 1(C))  are the inverse image of a(C) and the a-field gen-
erated by h - 1 (C) in  Q, respectively ([151], Proposition 3.1.2, p. 73). 

Let C be  a collection of subsets  of \II  such that a(C)  =  Q.  The function h is 
measurable if and only if h - 1 (C)  s; :F ([151], Proposition 3.2.1, p. 76). 

If g  : IRd  -+ IRq  is a continuous function, then g is  Bd I Bq -measurable. 
Proof: Let vr denote the topology on lR'  generated by the open intervals of lR'.  Because 
g  is  a continuous  function,  we  have  g - 1 (D)  E  Vd  for  all  D  E  Vq .  This  function  is 
measurable since the Borel fields gi and Bq  are generated by the open sets in W and Rq, 
respectively.  • 

2.4.2  Definition of random variable 

If a probability measure Pis attached to the measurable space (Q, :F), the 
function h in Eq. 2.28 is called a random variable. We consider primarily random 
variables corresponding to  (\11,  Q)  =  (JE.d,  Bd)  and denote them by upper case 
letters, for example, X  : Q  -+  JRd  for d  >  1 and X  : Q  -+ lR for d  =  1.  Random 
variables with values in JRd,  d  >  1, are also called random vectors. 

The a-field generated by a random variable X  is 

and represents the smallest a-field with respect to which X  is measurable. 

Proof:  The collection a(X) of subsets of Q  is a a-field because (1) W E  Bd  so that r.l  = 
x-1(Rd)  E  a(X), (2) if BE Bd, then x-1(B)  E a(X) and (X- 1(B))c  =  x- 1(Bc)  E 

(2.30) 

2.4.  Measurable functions 

23 

a(X),  and  (3)  if Bi  E  Bd,  i  E  /, we have  x- 1(Bi)  E  a(X) and  Uie/X- 1(Bi)  = 
x-1 (Uie/ Bi) E a(X), where I  is a countable index set. 

If 1l is another u -field relative to which X  is measurable, this field must include the 

subsets x- 1 (Bd) of 0  so that 1l includes a(X) . • 

The distribution of X  is the probability induced by the mapping X  : Q --+  lR d 
on the measurable space (JRd, Bd), that is, (Eq. 2.29) 

(2.31) 

The  mapping  X  :  (Q, :F)  --+ 
x-1(( -00, x]} E  F, X  E  !R ([151), Corollary 3.2.1, p. 77). 

(IR,  B)  is  a  random  variable  if and  only  if 

Note:  This result is used extensively in applications  to  determine  whether a function  is 
measurable and to find properties of random variables . .& 

The JRd -valued function X  : (Q, :F) --+  (JRd,  Bd) is a random vector if and only 
if its coordinates are random variables. 
Note:  If X  is a random vector,  its coordinates  Xi  = Jri  a X, i  = 1, ... , d,  are random 
variables because the projection map rri (x) = Xi  is continuous. 

S1pose now that Xi  are random variables.  Let R be the collection of open rectan-
with members R = /1  x  · · · x  Ia, where /i are open intervals in JR.  The a-field 
gles 
= a(R) ([151], Proposition 3.2.4, p.  81), 
Bd is generated by these rectangles, that 
so that it is sufficient to show that x-1(R) is in F. We have x-1(R) = nf=1 X/1(/i) so 
that x-1 (R)  E :F since xi are random variables.  This property shows that X  is a random 
vector if and only if {wE 0  : Xi (w)  :::S  xj} E }=for all Xi  E JR,  i  = 1, ... , d. 

These  considerations  can be extended  to  a  countable  collection  (X1, X2, ... )  of 
random variables, referred to as a time series or a discrete time stochastic process. A time 
series  (X1, X2, ... ) takes values in IR00 •  The measurable  spaces  (0, :F)  and  (IR00 ,  8 00 ) 
need to be considered to establish whether (X1, X2, ... ) is a measurable function . .& 

Example 2.18:  Consider the experiment of rolling a die.  Let X, Y  : n --+  lR be 
defined by X(w) = 1 and -1 for w 
3 and w  >  3, respectively, and Y(w) = w, 
where n  = {1, 2, 3, 4, 5, 6}  and  P({w})  =  1/6.  The a-fields generated by X 
and Y  are ;:x =  {0, {1, 2, 3}, {4, 5, 6},  Q} and FY  =  P(Q), where P(Q) is the 
power set of n, that is, the collection of all subsets of the sample space.  We have 
X  E  ;:x, Y  E  :FY,  and X  E  :FY  since ;:x c  :FY.  However, Y  ¢  Fx since the 
information content of :F X is too coarse to describe Y. <> 

Example 2.19:  Let  X  :  (IR, B)  --+  (IR,  B)  be an increasing function.  Then  X 
is measurable because B can be generated by the  collection of intervals  (a, b], 
a 

b, and x-1 ((a, b]) =  (x-1 (a), x-1 (b)] is in B. <> 

24 

Chapter 2.  Probability Theory 

Example 2.20:  Let Q = [0,  1], F  = B([O, 1]), and P(dw) = dw. If a  and f3  >  a 
are constants, the function w  f--*  X ( w)  =  a  + ({3  - a) w is a random variable on 
(Q, F, P)  since it is  continuous.  The distribution of X  is  Q((xt, xz])  =  (xz-
Xt)/({3- a). ¢ 
Proof:  Take B  =  (XJ, xz] in the range of X.  The distribution  Q ( (x!, xz]) is equal to the 
probability P((wt. wz]) of the interval x- 1 ((x1, xz]), where w;  = (xi  - a)/({3 -a). • 

2.4.3  Measurable transformations 

The determination of the output of a physical system subjected to a random 
input involves transformations of random variables. For example, suppose that the 
input to a system is modeled by an JRd -valued random variable X  and the objective 
is to  characterize the system output Y  =  g(X), where g  :  JRd 
IR  depends on 
the system properties. The mapping 

(Q' F) L  (IRd' Bd) 

(IR,  B) 

from  (Q, F) to  (lR,  B)  defines  the  output.  A  first  question we need to pose  is 
whether Y  is a random variable. 

If (Q, F), (\11,  9), and (<I>,  H) are measurable spaces and 

h: (Q, 

(\11,  9),  g: (\11,  9) 

(<1>,  H) 

are measurable functions, then 

go h: (Q, 

(<1>,  H) 

is measurable. 

Proof:  ForB  E  1{, g-1 (B) ising since g is measurable.  We have h-1 (A)  E  :F for any 
A  E  g since h is measurable, so that h-I (g -I (B))  E  :F.  Hence, g  o h is measurable from 
(Q, :F) to (<I>,  1{).  • 

(lR,  B) is a real-valued measurable function and 
(IR,  B)  is a Borel measurable function, that is g -I (B)  c  B, then 

Example 2.21:  If X  : (Q, F) 
g  :  (IR,  B) 
Y  = g(X) =go X  : (Q, F) 
Proof:  We  need  to  show  that  y-1(B)  =  x- 1(g- 1 (B))  E  :F for  any  B  E  B.  This 
condition is satisfied because B 1 = g- 1(B)  E  B, VB  E  Band x- 1 (B 1)  E  :F, VB'  E  B, by 
the properties of g  and X  (Fig. 2.2).  • 

(lR,  B) is a real-valued measurable function.  <> 

Example 2.22:  If X  is a random variable on a probability space (Q, F, P), r  >  0 
is an integer, and A.,  u  are some real constants, then 

are random variables on the same probability space.  ¢ 

-J..X 
e 
' 

and  eAux 

2.4.  Measurable functions 

25 

Real 
line 

Real 
line 

-1 g 

set 

Figure 2.2. Mappings X  and g 

Note:  A continuous function g  : lR  -+ lR is Borel measurable because the open intervals 
of lR  generate the cr-field Band g  is continuous if g-1(1)  E  V  for  any  I  E  V, where 
V  denotes the topology generated by the open intervals of JR.  Hence,  g o X  is a random 
variable if g is a continuous function and X is a random variable. 

The function w-+ eA u X(w)  E  IC  defined by the last transformation is complex-
valued.  A complex-valued function defined on  Q  is measurable if its real and imaginary 
parts are measurable functions  from  (Q, F) to  (JR,  B).  Hence, eA u X  is a measurable 
function because its real and imaginary parts, cos(u X) and sin(u X), are F-measurable as 
continuous transformations of X.  6 

Example 2.23:  If (X, Y)  :  (Q, F)  --+  (JR.2, B2)  and g  :  (JR.2, B2)  --+  (JR.,  B)  are 
measurable functions, then g(X, Y)  e  :F jB. For example, the functions X v Y = 
max(X, Y), X  1\ Y  =  min(X, Y), X+ Y, X- Y, X  Y, and X/Y are measurable 
from  (Q, F) to  (JR.,  B).  The  transformation  XfY  is  defined for  Y  =f:.  0  ([40], 
Theorem 3.1.5, p. 36)). 
Example 2.24:  If X;, i = 1, 2, ... , is a sequence of random variables defined on 
a measurable space (Q, F), then inf; X;, sup; X;, liminf; X;, and lim sup; X;  are 
measurable. 
Proof:  The event {inf; X;  >  x}  = nj{X;  >  x},  x  E  lR,  is in F  since  X;  are random 
variables.  Hence,  inf; X;  is  a measurable function.  Similarly,  sup; X;  is a random vari-
able  since {sup; X;  :::0  x}  = n;{X;  :::0  x}.  Because liminf; X;  = supi:O:l infj:o:i  Xj  and 
infj:o:i X j  are random variables, liminf; X;  is measurable.  A similar argument shows that 
lim sup; Xi  is a random variable.  • 

Example 2.25:  Consider a series  X  =  (X 1. X2, ... ),  where X;  are measurable 
functions from (Q, :F) to (\11,  Q).  Let K be the collection of all subsets of Z + = 

26 

Chapter 2.  Probability Theory 

{1, 2, ... }.  The function (m, w) 
Xm(w) depending on the arguments m and w 
is measurable from (/Z. + x  Q, K  x  :F)  to  (IV, Q).  Generally, this property does 
not hold if the discrete index m in this  example is  allowed to take values in an 
uncountable set, as we will see in the next chapter. ¢ 

Proof:  Let A= {(m, w)  :  Xm(w)  E  B} be the inverse image of the function  (m, w) 
Xm(w)  in z+ x  n  corresponding  to  an  arbitrary member B  of 9.  Because  Xm  is  mea-
surable,  this  set can be expressed  as  the  countable union  Um{w  :  Xm(w)  E  B} of sets 
{w  :  Xm (w)  E  B} that are in :F for each m  2:  1.  Hence, A is inK x  :F.  We also note that 
the function m  !--+  Xm (w) is K-measurable for a fixed  (L)  E  n  since {m  : Xm (w)  E  B} is a 
subset of z+ so that it is inK .• 

XM(w)(w) is measurable from (Q, :F) to (IV, Q).  ¢ 

Example 2.26:  Let M  :  (Q, :F)  --+  (IZ +, K)  and Xm  :  (Q, :F)  --+  (IV, Q)  for 
m  E  z+ be  measurable functions,  where K  consists  of all parts  of Z +.  The 
functionw 
Proof:  We  need to  show  that A  = {w  :  XM(w)(w)  E  B} is in :F forB  E  9.  The sets 
Am = {w: M(w) = m}, m  = 1, 2, ... , provide a countable partition of nand Am  E  :F for 
each m because M  is :F / K-measurable.  Hence, A is equal to a countable union of disjoint 
parts, that is, 

Since Xm  is an :F /9-measurable function for each m, A is in :F.  • 

2.5  Integration and expectation 

Let (Q, :F,  P) be a probability space.  We define the expectation for a spe-
cial class of random variables taking a  finite  number of values  and then extend 
this definition to arbitrary random variables. 

If I  is a finite index set and A;  E  :F, i  E  /,is a partition of Q, then 

X= I:x; lA;• 

x;  E  JR, 

ie/ 

(2.32) 

defines a simple random variable. 

Note:  Because X  takes a constant value x;  in A; and the subsets A; partition n, we have 
P(A;) = P(X = x;), where {X;  = x;} is an abbreviated notation for the event {w  E  n  : 
X(w) = x;}. 

The  collection of simple random variables is  a vector space.  Moreover,  if X  and 
Yare two  simple random  variables defined  on  a probability  space  (Q, :F,  P), then  X Y, 
X  A  Y  = min(X, Y) and  X  v  Y  = max(X, Y)  are  simple random variables on the  same 
space ([151], Section 5.1). 

2.5.  Integration and expectation 

If A E F, the indicator function 

{  1 
1A(w)  =  0 

ifwEA 
ifw 

27 

is a simple random variable. 

(2.33) 

Proof:  Because  1:41(B)  = {w:  lA(w)  E  B} is 0,  A, Ac, and  Q  ifO, 1 ¢  B, 1  E  B  but 
0 ¢  B, 0  E  B but 1 ¢  B, and 0, 1 E  B, respectively, we have 1:41(B)  E F  for any BE B 
so that lA is FIB-measurable. • 

The following measurability theorem suggests that we may be able to ex-
tend properties established for simple random variables to arbitrary random vari-
ables. 

LetX: Q--+  RbesuchthatX(w)  Oforallw E  Q.  ThenX  E F/Bifand 
only if there exists an increasing sequence of simple random variables X n 
0, 
n = 1, 2, ... , converging to  X, referred to as an approximating sequence for 
X ([151], Theorem 5.1.1, p. 118). 
Proof:  If there is an approximating sequence of simple random variables Xn  and X (w)  = 
liiDn--+oo Xn(w), then X  is a random variable since limits preserve measurability (Exam-
ple 2.24). 

Figure 2.3. Construction of the approximating sequence X n 

If X  E  FjB, construct the sequence 

nzn 

Xn = LX 

k=l 

(k  1) 

; 

lAn,k + n lBn 

0 

of simple random variables, where An,k  = {w :  (k- l)/2n  ::::;  X(w)  <  kj2n} and  Bn  = 
n}  (Fig.  2.3).  The sequence  Xn, n  = 1, 2, ... , is increasing, that is,  Xn  ::::; 
{w  :  X(w) 
Xn+l• and its members are measurable functions that are smaller than X.  If X(w)  <  oo, 

28 

Chapter 2.  Probability Theory 

then IXn(w)- X(w)l  ::;  2-n --+  0 as n--+ oo.  If X(w) = +oo, then Xn(w) = n so that it 
approaches infinity as n increases.  • 

2.5.1  Expectation operator 

Consider  a  probability  space  (Q, :F,  P).  We  define  the  expectation  for 
finite-valued simple random variables and then extend this definition to arbitrary 
real-valued random variables. 

2.5.1.1  Finite-valued simple random variables 

If X  is  a  simple random variable  (Eq.  2.32)  such that  lxd  <  oo,  i  E  /, its 
expectation is 

(2.34) 

E[X] =  I>i P(A;). 

iel 

Note: The expectation of the indicator function in Eq. 2.33 is E[lA] = P(A).  A 

Example 2.27:  Consider a loaded die with m  <  oo  sides showing the numbers 
Xi  with  probabilities  Pi.  i  =  1, ... , m.  Suppose  we  roll  the  die  n  times  and 
ni  ;:::  0 denotes the number of times we see side i.  The arithmetic average, i  = 
Lie! Xi  (ni/n), of the observed values approximates E[X] in Eq. 2.34 for large 
values of n because n if n  converges to Pi  as n  --+  oo. <> 

The following properties are direct consequences of the definition in Eq. 2.34. 

If X  andY are finite-valued simple random variables, then 

•  X  ;:::  0 ==>  E[X] ;:::  0. 
•  E[a X+ fJ  Y] =a E[X] + fJ  E[Y],  a, fJ  =constants==> E[·] is linear. 
•  X  ::;  Y  implies E[X] ::;  E[Y] ==>  E[·] is monotone. 
(2.35) 

Proof:  Let  X  =  Lief Xi  1Ai  and  Y  =  LjeJ Yj 1ni' where  I  and  J  are  finite  sets. 
X  2::  0 implies x;  2::  0 so that E[X] is positive (Eq.  2.34),  that is,  the first property.  To 
prove the  second property,  note that a X + f3  Y is a finite-valued simple random variable 
corresponding  to  the  partition A;  n  Bj  of f.l  ([151],  pp.  120-121).  If X  ::;  Y,  the  first 
property and the fact that Y- X  2::  0 is a simple random variable imply E[Y- X]  2::  0 or 
E[Y] 2::  E[X] (Eq. 2.34) .• 

If X  and X n are finite-valued simple random variables and X n t  X  or Xn  ,!..  X, 
then ([151], Property 5, p.  121) 

E[Xn] t  E[X]  or  E[Xn] ,!,  E[X]. 

(2.36) 

2.5.  Integration and expectation 

29 

2.5.1.2  Positive random variables 

If P(X =  oo)  >  0, set E[X] =  oo.  Otherwise, 

E[X] = 

lim  E[Xn], 
n--j.CXJ 

(2.37) 

where  Xn  is  an approximating sequence of finite-valued  simple random vari-
ables such that Xn  t  X and E[Xn] is finite for each n. 

Note:  The measurability theorem guarantees the existence of an approximating sequence. 
The expectation in Eq.  2.37  is well  defined since  the value  of E[X]  does  not change  if 
another approximating  sequence  Ym  t  X  is used in this equation in place of Xn  ([151], 
Proposition 5.2.1, p.  122).  A 

The properties of the expectation for finite-valued simple random variables 
in Eqs. 2.35 and 2.36 can be extended to positive random variables with the range 
[0, oo]. 

If X, Y, and Xn, n =  1, 2, ... , are positive random variables with range [0, oo], 
then ([151], Section 5.2.3) 

•  E[X]  E  [0, oo]. 
•  E[a X+ p Y] =a E[X] +  p E[Y],  a, p >  0. 
•  Xn  t  X  ==}  E[Xn] t  E[X]. 

(2.38) 

Note:  The  last property,  called  the  monotone  convergence  theorem,  gives  conditions 
under which limits and expectations can be interchanged ([151], Section 5.2.3).  A similar 
result is given in Eq. 2.36.  A 

2.5.1.3  Arbitrary random variables 

An arbitrary random variable  X  has  the  representation  X  =  X+  - x-, 

where 

x+ =X v o =  max:(X, 0)  and  x- =(-X) v o =  max:(-X, 0) 

(2.39) 

are positive random variables. 

• If X is an arbitrary random variable such that at least one of E[X +]and E[X-] 
is finite, we define 

(2.40) 

elf E[X+] and E[X-] are both finite, then E[X] in Eq. 2.40 exists and is finite. 
We say that X  has a finite expectation or is P-integrable. 

• If both E[X+] and E[X-] are unbounded, E[X] does not exist. 

30 

Chapter 2.  Probability Theory 

Note: If the expectations E[X+] and E[X-] are unbounded, E[X] given by Eq. 2.40 does 
not exist.  If E[X+] and  E[X-] are finite,  then both  E[X]  <  oo  and E[IXI]  <  oo  since 
X  = x+ - x- and  lXI  = x+ + x-. If one of the expectations  E[X+] and  E[X-] is 
finite  and the other infinite,  E[X] is defined but is unbounded.  For example,  E[ X]  exists 
and E[X] =  +oo if E[X+] =  +oo and E[X-1 is bounded.  A 

If the expectation of a random variable X exists, it is also denoted by 

E[X] =In X(w) P(dw)  or E[X] = f X dP. 

•  The integral of X  with respect to P  over set A  E  F  is 

E[X 1A] =In 1A(w) X(w) P(dw) = i X(w) P(dw). 

(2.41) 

(2.42) 

•  If E[X 1A] exists and is finite,  X  is  said to be integrable with respect to  P 
over A or P-integrable over A. 

Note:  The integrals in Eqs. 2.41  and 2.42 are special cases of the Lebesgue-Stieltjes inte-
gral J h dJ.L,  where his a measurable function on a measure space (r.l, :F,  J.L).  The random 
variable X and the probability measure Pin Eqs. 2.41  and 2.42 correspond to the measur-
able function h  and the measure J.L,  respectively.  Hence, J X d P  has properties similar to 
fhdJ.L.  A 

Example 2.28:  Let Q  =  {w  =  (i, j)  :  i, j  =  1, 2, ... , 6}  be the  sample space 
associated with the experiment of rolling two dice and F  be the collection of all 
subsets of n. Define a random variable X(w) =  i 2 + }2 . This function is positive 
and takes on a finite number of values.  The integral of X  with respect to  P  over 
A is (Eq. 2.42) 

E[X lA]  =  2)i2 + }2)  36  =  [(2)(40) + (2)(34) + 32]  36  =  5, 

1 

1 

wE A 

where A= {w =  (i, j): i + j  =  8}  =  {(2, 6), (3, 5), (4, 4), (5, 3), (6, 2)}. <> 

2.5.2  Properties of integrals of random variables 

We review essential properties of integrable random variables. These prop-
erties are divided into three groups depending on the number of random variables 
in the integrand and on the domain of integration. 

2.5.2.1  Finite number of random variables 

Let X  and Y  be random variables defined on a probability space (Q, F, P) 

and let A  be an event on this space, that is, A  E  F. 

2.5.  Integration and expectation 

31 

I fA  X dP is finite if and only if fA  lXI dP  <  oo ([40], Section 3.2). 

Note:  We have IE[X]I  <  oo if and only if E[IXI]  <  oo by setting A = Q.  This result is 
consistent with an earlier comment (Eq. 2.40).  A 

If X andY are P-integrable over A, a X+ bY is P-integrable over A and 

i<aX+bY)dP=a LxdP+b LYdP, 

(2.43) 

where a, bare constants ([40], Section 3.2). 

Note:  If A  =  Q,  Eq.  2.43  yields  E[a X  + bY]  = a E[X] + b E[Y]  showing  that  E 
is  a linear  operator  in  agreement  with  Eq.  2.35  and  2.38.  This  property  implies  that 
fA L7=1 ai Xi dP = L:?=t ai fA Xi dP if the random variables Xi are P-integrable over 
A and ai denote constants.  A 

If X  is P-integrable and Ai E :F is a partition of Q, then ([40], Section 3.2) 

(2.44) 

I If X:=:::  0 a.s., then fA  X dP :=:::  0 ([40], Section 3.2). 

If X is P-integrable, then X is finite a.s., that is, {w: X(w) =  ±oo} is in :F and 
has probability zero ([40], Section 3.2). 
If Y  ::::X a.s. and the integrals f X dP and f Y dP exist ([40], Section 3.2), 

LYdP:::: L XdP. 

(2.45) 

Note:  Because X- Y  2:  0, we have fA (X- Y) dP 2:  0 by one of the above properties. 

The mean value theorem, a P(A) :::;  fA X d P  :::;  b P(A) if a :::;  X  :::;  b a.s., and the 

modulus inequality, 

IL XdPI::::: L IXIdP, 

(2.46) 

are  direct  consequences  of Eq.  2.45.  For example,  a P(A)  :::;  fA X  dP  follows  from 
Eq.  2.45  with  Y  =  a  and  X  2:  a  a.s.  The modulus  inequality  can  be  obtained  from 
Eq. 2.45 with (-lXI, X) and (X, IX!) in place of (Y, X).  A 

32 

Chapter 2.  Probability Theory 

2.5.2.2  Sequence of random variables 

Let Xn, n = 1, 2, ... , andY be random variables defined on a  probability 

space (Q, F, P). Let A be an event on this space, that is, A  E  F. 

Xn  =  X  a.s. and if, for each n, 

•IXnl:::;: Y a.s., Y ::=:  0, and fAY dP  <  oo, or 
•  IXn I :::;:  c a.s. for a positive constant c, or 
•  Xn  ::=:  0 a.s. is an increasing sequence that can take on the value +oo, 

then 

lim  {  Xn dP = { ( lim  Xn) dP = { X  dP. 

(2.47) 

}A 

}A 

}A 

Note:  Under the conditions of this theorem we can interchange the limit and the integra-
tion operations.  The a.s. convergence of Xn  to X  means that the numerical series  Xn (w) 
oo  for  each w  E  Q  \  N,  where  N  E  :F  and  P(N)  =  0 
converges  to  X(w)  as  n 
(Section 2.13). An event N  with this property is called a null set. 

The statements in Eq.  2.47  corresponding to the conditions  (1)  IXnl  :::=::  Y  a.s  and 
fAY dP  <  oo, (2)  IXnl  :::=::  c a.s., and (3)  Xn 
0 a.s. is an increasing sequence with +oo 
being an allowed value are referred to as  the dominated convergence, bounded conver-
gence, and monotone convergence theorems, respectively.  Slightly weaker versions of the 
dominated,  bounded,  and monotone  convergence conditions under which Eq.  2.47  holds 
can be found in [40] (Section 3.2).  i. 

If Ln fA  IXnl dP  <  oo, then integration can be performed term by term ([40], 
Section 3.2) 

(2.48) 

If Xn  ::=:  0 a.s. on A for each n, then ([40], Section 3.2) 

{  (liminf Xn) dP:::;:  liminf  {  Xn dP 
}A 

}A 

n 

n 

(Fatou's lemma). 

(2.49) 

Note: Recall that 

liminf Xn  = sup  inf Xk =  lim  1\k>nXk  and 
limsupXn = inf supXk =  lim  Vk>nXb 

-

-

where 1\k>nXk and Vk>nXk are increasing and decreasing sequences. Because Vk>nXk = 
The above limits of 
-
Xn resembles the limits for sequences of subsets in Q (Eqs. 2.19 and 2.20).  Also note that 

(:_Xk),  we hmre 

Xn  = 

{VnXn  :::5  x}  = nn{Xn  :::5  x}  E :F  and  {1\nXn  >  x} = nn{Xn  >  x}  E  :F 

2.5.  Integration and expectation 

33 

if Xn  are random variables on (Q, :F,  P). • 

If the sequence of random variables Xn is such that IXnl  Z, where Z:::: 0 a.s. 
and P-integrable over A, then 

n 

liminf1  XndP 

{  (liminfXn)dP 
JA 
lim sup 1 Xn d P  1 (lim sup Xn) d P 

n  A 

A 

n 

n 

A 

(Lebesgue theorem). 

(2.50) 

Proof:  Since Z  is  P-integrable,  Z  is finite  a.s.  so that P({w  E  A  :  Z(w)  =  +oo})  =  0. 
Note that Xn  +  Z  2: 0 a.s. so that the Fatou lemma yields 

/(liminfXn)dP+ J 

J XndP+ J ZdP 

or  j(liminfXn)dP 
liminfJ XndP  since liminf(Xn  +  Z)  =  liminfXn  +  Z.  The 
last inequality in Eq.  2.50 results from sup{Xn, Xn+l• . .. }  =  -inf{-Xn. -Xn+l• ... }. 
The middle inequality is valid for any numerical sequence, in particular for the sequence 
fAXndP .• 

Example 2.29:  The inequalities in Eq.  2.26 can be obtained from the Lebesgue 
theorem in Eq. 2.50 with A  =  Q, X n  =  1 An, and An  E  F. ¢ 

Proof: Take A  =  Q  and Xn  =  lAn, An  E  :F, in Eq. 2.50.  Then 

f (liminfXn)dP =/(sup inf lAk)dP =  P  (sup lnk::nAk)  =  P(liminfAn) 

n-+oo 

n-+oo 

lAk  =  lnk>nAk  is an increasing sequence so that SUPn>Ilnk>nAk  is equal 
tl nk>n Ak  or lun> 1 n;>nAk . Similar considerations give the last inequalitY in Eq. 2.26. 

because 
to 
The integral fA Xn dP is 

lAn dP =  P(An) so that we have 

liminf P(An) 

n 

sup P(An) 
n 

from the middle inequality in Eq. 2.50.  • 

2.5.2.3  Expectation 

The  properties  in--Sections  2.5.2.1  and  2.5.2.2  hold for  any  A  E  F.  If 
A =  Q, the above integrals become expectations. We give here a list of properties 
of the expectation operator that are useful for calculations.  It is assumed that all 
expectations exist and are finite. 

34 

Chapter 2.  Probability Theory 

•  The expectation is a linear operator. 
•  If X  ::::  0 a.s., then E[X] ::::  0. 
•  If Y :::;  X  a.s., then E[Y] :::;  E[X]. 
•  IE[X]I  s E[IXI]. 
•  Iflimn--+oo Xn  =X a.s., and there exists Z:::: 0 a.s.  such that E[Z] <  oo and 
IXn I S  Z, then limn--+oo E[Xn] =  E[Iiffin--+oo Xn]  =  E[X]. 
•  If Ln E[IXn ll <  00, then E  [.En Xn]  =  Ln E[Xn]. 
Proof:  The  first  four  properties  follow  from  Eq.  2.43,  the  fact  that  X 
0 a.s.  implies 
0 for  A  E  :F,  Eq.  2.45,  and Eq.  2.46,  respectively.  The Lebesgue  theorem 
fA X dP 
gives  fA(limXn)dP  =  limfA XndP  if limXn  =X.  The  last property  follows  from 
Eq. 2.48 .• 

2.6  The Lq(Q, F, P) space 

Let (Q, F, P) be a probability space.  Denote by Lq(Q, F, P) the collec-
tion of real-valued random variables X defined on (Q, F, P) such that E[IXI q]  < 
oo for q  ::::  1.  If X  is in Lq(Q, F, P) we write X  "' Lq(Q, F, P) or X  "' Lq 
provided that there is no confusion about the probability space.  The case q  =  2 
is most relevant for applications because it relates to second moment calculus and 
estimation theory discussed later in this  and subsequent chapters.  The L 2 space 
has some notable properties. 

•  L2 is a vector space. 
•  L2 is a Hilbert space with the inner product (X, Y)  =  E[X Y] for X, Y E  L2 
and the norm II  X  II Lz= (E[X2l)112, referred to as the L2-norm. 
Proof:  We need to show that (1)  (X, Y)  =  E[X Y]  is an inner product on L2,  (2) L2 is a 
vector space, and (3) L2 with the metric d(X, Y)  =  (X- Y, X- Y) 112 =II  X- Y  IIL2  is 
complete. 

The expectation E[X Y] defines an inner product on L2 because 

(0, X) = 0,  X  E  L2, 
(X, X)  >  0,  X  E  L2,  X#=  0, 
(X, Y)  =  (Y,  X),  X,  Y  E  L2, 
(X+ Y,  Z)  =(X, Y) +  (Y,  Z),  X, Y,  Z  E  L2, 
A.  (X, Y)  =(A. X,  Y),  X, Y  E  L2,A.  E  R. 

The function d: L2  x L2----+  [0,  oo) defined by d(X, Y)  =II  X- Y  IIL2  is a metric on L2 
because 

d(X, Y)  =  0 
d(X, Y)  =  d(Y, X) 
d(X, Y) 

d(X, Z) + d(Z, Y) 

for each X, Y,  Z  E  L2. 

if and only if X= Y, 

for each X, Y  E  L2, 

2.6.  The Lq (Q, :F,  P) space 

35 

The first  condition in the  above equation is  not satisfied in  a strict sense.  The condition 
holds if we do not distinguish between random variables that differ on a set of probability 
zero. 

That  L2  is  a  vector  space  follows  from  the  properties  (a)  X 

L2  since  E[(). X)2]  =  ).2 E[X2]  <  oo  and  (b)  X, Y 

L2  and  ).  E  lR 
imply  ). X 
L2  implies 
L2  since  E[(X +  Y)2]  =  E[X2] +  E[Y2] +  2 E[X Y],  E[X2]  and  E[Y2] 
X  +  Y 
are  finite,  and  IE[X Yll  <  oo  by the  Cauchy-Schwarz inequality discussed  later in this 
chapter (Eq. 2.112). 

It remains to show  that L2 endowed with the metric  (X, Y)  r+  d(X, Y)  =II  X-
Y  IILz is complete, that is, that any sequence Xn  E  L2, n  = 1, 2, ... , with d(Xn, Xm)  -+ 0 
as n, m-+ oo is convergent and its limit is in L2.  The proof that L2 is a Hilbert space can 
be  found  in  [66]  (Proposition 4,  p.  399).  We  only  show  here  that,  if X,  Xn  E  L2  and 
II  Xn- X  11£2 -+  0 as  n  -+  oo,  that is,  Xn  converges in mean square (m.s.)  to  X,  then 
II  Xn - Xm  II Lz-+ 0 as n, m  -+  oo, that is, Xn is a Cauchy sequence in the mean square 
sense (Section  2.13).  Take  e  >  0  and  an index ii  such that  II  Xn- X  11£2 <  t:/2  and 
II  Xm- X  IIL 2 <  ef2 for n, m  2::  ii. This is possible since II  Xn- X  IIL 2  converges to zero 
as n-+ oo.  We have  II  Xn- Xm  11£2:511  Xn- X  11£2  +II Xm- X  11£2 <  e for n, m  2::  ii, 
that is,  II  Xn  - Xm  IIL2  converges to zero as n, m  -+ oo.  • 

Example 2.30:  The sequence of spaces L q ( Q , :F,  P) is decreasing, that is, L ql 
Lq  for q  :=:  q'.  However,  the  spaces  Lq(Q, :F, tL)  corresponding to a  measure 
space (Q, :F, tL) may not decrease with q. <> 

Proof:  The  first  part follows  from  (E[IXIJ)P  :5  E[IXIP],  1  <  p  <  oo,  X  E  L P•  de-
rived from HOlder's inequality with Y  = 1.  This inequality is proved later in this chapter 
(Eq.  2.113).  Holder's inequality with  IXIq  in place of X  gives  {E[IXIql)P  ::::  E[IXIPq] 
1j 
::::  E[IXIq l  for  p  =  q' jq  2::  1.  Hence,  E[IXIq l  <  oo  implies 
or  (E[IXIql)q  q 
E[IXIql <  oo, that is, Lql  s;  Lq forq'  2::  q. 

Let h  :  (JR,  B, ).)  -+  (JR,  B, ).)  be a measurable function defined by h(w) = 0 for 
w  <  1 and  h(w)  =  1/w for w  2::  1,  where  ).(dw)  =  dw is  the Lebesgue measure.  The 
integrals  fJR h d).  and  fJR h2 d).  are  equal  to  +oo  and  one,  respectively.  Hence,  h  is  an 
element of L2(JR,  B, ).) but is not in L1 (JR,  B, ).), so that L2 rt.  L1.  • 

I 

I 

Let (Q, F, P)  be a  probability space and Q a  sub-a-field of F.  Consider 
an m.s.  convergent sequence Xn  in L2(Q, Q,  P).  If the m.s. limit X  of Xn  is in 
L2(Q, Q,  P), we say that L2(Q, Q,  P) is a closed subspace of L2(Q, F, P). The 
following theorem, referred to as the orthogonal projection theorem,  gives an 
essential property of the L 2  spaces. 

If Q is  a  sub-a-field of :F,  then for any  X  E  L2(Q, :F, P)  there  is  a  unique 
X E  L2(Q, Q,  P) such that ([156], Theorem4.11, p. 84) 

II  X- X 11£2 =  min{ll  X- Z  IIL2 :  Z  E  L2(Q, Q,  P)}  and 
(X- X,  Z) = 0,  vz E  L2(Q, Q,  P). 

(2.51) 

36 

Chapter 2.  Probability Theory 

Note:  The random variable X E  L2(f2, 9, P) has the  smallest mean square error of all 
members of L2(f2, 9, P), and is called the best m.s. estimator of X.  The second equal-
ity in the  above  equation can be used  to  calculate X and shows  that the error X  - X is 
orthogonal to L2(f2, 9, P).  A 

2. 7 

Independence 

We define independent a-fields and apply this definition to events and ran-
dom variables. We also discuss the Borel Zero-One Law giving the probability of 
lim sup of independent events. 

2.7.1 

Independence of a-fields 

Consider a probability space ( Q , :F,  P) and a collection of sub-a-fields, :F i, 

i  E  I, of :F. 

• If I  is finite and 

P (nieiA;) = n P(Ai), 

ie/ 

'v'Ai  E  :F;, 

(2.52) 

then the a-fields :Fi, i  E  I, are independent. 
•  If I  is infinite and Eq. 2.52 holds for all finite subsets of I, then the a-fields 
:Fi  are independent. 

Note:  The above condition implies that any sub-collection of events A;  E  :Fi, i  E  I, must 
satisfy Eq. 2.52 since some of the events Ai  may coincide with the sample space 0. This 
requirement is consistent with Eq.  2.54.  If the a-fields :Fi, i  E  I, are on different sample 
spaces, the above independence condition has to be applied on the corresponding product 
measure space.  A 

Example 2.31:  The sub-a-fields :Ft and :F2 generated by the collections of events 
At  = {{1, 2, 3}, {4, 5, 6}}  and A2  = {{1, 2, 3}, {4}, {5}, {6}}  in Example 2.1  are 
not independent.  For example,  the  subset {1, 2, 3}  belongs to  both :F 1  and :F2, 
but the  probability  P({1, 2, 3}  n {1, 2, 3})  =  P({1, 2, 3})  =  1/2 differs  from 
P({1, 2, 3}) P({1, 2, 3})  =  1/4. <> 

2. 7.2 

Independence of events 

The definition in Eq. 2.52 applied to events is consistent with the classical 

definitions of independence between events. 

The events Ai  E  :F, i  E  I, of a probability space (Q, :F,  P) are independent if 
the a-fields a(Ai) generated by these events are independent, where the index 
set I  may be finite or infinite. 

2. 7.  Independence 

37 

Example 2.32:  Let A and B be two events in :F.  These events are independent if 
the a-fields a(A) =  {0, A, Ac, Q} and a(B) =  {0, B, Be, Q} are independent or, 
equivalently, if P(A n B) =  P(A) P(B). <> 
Proof:  The  independence  of the  a-fields  a(A)  and  a(B) requires  that  P(Ai  n Bj)  = 
P(Ai) P(Bj) for  all  Ai  E  a(A) and  Bj  E  a(B)  (Eq.  2.52).  The resulting  non-trivial 
conditions  of independence  are  P(A n B)  = P(A) P(B),  P(Ac n B)  = P(Ac) P(B), 
P(A n Be)  =  P(A) P(Bc),  and  P(Ac n Be)  =  P(Ac) P(Bc).  These  conditions  are 
equivalent with the classical requirement P(A n B) = P(A) P(B) for the independence of 
two events (Eq. 2.53).  For example, P(AcnB) = P(B)- P(AnB) since A cnB = B\(An 
B) so that P(A c n B) = P(A c)  P(B) if P(A n B) = P(A) P(B). Similar considerations 
apply to show that P(A n Be) = P(A) P(Bc) follows from  P(A n B) = P(A) P(B) . • 

We  give  now  classical  definitions  for  the  independence  of two  or more 

events and for families of events. 

Two events, A and B, are said to be independent if 

P(A n B)= P(A) P(B). 

(2.53) 

Note:  Let A  and  B  be  two  events  such that  P(A)  >  0 and  P(B)  >  0.  If A  and  B  are 
independent, the occurrence of B does not affect the probability of A so that P(A  I B) = 
P(A) implying  P(A n B)  =  P(A) P(B).  An equivalent condition of independence for 
the  events  A  and  B  is  P(B  1  A)  = P(B).  Note that the  events  A  and  B  = Ac  are  not 
independent because A cannot occur if B is observed.  & 

A finite collection of events, Ai, i  = 1, ... , n, is independent if 
P(Ai 1 n Ai2  n · · · n Aim)= n P(Aik) 

m 

k=l 

(2.54) 

holds for any subset {i 1,  ... , im}  C  { 1, ... , n}. 

Example 2.33:  The conditions of Eq.  2.54 are  essential to  assure  the  indepen-
dence  of three  or more events.  It is  not  sufficient to  require  that  Eq.  2.54  be 
satisfied for  the  entire  collection of events.  For example,  consider the  sample 
space Q  =  {1, 2, 3, 4}  with :F given by all parts of Q  and a probability measure 
P  defined by P({1})  =  .../2/2- 1/4, P({2})  =  1/4, P({3})  =  3/4- .../ij2, and 
P({4}) = 1/4. Let A1  =  {1, 3},  A2  =  {2, 3}, and A3 = {3, 4}  be some events on 
(Q, :F).  The probability of A1  n A2 n A3  =  {3}  is  P({3})  =  3/4- .../2/2 and 
is equal to  P(A1)P(A2)P(A3).  However,  P(A1 n A2)  f.  P(A1)P(A2)  ([106], 
p. 2). <> 

Example 2.34:  Let Si,  i  =  1, 2,  ... , n, be the event that the maximum flow in a 
river during year i  does not exceed the height of a flood protection system.  The 

38 

Chapter 2.  Probability Theory 

probability that there will be no flood inn years is  P8 (n)  =  P(n?=l S;).  If the 
events S;  are independent, the reliability of the flood protection system in n years 
is P8 (n) = Jl?=l P(S;) so that P8 (n) = pn for the special case P(S;) = p. ¢ 

The  families  C;  c  :F,  i  =  1, ... , n,  are  independent,  if  for  any  A 1  E 
cl •... ' An  E  Cn. the events AI, ... ' An  are independent. 

The families Ct.  t  E  T, where T is an arbitrary index set, are independent if Cr. 
t  E  I, are independent families for each finite subset I  of T. 

The above definitions and the following criterion can be used to prove in-
dependence of a-fields. The criterion uses classes of events forming a rr-system. 
A  collection C of subsets  of n is  said  to be a  rr -system if it is  closed to  finite 
intersection, that is, A, B  E  C implies A n  B  E C. 
If C;  is a non-empty class of events in :F for each i  = 1, ... , n, such that (1) C i 
is a rr-system and (2) C;, i  =  1, ... , n, are independent, then the a-fields a(C;), 
i  = 1, ... ,n, areindependent([l51], Theorem4.1.l,p. 92). 

Borel Zero-One Law.  If A;  is a sequence of independent events, then 
ifandonlyif I:; P(A;) <  oo, 
ifandonlyif I:; P(A;) = oo. 

)  _  {  0 
1 

A·)_ P(A·. 

1  t.o.  -

P(l. 

tmisup 

1 

-

(2.55) 

Proof:  For proof see  [151]  (Proposition 4.5.2, p.  103).  We only show that Li P(A;) = 
oo  implies  P(A; i.o.)  =  1.  Note  that,  by  the  definition  of the  event  {A;  i.o.}  and  the 
independence of A;, 

1- P(A; i.o.) = 

Aj) = P( _lim 

=  _lim 

00 

=  .lim  n[1- P(A;)]. 

i=j 

The inequality  1 - x  .:::;  e-x, 0  <  x  <  1,  applied for  x  = P(A;) gives  1 - P(A;)  .:::; 
P(A;) = 
exp[-P(A;)] so that 1- P(A; i.o.)  .:::; 
oo forallj, exp[-

P(A;)] is zero so that 1- P(A; i.o.) = 0.  • 

P(Ai). Because 

e-

2. 7.3  Independence of random variables 

The random variables X;, i  E  I, defined on a probability space (!:2, :F, P) are 
independent if the a-fields a(X;) generated by these random variables are inde-
pendent, where the index set I  is finite or not. 

2.8.  The Fubini theorem 

39 

Example 2.35:  Let  X  and  Y  be  two  real-valued random  variables  defined  on 
(Q, :F, P). If the a-fields a(X) and a(Y) are independent, the random variables 
X  and Y  are  said to be independent.  This definition is  equivalent to  a classical 
definition for the independence for random variables given in Section 2.11.2. ¢ 

Note:  The condition of independence of the events A and B in Example 2.32 is equivalent 
to the requirement that the random variables lA  and ln be independent.  .t. 

Example 2.36:  Let Xk. k  =  1, 2, ... , be a sequence of independent random vari-
ables  and CfJk  be real-valued measurable functions defined on the real line.  The 
random variables CfJk  o  Xk  are independent.  For example, the collection of func-
tions sin(Xk)  are independent since the "sin" function is continuous and, hence, 
measurable. ¢ 
Proof:  We have rpJ;1(B)  Band XJ;1(rpJ; 1(B)) 
:F because (/Jk  is a Borel measurable 
function and Xk  is a random variable. Because XJ;1(rpJ;1(B))  XJ; 1(B) and the u-fields 
XJ; 1(B), k  = 1, 2, ... , are independent by hypothesis, the random variables CfJk  o Xk  are 
independent.  • 

2.8  The Fubini theorem 

The definition of the integrals in Eq. 2.42 is also valid for random variables 
defined on a product probability space. The Fubini theorem gives conditions under 
which the integration on the product space can be performed sequentially. 
Let  (Qk, :Fk. Pk),  k  =  1, 2,  be  two  probability  spaces  and  denote  their 
completions by  (Qk. :ik. Pk).  Denote by  Q  = Ql  x  Qz,  :F  = :Ft  x  :Fz,  and 
P  =  Pt  x  Pz  the product sample space,  a-field, and probability measure.  Let 
(:it, Pt),  (:iz, Pz),  and  (:i, P)  be  the  completions  of (:Ft. Pt),  (:Fz,  Pz),  and 
(:F,  P), respectively. The following statement is the Fubini theorem. 

If (a>t, wz)  r-+  X (a>t, wz) is :F-measurable and P-integrable, then 
1. X(a>t, ·)is :iz-measurable and Pz-integrable for each a>t  E  Ql \Nt, Nt  E :Ft. 
and Pt (Nt) =  0. 
2. f02 X(·, wz) Pz(dwz) is :it-measurable and fit-integrable. 
3. The equality 

L X(w)i>(dw) = L1 [L2 

X(a>t,a>z)Pz(dw1)]  P2(dw1) 

(2.56) 

holds.  If in addition X  is positive and either side of Eq. 2.56 exists and is finite 
or infinite, so does the other side and Eq. 2.56 is valid ([40], p. 59). 

Note:  We have seen in Section 2.2.3 that for any probability space (111, Q,  Q) there exists 
a  complete  probability  space  (111, Q,  Q)  such  that  Q  c  g and  Q  =  Q on  Q.  Hence, 

40 

Chapter 2.  Probability Theory 

the  assumption  that  X  is defined  on  a complete probability  space is  not restrictive.  The 
last  statement  of the  theorem considers  the  case in which  X  is  positive but may  not be 
?-integrable, that is, the integral fn  X dP may not be finite.  & 

Example 2.37:  Let X  : ([0,  1]  x  Q, B([O,  1])  x  F) 
(JR,  B)  be a measurable 
function.  The  product measure  space  on  which  X  is  defined  is  endowed with 
the  product measure A x  P,  where A denotes the  Lebesgue measure and  P  is  a 
probability measure on  (Q, F).  It is  common to interpret the first  argument of 
Xastime.  Theintegralx(A,w)  = JAls(X(s,w))ds,A  E  B([O,l]),B  E  B, 
represents the time X(·, w),  w  E  Q, spends in  B  during a time interval A.  The 
expectation ofthis occupation time is  E[x (A, w)]  =  fA  P(X(s)  E  B) ds. <> 

Proof:  The measurable mapping  (s, w)  r-+  X (s, w)  generalizes the time series considered 
in Example 2.25  because the index s  takes values in  [0,  1]  rather than in a countable  set. 
This mapping is a stochastic process (Chapter 3). The function X(·, w), called the sample 
path w of X, is defined on [0,  1] for each w. 

The indicator function,  1s  :  (JR,  B)  --+ ({0,  1}, K), is measurable because B  E  B 

and K  = {0, {0,  1}, {0}, {1}}  so that 

1s oX: ([0, 1] x  n, B([O,  1]) x  :F)  --+ ({0, 1}, K) 

is measurable.  The expectation of the occupation time is 

E[x(A, w)] = £ x(A, w)P(dw) = £ [£ 1s(X(s, w)) ds J  P(dw) 
= L [£ 1s(X(s, w)) P(w)J  ds = L P(X(s)  E  B)ds, 

where we have used Fubini's theorem ([151], Example 5.9.1, p.  153).  • 

Example 2.38:  If X  is  a positive random variable,  its expectation can be calcu-
latedfromE[X] =  ho,oo)  P(X >  x)dx. <> 

Proof: The mapping (x, w)  r-+  1{X(w)>x) is measurable from ([0, oo) x Q, B([O,  oo)) x:F) 
to ({0,  1}, K), where K = {0, {0}, {1}, {0,  1} }.  We have 

P(X >  x) dx =  { 

[ {  1{X(w)>x} P(dw)]  dx 

Jro,oo)  Jn 

{ 
J[O,oo) 
=  {  [ { 

Jn 

1{X(w)>x} dx]  P(dw) =  {  X(w) P(dw) = E[X] 

Jn 

J[O,oo) 

by Fubini's theorem and the equality f[O,oo)  1{X(w)>x) dx =  f[O,X(w)) dx =  X(w). • 

2.9.  Radon-Nikodym derivative 

41 

2.9  Radon-Nikodym derivative 

We will primarily use the Radon-Nikodym derivative to improve the effi-

ciency of the Monte Carlo simulation (Section 5.4.2). 

Let (0, :F) be a measurable space and f.L,  v  : 0-+ [0, oo] be two measures on 
this space. If JL(A)  = 0, A  E  :F, implies v(A) = 0, we say that v is absolutely 
continuous with respect to f.L  and indicate this property by the notation v « f.L. 
If v « f.L  and f.L  « v, v and f.L  are said to be equivalent measures. 

Example 2.39:  Consider a measure space ( 0, :F, f.L)  and a measurable function 
h: (0, 

([0, oo), B([O, oo))). The set function 

v(A) = l h df.L,  A  E :F, 

(2.57) 

is a measure that is absolutely continuous with respect to f.L.  <> 
Proof:  The  set function  v  is  positive by definition.  This function  is countably  additive 
since, for any disjoint sets An  E :F, n = 1, 2, ... , we have 

An) = 100 

h df-1,  = J f h lAn df-1, 

n=l 

Un=lAn 

= f J h lAn df-1,  = f L h df-1,  = f v(An). 

n=l 
The above term by term integration is valid whether 
since h is positive. The measure v is absolutely continuous with respect to f1,  because 

J h  lAn df-1,  is or is not finite 

n=l 

n=l 

n 

}A 

wEA 

}g 

v(A) =  { h df-1,  =  {  h  lA df-1,  ::0  sup (h(w)) fl,(A) 
so that fl,(A) = 0 implies v(A) = 0 with the usual convention 0 · oo = 0 
We also note that if f1,  is a-finite so is  v,  that is, there exists a sequence of disjoint 
events  B j  E  :F such that v(B j) <  oo for every j  and v(B) = 
v(B n B j ), B  E  :F. 
Take  Bj  ={wE !J: j  -1 ::0  h(w)  <  j} E :F and note that Vj(A)  =  fA(h lBj)df-1, is 
finite for each j  and A  E  :F such that fl,(A)  <  oo.  Also, Vj(A) is bounded by j  fl,(A). The 
monotone convergence theorem for the  sequence of measurable,  increasing,  and positive 
functions  Xn = LJ=l h lBj gives (Eq. 2.47) 

}A 
The left and the right sides of this equation are 

}A 

lim  {  Xndf-1, =  { (lim  Xn)  df-1,. 

lim  tJhlB.df-1,=-f  {  hlBdfl,=i:vj(A)  and 

JA 

j=l 

1 

j=l 

A 

1 

. 

j=l 

L c;hlsj) 

•(A), 

42 

Chapter 2.  Probability Theory 

respectively, so that v is a-finite.  • 

The Radon-Nikodym theorem can be interpreted as  the converse of Ex-

ample 2.39. The statement of this theorem is given in Eq. 2.58 without proof. 
If J-t  and v are a -finite measures on a measurable space (!>2, :F) such that v « J-t, 
then there exists a measurable function 

dv 

h = - : (!>2,  F)-+ ([0, oo), B([O, oo))), 

(2.58) 

called the Radon-Nikodym derivative of v with respect to f.t,  such that Eq. 2.57 
holds ([66], Theorem 18, p.  116). 

Example 2.40:  Consider  a  probability  space  (!>2, :F,  P),  a  partition  A;  E  :F, 
i  = 1, .. . ,n,ofr>2 suchthatP(A;) >  O,andarandomvariableX = L:7= 1 x;  1A; 
defined on this space, where x;  E  R  Let Q be a probability measure on (!>2,  :F) 
such that Q(A;)  >  Oandh;  =  P(A;)/Q(A;), i  =  1, .. . ,n. Denote expectations 
under the probability measures  P  and Q by E p  and E Q, respectively. The expec-
tations  Ep[X] and EQ[X h]  of the random variables  X  and X h  with respect to 
the measures P and Q coincide. <> 
Proof:  The expectation of X h under Q is 

EQ[X h] = 

n 

i=l 

h;) Q(A;) = L  x; 

n 

(  P(A;)) 

i=l 

Q( 

,) 

Q(A;) = Ep[X]. 

Since both P and Q are zero only on the impossible event 0, the function h is measurable 
and Q is absolutely continuous with respect to  P  on the a -field a (A;, i = 1, ... , n).  The 
function his the Radon-Nikodym derivative of P with respect to  Q.  A 

Example 2.41:  Let X  "' L 1 (!>2,  :F,  P) be a random variable. If Q is a probability 
on a measurable space (!>2, :F) such that P « Q, we have 

Ep[X] =I X dP =I 

dQ =I X hdQ =  EQ[X h], 

(2.59) 

where h  =  d P 1 d Q is  the Radon-Nikodym derivative.  This result extends  our 
discussion in Example 2.40 to an arbitrary random variable. The importance sam-
pling technique uses Eq. 2.59 to improve the efficiency of the Monte Carlo solu-
tion (Section 5.4.2). <> 

2.10  Random variables 

Consider a probability space  (!>2,  :F,  P) and a real-valued random variable 
X  defined on this space (Section 2.4).  This section defines the distribution, den-
sity, and characteristic functions of X, and illustrates the use of these functions in 
calculations. 

2.10.  Random variables 

2.10.1  Distribution function 

43 

The cumulative distribution function or the distribution function of a ran-
dom variable X  is defined by the mapping X  : Q  ---+  ffi.  and the probability mea-
sure P. 
The distribution function of X is 

F(x) =  P(X-1((-oo,x])) =  P({w: X(w) S  x}) =  P(X S x). 

(2.60) 

Note:  F  is  the probability induced by  X  on  (R, B)  and constitutes  a special case of the 
distribution in Eq. 2.29 forB  =  ( -oo, x] and h  =  X. The definition is meaningful because 
X is F-measurable so that {w: X(w) 
x) used in Eq. 2.60 
is an abbreviation for P({w: X(w) 

x}  E  F. The notation P(X 

x}).  & 

The distribution function F has the following properties. 

•  F  is a right continuous, increasing function with range [0,  1]. 
•  F  can have only jump discontinuities and the set of these jumps is countable. 
The number of jumps ofF exceeding£  E  (0,  1) is smaller than 1/£. 
elimx-HXJ F(x) = 1 and limx-*-oo F(x) = 0. 
•  P(a  <  X  S  b)  =  F(b)- F(a)  0:::  0,  a  S  b. 
•  P(a  S  X< b)= F(b)- F(a) + P(X =a)- P(X =b),  aS b. 
Proof:  Since  F  is  a  probability  measure,  its  range  is  [0,  1].  Also,  F  is  an  increasing 
function because {X 
xz (Eq. 2.5).  That F  is right continuous 
follows  from the continuity of the  probability measure  and the  definition of F.  Let { Xn} 
be a decreasing numerical series converging to x,  Bn  = {w:  X(w) 
xn}, and  B  = {w: 
X(w) 
Bn  =  B 
and (Eq. 2.25) 

x}. The sequence of events Bn  is decreasing sothatlirun--* 00  Bn  = 

x1}  s;  {X 

xz} for x1 

lim  F(xn) = 
n-+oo 

lim  P(Bn)  =  P(  lim  Bn) =  P(B) =  F(x). 
n---+oo 

n---+oo 

A function  g  :  I  -+ R  I  c  R,  is discontinuous at c  E  I  if it is not continuous at 

this point. The discontinuity of g at c can be of four _types: 
(a) Infinite discontinuity if the left limit limxtc g(x) and/or the right limit limx,j,c g(x) of 
g at c is infinity. 
(b) Jump discontinuity if the left and right limits of g at c are finite but not equal. 
(c) Removable discontinuity if limx-+c g(x) exists and is finite but differs from the value 
of gat c. 
(d)  Oscillating discontinuity if g is bounded and the left and right limits of g  at c do not 
exist. 

F  can have only jump discontinuities because it is a bounded, increasing, and right 
continuous function.  We  need to  show  that  F  has  at most a  countable  number of jump 
discontinuities. 
be two distinct jump points ofF and consider the open intervals 
It;  = 
), F(()) associated with these jumps. Because the 

< 
and It;'  = 

E 

44 

Chapter 2.  Probability Theory 

showing that 
since each /1;  contains a rational number and the set of rational number is countable. 

are disjoint intervals. The collection of the intervals 

and 

is countable 

= 

::::  1 so that n8 

:::: 
::::  1/8, 

The sum of all jumps ofF is 

1, where J denotes the collection of jump points of F. Hence,  8  n8 
where n8  denotes the number of jumps of F  larger than 8. 

The third property results from the equalities 
lim  P(( -oo, x]) = P(!J) = 1  and 

lim  P(( -oo, x]) = P(0) = 0. 

The fourth property follows  from the equality  P(B \  A)  =  P(B) - P(A), which 
holds since the event A= {w: X(w)  ::::a} is included in B = {w: X(w):::: b}  for a:::; b. 
The last property holds because the event {a  ::::  X  <  b} is the union of the disjoint 
events {X  = a}  and {a  <  X  ::::  b}  \{X = b}  so that the probability of {a  ::::  X  <  b}  is 
P(X = a) +  P({a  <  X  :::;  b}  \  {X  = b}),  and  P({a  <  X  :::;  b}  \{X = b})  is equal to 
P(a  <  X  ::::  b) - P(X =b) .• 

Example 2.42:  Consider the system in Example 2.14 and let F denote the distri-
bution of the system strength X.  The system reliability without and with a proof 
test at Xpr  is  Ps(X)  = 1- F(x) and  Ps(x)  = (1- F(x  V Xpr))/(1- F(xpr)). 
respectively. 

Figure 2.4 shows the system reliability disregarding and accounting for the 

0.8 

0.6 

Reliability with 
proof test 

0.4  Reliability 

without proot test 

I 

0.2 

00 

X pr 

2 

3 
X 

4 

6 

Figure 2.4. Reliability with and without proof test information 

information provided by a proof test at x pr  = 2 for a lognormal random variable 
X  = exp(Y),  where  Y  is  a  Gaussian  variable  with mean JL  =  1 and  variance 
a 2  = 9 (Eq. 2.68).  The figure  suggests that the additional information provided 
by the proof test can be beneficial in practical applications. ¢ 

Example 2.43:  Let  F  be the  distribution of a random variable  X  defined on a 
probability space  (Q, :F, P).  The distribution  F  is continuous at x  E  lR  if and 
only if P({X =  x}) =  0.  ¢ 

2.10.  Random variables 

45 

Proof: Let {xn} be a positive sequence such thatxn  -J,  0 as n--...  oo.  Define the sequence of 
intervals An = { w  E  r.l  : X (w)  E  (x- Xn, x]} for x  E  R.  Since this sequence is decreasing, 
we have  P({X = x}) = P 
An)= limn--+oo  P(An) and  P(An) = F(x)- F(xn)· If 
F  is continuous at x, then F(x)- F(xn)  --...  0 as n--...  oo so that P({x}) = 0.  Conversely, 
if P({X = x})  = 0, we have limn--+oo[F(x)- F(xn)l = 0 so that F  is  continuous at x 
since it is right continuous.  • 

2.10.2  Density function 

Consider a distribution function F  that is absolutely continuous in IR,  that 
is, there exists an integrable function  f, called a probability density function or a 
density function, such that Eq. 2.61 is satisfied. 
The density function f  is an integrable function such that 

F(b)- F(a)  = ib f(x)dx, 

a  :S:  b. 

(2.61) 

= F(x). 
0 because F  is an increasing function. 

The density function has the following properties. 
•  j(x) = F'(x) so that 
• f 
• f  is not a probability measure. 
•  The area under f  is 

f  (x) dx =  1. 

Consider a random variable X defined on a probability space (Q, :F,  P) and 
Then Y =  go X is a random variable 

a measurable function g  : 
-+ 
defined on (Q, :F,  P) (Section 2.4.3). 

If X  andY =go X  are integrable and Q(B) =  P(X- 1 (B)), B  E  B, then 

E[Y] =In Y(w) P(dw) =In g(X(w)) P(dw)  and 
E[Y] = l g(x) Q(dx) = l g(x) dF(x) = l g(x) f(x) dx. 

(2.62) 

(2.63) 

Proof:  If g  = lB, B  E  B, then Eqs.  2.62 and 2.63  give E[Y] = P(X E  B) = Q(B). If I 
is a finite index set and g  = LiEf bi  lBi, the subsets B;  E  :F partition JR,  and bi  are real 
constants, then Eqs. 2.62 and 2.63  give LiEf bi P(B;) because the integration is a linear 
operator. 

If g  is  an  arbitrary  positive Borel function,  there  exists  a sequence  of simple,  in-
creasing,  and  measurable  functions  gn,  n  =  1, 2,  ... , converging  tog as  n  --...  oo.  We 
have seen that the  expectations  of gn (X)  in Eqs.  2.62  and  2.63  coincide.  The monotone 

46 

Chapter 2.  Probability Theory 

convergence theorem shows that the expectations of g(X) in Eqs.  2.62 and 2.63  coincide. 
If g is an  arbitrary Borel function,  it can be represented by g  = g+  - g-, where g+  and 
g- are positive Borel functions.  Because g(X) is integrable and the expectation is a linear 
operator, the formulas in Eqs. 2.62 and 2.63 give the same result. 

That Eqs.  2.62  and  2.63  give  the  same  result can  be  indicated  by  Ep[g  o  X]  = 
EQ[g], where  Ep  and  EQ  denote expectations under the probabilities  P  and  Q,  respec-
tively.  We  note  that the probabilities  P  and  Q live  on different  measurable spaces,  P  is 
defined on  (Q, :F) while  Q is the probability measure induced by X  on (R, B) (Eq. 2.29). 
Generally, the last two formulas  in Eq.  2.63  involving Riemann-Stieltjes and Riemann in-
tegrals are used to calculate E[Y]. • 

Example 2.44:  The expectation of the Cauchy random variable  X  with density 
f(x)  =  aj[;rr  (a2 + x 2)], a  >  0, x  E  JR.  does not exist.<> 
Proof:  The expectation of x+ is (Eq.  2.63) 

E[X+] = E  [lx>O X]  =  { 00 x 

-

lo 

2a 

n  (a  + x  ) 

2  dx = 

log(a2 + x2)  IQ"=  +oo. 

2 n 

Similarly, E[X-] is infinity.  Hence, E[X] is not defined.  • 

Example 2.45:  Let g  :  (JR,  B)  ---+  (JR,  B)  be a measurable function and  X  be a 
random variable  defined  on a probability space  (Q, :F,  P).  The expectation of 
the  random variable  g(X)  can  be  calculated by the  last integral in  Eq.  2.63  or 
Ef[g(X)]  =  Eq [g(X) f(X)jq(X)],  where  q  is  a probability density  function 
Iq  =  {x  E  lR  :  q(x)  >  0}.  The 
such  that  If  =  {x  E  lR  :  f(x)  >  0} 
expectations E f  and Eq  correspond to  f  and q, respectively. The requirement on 
the subsets Iq  and If of lR  is consistent with the absolute continuity condition for 
the existence of the Radon-Nikodym derivative (Eq. 2.58). <> 
Proof: The expectation of g(X) is 

E j[g(X)] =!,  g(x) f(x) dx =!,  [g(x)  f(x) J q(x) dx, 

Iq 

q(x) 

It 

where the last equality holds  since  f  is  zero  in  Iq  \  If.  The integral  on  Iq  is well de-
fined because q is strictly positive on Iq,  and gives the expectation of the random variable 
g(X) f(X)jq(X) with respect to the density function q.  • 

Example 2.46:  Let X be a random variable with density f. It is assumed that the 
expectation of X and of all functions of X considered in this example exist and are 
finite.  Let X;, i  =  1, ... , n, be independent copies of X.  The classical estimator 
X= (ljn) I:7=1 X;  of E[X] has mean E[X] and variance Var[X]/n. The impor-
tance sampling estimator of E[X] is  Xis  =  (1/n) I:7= 1 X;  f(X;)/q(X;), where 
q  is a density such that q(x) = 0 implies  f(x)  = 0.  The mean and variance of 
Xis  are E[X] and Var[X  f(X)/q(X)]jn, respectively. 
The  success  of the  importance  sampling  technique  depends  on  the  func-
tional form  of q.  For example,  E[X]  =  1/2 and Var[X]  = 0.05 for  a random 

2.10.  Random variables 

47 

variable X with density f(x) = 6x (1-x) 1 [O,IJ(X).  The variance of Xis is 0.0929 
and 0.0346 for q(x) = 1 [O,IJ(x)  and q(x) = (20/7) x 1[o,0.7l + [2- (20/3)(x -
0.7)] 1(0.7,1]•  respectively.  This shows that Xis may or may not be superior to  X 
depending on q. ¢ 

Note:  The importance  sampling technique in this  illustration is  a special case of Exam-
ple 2.45 for g(x) = x.  If we set q(x) = x  f(x)/ E[X], the variance of Xis is zero.  How-
ever, this estimator cannot be used because it depends on E[X], that is, on the parameter to 
be estimated.  A 

2.10.3  Characteristic function 

Let X be a real-valued random variable with distribution F and density f. 

Define acomp1ex-valuedfunction g(x, u) = exp (.J=I ux), u, x  E  R 
The characteristic function of X is 

cp(u)  =  E [eAux] = k eAux dF(x) = k eAux f(x) dx. 

(2.64) 

Note: We define the expectation for real-valued random variables and eA u X is complex-
valued.  The  expectation  of eA u X  is  complex-valued  with  real  and  imaginary  parts 
E[cos(u X)] and E[sin(u X)], respectively.  A 

Example 2.47:  The characteristic function exists for any random variable.  For 
example,  the  characteristic  function  of the  Cauchy  random variable  in  Exam-
ple 2.44 is  cp ( u)  = exp( -a I u I),  u  E  R  We  have seen that the expectation of 
this random variable does not exist. 
The moment generating function, m(u) = E[exp(u X)], u  E  R  is  also 
used in calculations.  However, m(·) may not be bounded, for example, the mo-
ment generating function of a Cauchy random variable. ¢ 

2.10.3.1  Properties 

•  lcp(u) I ::::  cp(O)  =  1. 
•  cp( -u) =  cp(u)*, where z* denotes the complex conjugate of z E  C. 
•  The characteristic function is positive definite. 
•  The characteristic and the density functions are Fourier pairs. 
•  cp  is uniformly continuous in R 
elf X  E  Lq, then cp  E  Cq(JR)  andcp(k)(O)  =  (.J=T)k E[Xk], k  =  1, ... , q. 

48 

Chapter 2.  Probability Theory 

Proof: Eq. 2.64 gives rp(O)  =  1,  lrp(u)l  =  IJ eR ux f(x) dxl  ::'0  J leR uxl f(x) dx  = 
1, and rp(u)  =  rp(-u)*. 

Let Z  =  Lk=l Zk  exp(.J=T Uk  X) be a random variable.  Because Z Z*  =  IZI 2 is 

a positive random variable for any Zk  E  IC  and uk  E  JR, 

0 ::'0  E[Z Z*] = L  Zk z/ E  [eR (uk-uz) X]=  L  Zk z/ rp(uk- UJ), 

n 

n 

k,l=l 

k,l=l 

so that rp  is positive definite. 

For the fourth property we need to show that 

rp(u)=  [  eRux f(x)dx  and  f(x)=-1-

[  e-Ruxrp(u)du. 

(2.65) 

lJR 

2TC  lJR 

The  first  equation  is  the  definition  of the  characteristic  function.  The  second  equation 
follows from the fact that, if fJ  : lR  -+ <C  is a continuous, positive definite function such that 
{J(O)  =  1 and J lfJ(u)l du  <  oo, then fJ  is  a characteristic function  of a distribution  F  on 
lR that is absolutely continuous with respect to the Lebesgue measure and has a continuous 
density f  given by ([66], Theorem 14, p.  231) 

It can also be shown that the  characteristic function  defines  uniquely  the density  and the 
distribution of X ([66], Theorem 3, p. 211) and that 

f(x) = -1-

[  e-Rux {J(u)du. 

2 TC  lJR 
1' e-Ruxz _  e-Rux1 

,--, 

-v-lu 

F(x2) - F(xl) =  -

1 
2:rc  r---+oo  -r 

lim 

rp(u) du, 

(2.66) 

where and x1 and x2  >  x1 are points of continuity ofF ([142], Theorem 3, p.  12). 

To prove that rp  is uniformly continuous in JR,  we have to show that for an arbitrary 
rp(u)l  <  s if lhl  <  8 for all u  E  R  The 

s  >  0 there exists 8  >  0 such that  lrp(u  +h) -
increment of the characteristic function in ( u, u + h) satisfies the inequality 

lrp(u  +h)- rp(u)l  =  JE[eR<u+h)X]- E[eRux]l 

::'0  E  [JeRux (eRhx _  1)J]  ::'0  E  [JeRhx -lJ] 
=  f 

JeRhx- 11  dF(x) +  [ 

JeRhx- 11  dF(x) 

Jlxl>a 

Jlxi:'Oa 

for any a  >  0.  The first integral is  smaller than 2 P(IXI  >  a).  We can take a  sufficiently 
large such that P(IXI  >  a)  <  sj4.  The second integral can be made smaller than s/2 for 
the  selected value  of a  by taking  lh I smaller than a real  8  >  0  that is independent of u. 
Hence, the increment  lrp(u  +h)- rp(u)l  of the characteristic function does not exceed an 
arbitrary s  >  0 provided that lh I <  8 irrespective of the value of u. 
The proof of the relationship between rp(k) (u)  = dkrp(u)jduk  and moments of X 

can be based on the inequalities ([151], p. 298) 

eRx- L (v-lx) 

,--, 

n 

k 

k=O 

k! 

lxln+l 
< - - -
(n + 1)! 
-

and 

21xln 
< - -

n! 

2.1 0.  Random variables 

49 

For example, suppose that X 

L1  and consider the difference 

The latter expectation is finite because 

I R 
e 

u 

xlleHhX -1-FfhXI 

h 

:::0:  21XI  E  L1 

by the second inequality with n  =  1 and x  replaced by h X. The first inequality gives 

eRhx -1- Ffhxl 
l
<--=h-----+0 
-
, 

h2 x2 
2h 

x2 
2 

h 

ash-!- 0, 

so that 

lirulcp(u + 

cp(u)- E [ n  X eRuxJI = 0 

by dominated  convergence.  Hence,  we  have  dcp(u)jdu  =  E[.J=IxeRuxl so  that 
cp1(0) = Ff E[X]. Higher order moments can be found in the same way.  • 
Example 2.48:  Let X  be a random variable with characteristic function q;.  The 
characteristic function of a X+ b is ({JaX+b(u)  =  q;(a u) eHub, where a and b 
are constants. <> 
Proof:  The characteristic function of a X+ b is E[exp(.J=T u(a X+ b))] by Eq. 2.64 or 
E[exp(Ff u a X)]  exp(Ff u b).  • 

Example 2.49:  Let X be a random variable with the distribution function F (x) = 
LiEf Pi 1[xi,oo)(x), where I  is  a finite  index set,  Pi  :=::  0  such that LiEf p;  =  1, 
and {x;}  is  an increasing sequence of real numbers.  The density and the charac-
teristic functions,  f(x)  =  LiEf p; 8(x  -Xi) and q;(u)  =  LiEf p;  [cos(u Xi) + 
A 
sin(u x;)], of X  are Fourier pairs.  The characteristic function consists of a 
superposition of harmonics with amplitudes  p;  and frequencies  coinciding with 
the locations x;  of the jumps ofF. <> 

Example 2.50:  Let  X  be a  real-valued random variable on a  probability space 
(Q, :F, P) andY= g(X)  =  xr, where r  :=::  1 is  an integer.  Because g(x) =  xr 
is a continuous function, it is Borel measurable and Y =  X r  is a random variable. 
Lr (Q, :F,  P), the expectation of Y  exists and is  finite.  The moment of 
If X 
order r  of X  is 

f.L(r)  =  E[Xr] = l: xr dF(x) = l: xr f(x) dx. 

(2.67) 

t.L(1)Y  and g(x)  =  lx- f.LClW  are  considered, 
If the functions  g(x)  =  (x  -
the resulting expectations define the central moments of order r  and absolute 

50 

Chapter 2.  Probability Theory 

central moments of order r  of X.  The moments f.L  = JL(1),  a 2  = E(X- JL)2, 
v  =  afJL,  Y3  =  E[(X- JL)3]ja 3, and Y4  =  E[(X- JL)4]ja4 are called mean, 
variance,  coefficient of variation,  coefficient of skewness,  and coefficient of 
kurtosis,  respectively.  These  moments  can be calculated  by  direct  integration 
(Eq.  2.67)  or from  cp (r) (0)  =  ( RY E[Xr].  The  positive  square  root of the 
variance is called standard deviation and is denoted by a. <> 
Example 2.51:  A  random variable  X  is  said to  be  Gaussian  with mean  f.L  and 
variance a 2, in short X  N (JL,  a 2), if it has the density 

f(x)  =  - - exp  -- - - , 

[  1(X-JL)

1 

X  E  JR. 

(2.68) 

2

] 

,J2ii a 

2 

a 

The skewness and kurtosis coefficients of X  are Y3  =  0 and Y4  =  3.  The skewness 
coefficient is zero because f  is symmetric about x  =  f.L. 

The random variable X follows a gamma distribution with parameters k  > 

0 and A >  0 if it has the density 

f(x)  = 

xk-1 A k e-A.x 

r(k) 

, 

x:;::  o. 

(2.69) 

r(k, A),  are 

The first  four  moments  of this  random variable,  denoted by  X 
JL  =  kjA, a 2  =  kjA2 ,  Y3  =  2/ -Jk,, and Y4  =  3(1 + 2/ k). 

The characteristic functions of the random variables with densities given by 

Eqs. 2.68 and 2.69 are 

cp(u)  =  exp ( ,J=l f.L u-

u2) 

cp(u)  =  (1  - J=T ujA)k 

1 

for  X"' r(k, A). 

(2.70) 

(2.71) 

Figure 2.5  shows the  density and the characteristic functions  of a gamma and a 
Gaussian random variable with mean  f.L  =  1.5  and variance  a 2  =  1.  Because 
these densities are not even functions, their characteristic functions are complex-
valued.<> 
Example 2.52:  Let N  be a discrete random variable taking values in {0,  1, 2, ... } 
with the probability 

P(N =  n) = - e-:A, 

An 
n! 

n  =  0,  1, ... , 

(2.72) 

where A >  0 is an intensity parameter. The probability measure in Eq. 2.72 defines 
a Poisson random variable. The characteristic function of X  =  a N  + b is 

(2.73) 

where a and b are constants. The random variable X  is referred to as Poisson with 
parameters (a, b, A).  <> 

2.1 0.  Random variables 

51 

f(x) 

0.5 

0 
-3 

0.5 

0 

-0.5 
-4 

0 

-1 
-4 

-2 

-1 

0 

2 

3 

4 

5 

9i{!p} 

-3 

-2 

-1 

0 

2 

3 

S{<p} 

-3 

-2 

-1 

0 

2 

3 

X 

6 

u 

4 

u 

4 

Figure 2.5. The density and characteristic functions of a gamma and a Gaussian 
variable with the same mean and variance 

Note: The characteristic function of N  is (Eq. 2.64) 

fPn(u)  =  E  [eAuN] =  L eAuk 

oo 

= exp [ ')..  (eA u - 1) J. 

k=O 

k 

k. 

e-J...  =  e-J...  L 

k=O 

oo  (')..eAut 

' 

k. 

This function  and  fPx(u)  = exp(Hub)cpn(ua) give  Eq.  2.73,  where  fPx  denotes  the 
characteristic functions of X. • 
Example2.53:  Let Nj,  j  = 1, .. . ,m, be  independent Poisson variables  with 
intensity parameters AJ  >  0.  The characteristic function of the random variable 
X  =  I:j=1 x 1 N1 is 

where xi are real numbers. <> 
Proof: We have cp(u)  = E [eA uX] = IT}=I  E [eA uxj Nj]  by the independence of 
the random variables Nj.  The result in Eq. 2.74 follows from this expression and Exam-
ple2.52. • 

(2.74) 

52 

Chapter 2.  Probability Theory 

Example 2.54:  Let X be a compound Poisson random variable defined by 

N 

X = L Yk 

k=l 

for N  >  0  and X  = 0 for N  = 0, 

(2.75) 

where N is a Poisson variable with intensity A.  >  0 (Eq. 2.72) and Yk. k = 1, 2, ... , 
are independent copies of Y 1·  The random variables Yk  are independent of N.  The 
characteristic function of X is 

rp(u)  =  exp (-A l (1- eR"Y)dFy(y)), 

(2.76) 

where Fy  denotes the distribution function of Y 1·  <> 
Proof:  We have 
rp(u) = E [eRux 

{ E [.Q ,v'=T•Y•  1 N]) +P(N 

+e.J=Iux 1(N=O}J  = E [eRu 'Lf=l Yk J + P(N = 0) 

00 

= L 

k=l 
= LJ 
k=O 

P(N = k) + P(N = 0) 

(A. qiy(u))k  A 

k! 

e- = exp[-A. (1- qiy(u))], 

where rpy  denotes the characteristic function of Y1.  The expression of rp  in Eq. 2.76 is an 
alternative form of the above result.  • 

2.10.3.2  Infinitely divisible characteristic function 

Let X be a random variable with characteristic and distribution functions rp 

and F, respectively. 

If there is a characteristic function (/)n  for every integer n  :=::  1 such that 

rp(u) = (rpn(u)l,  u  E  JR, 

(2.77) 

then rp  is said to be infinitely divisible (i.d.). 

Note:  This  definition  shows  that a random variable  X  with  an  infinitely divisible  char-
acteristic function  has the representation  X  = L?=l 
1,  where  x}n), 
i  = 1, ... , n, are independent identically distributed (iid) random variables with the char-
acteristic function (/Jn.  A 

for each n 

Example 2.55:  The characteristic function of X  ,.....  N(f.L, a 2 )  is infinitely divisi-
ble.<> 

2.1 0.  Random variables 

53 

Proof:  The characteristic functions  ({Jn (u)  = exp ( J=T JJ, u In - u2 u2 I (2 n))  and <p  in 
Eq. 2.70 satisfy Eq. 2.77 for each n. Hence, X  can be represented by a sum of n independent 
Gaussian variables with mean JJ,In  and variance u 2 ln. • 

Example 2.56:  Let N  denote a Poisson random variable with intensity A >  0 and 
let a, b be some constants (Example 2.52). The characteristic function of aN+ b 
is infinitely divisible. ¢ 
Proof:  <fJn(u)  = exp (CAin) (eRau -1) + J=T (bin) u) and<p inEq. 2.73 satisfy the 
condition <p  = (<pn)n  for any n  :::=:  I  integer.  Hence, a Poisson variable X with parameters 
(a, b, A)  can be represented by a sum of n independent Poisson variables with parameters 
(a, bin, A In) for each n (Example 2.52).  • 

Infinitely divisible characteristic functions are encountered in the analysis 
of the Brownian motion and other processes with stationary independent incre-
ments introduced in the next chapter and used extensively in this book. We review 
here essential properties, methods of construction, and canonical representations 
of infinitely divisible characteristic functions. 

Properties of i.d. characteristic functions. 

If rp  is an i.d. characteristic function, then rp  has no real zeros, that is, rp(u)  =j:.  0 
for every u  E  IR  ([124], Theorem 5.3.1, p. 80). 
Proof:  This property can be used as a criterion for finding whether a particular character-
istic function is not infinitely divisible.  For example, the characteristic function in Exam-
ple 2.49 is not infinitely divisible. 

If <p  is infinitely divisible,  there exist characteristic functions  ({Jn  = <plfn  for each 
integer n  >  0 so that g(u) = liiDn--+oo <fJn(u)  = liiDn--+oo(<p(u)) 1fn takes only two values, 
zero for <p(u)  = 0  and one for <p(u)  I  0.  Because <p  and ({Jn  are characteristic functions, 
there is an interval  I  c  R  containing zero in which both <p  and ({Jn  are not zero  so that 
log(<pn(u))  = (lin)  log(<p(u)), u  E  I.  The right side of this equation approaches zero as 
n --+  oo so that <fJn (u)  --+  1, u  E  I, as n increases indefinitely. 
The  function  g  is  a  characteristic  function  as  a  limit  of characteristic  functions 
([124], Chapter 3), can be either zero or one, and g(u) = 1 for u  e  I.  Hence, g(u) = 1 
everywhere by the continuity of the characteristic function so that <p(u)  I  0, Vu  E R.  • 

Finite products of i.d.  characteristic functions  are i.d.  characteristic functions 
([124], Theorem 5.3.2, p. 81). 
Proof:  Let <fJb k  =  1, ... , q, be i.d.  characteristic functions so that <fJk  =  (rpk,n)n, n  2:  1, 
where  rpk,n  are  characteristic  functions.  The function  rp  = Tik=l rpk  is  a  characteristic 
function as a product of characteristic functions and 

rp(u)  = Ii rpk(U)  = n[(/Jk,n(U)]n = [n rpk,n(U)]n = rpn(u)n 

k=l 

k=l 

k=l 

for any n  2:  1, where rpn  = Tik=l rpk,n·  Hence, <pis infinitely divisible.  • 

54 

Chapter 2.  Probability Theory 

If cp  is an i.d. characteristic function so is lcp I ([124], Corollary to Theorem 5.3.2, 
p. 81). 

Proof:  The function  lcp(u)l 2  = cp(u) (cp(u))*  = cp(u) cp(-u) is an i.d.  characteristic func-
tion by the previous property so that  (lcp(u)l2) 1/(2 n)  =  lcp(u)l 1/n is a characteristic func-
tion for each integer n  >  0.  • 

A  characteristic  function  that  is  the  limit  of a  sequence  of i.d.  characteristic 
functions is infinitely divisible ([124], Theorem 5.3.3, p.  82). 

If cp  is an i.d. characteristic function, cp 01  is a characteristic function for each real 
number a  >  0.  The converse is  also true ([124],  Corollary to Theorem 5.3.3, 
p. 82). 

Example 2.57:  The characteristic function  of X  ,.....,  N(O,  1)  is  cp(u)  =  e-u212 . 
We have seen in Example 2.55 that cp  is infinitely divisible.  This function has no 
real  zeros consistent with a property of i.d.  characteristic functions.  The func-
tion cp(u) 01  =  e-u20112 ,  a  >  0,  is  also  an i.d.  characteristic function because it 
corresponds to the variable N(O, a), a result consistent with the last property. <> 

Construction of an i.d. characteristic function. 
If g : lE.  -+  C is a characteristic function and p  >  0 denotes a real number, 

cp(u)  =  exp {p [g(u)- 1]}, 

u  E  JE., 

(2.78) 

is an i.d. characteristic function ([124], Lemma 5.4.1, p 83). 

Note:  This fact  can be used to  construct infinitely divisible  characteristic functions.  For 
example, the characteristic function in Eq. 2.73 with b =  0 can be obtained from Eq. 2.78 
with p  =  J...  and g(u) =  exp(H au), a  E  JR.  .& 

A characteristic function cp  is infinitely divisible if and only if 

cp(u)  = 

lim  exp[pn (gn(u)- 1)], 
n--+oo 

(2.79) 

where Pn  >  0  are real numbers and gn  denote characteristic functions  ([124], 
Theorem 5.4.1, p. 83). 

The limit of a sequence of finite products of Poisson type characteristic functions 
is an i.d. characteristic function.  Moreover, every i.d. characteristic function can 
be written as the limit of a sequence of finite  products of Poisson type charac-
teristic functions ([124], Theorem 5.4.2, p. 83). 

2.1 0.  Random variables 

55 

Proof:  We only prove the stated representation of i.d. characteristic functions. 

Suppose that q>  is an i.d. characteristic function.  According to the previous theorem, 
we have q>(u)  = liiiln--+oo exp[pn (gn(u)- 1)], where  Pn  >  0 and gn  are characteristic 
functions.  Take gn(u)  = f"M. eA ux dGn(x)  in Eq. 2.79,  where Gn. n  = 1, 2, ... , is a 
collection of distributions.  For a  >  0 consider a partition -a = ao  :::;  a1  :::;  · · · :::;  am  = a 
of (-a, a) such that maxi (ai  -ai-d --+  0 as m  --+  oo.  The function Pn (gn (u) - 1) can 
be approximated by 

where bk  = Pn  [Gn(ak)- Gn(ak-I)].  For any  a  >  0 the last expression  is the limit 
of a finite product of characteristic functions  corresponding to Poisson random variables 
(Eq. 2.73).  The stated result follows by taking the limit as a --+  oo.  • 

Canonical representations of i.d. characteristic functions. 

Let a  E  JR.  be a  constant,  (J  be a  real-valued,  bounded,  and increasing func-
tion defined on the real line such that 0( -oo) =  0.  If a function IP  admits the 
representation 

log(qJ(u))=v-wu+ 

e- ux-1-

11  1 ( A 

"M. 

.J=T u x)  1 + x2 

1 +x 

x 

2  - -2 -dO(x)  (2.80) 

for all u  E  JR.,  then qJ  is an i.d. characteristic function.  The constant a  and the 
function (J  are uniquely determined by qJ  ([124], Lemma 5.5.1, p. 85). 

Note:  The integrand of the integral in Eq. 2.80 is defined by continuity at x  = 0 so that it 
is equal to -u2 /2 at this point.  A 

If IP  is an i.d. characteristic function, there exists a sequence of functions  n ( u) 
such that limn--+oo 

(u)  =  log(qJ(u)), u  E  lR,  where 

h (A 

"M. 

e- ux-1-

Rux) 1 +x2 
2  - -2 -dOn(X), 
1 +x 
Y 
-00  1 + y 

l x 

x 

On(X)  =  n  - -2  dFn(y), 

(2.81) 

an= n  {  -1  X  2  dFn(X), 

J"M.  +x 

and Fn  denotes the distribution function of qJ lfn ([124], Lemma 5.5.3, p. 88). 

56 

Chapter 2.  Probability Theory 

Levy-Khinchine representation. A function cp  is an i.d. characteristic function 
if and only if log(cp(u)) is given by Eq. 2.80.  The representation is unique and 
the integrand defined at x  =  0 by continuity is  -u 2 /2 ([124],  Theorem 5.5.1, 
p.  89). 
Note:  If the function e has  a jump CY2  =  &(0+)  - &(0-) at X  =  0,  the Levy-Khinchine 
representation can be given in the form 

log(rp(u))=J=lau---+ 

e  -lux_1-

r>2 u2  k  ( R 

2 

IR\{0} 

R  u x)  1 + x2 

2  - -2 -d&(x) 

1 +x 

x 

(2.82) 
for each u E  R because the integrand is -u2 /2 at x  =  0 (Eq. 2.80).  An alternative form of 
this equation is 

log(rp(u))  =  J=l au- - - + 

r>2u2 

(  R 
e  -lux - 1-

.Pux) 
2 
1 +x 

where 

= 

2 

IR\{0} 

I j:_ 00  l+t d&(y) 

- J00  l+y  d&(  ) 
y 

Y 
y2 

X 

2 

for x  <  0, 

for x  >  0. 

(2.83) 

(2.84) 

The function 

is defined  on R  \  {0},  is increasing  in  ( -oo, 0)  and  (0, oo),  satisfies the 
<  oo for any s  > 
0.  The representation in Eq.  2.83  is unique  and is referred to  as the Levy representation 
for the i.d. characteristic function rp.  A 

=  0, and the integral fc-t:,t:)\{O} x 2 

-oo) =  0, 

An alternative version of the Levy-Khinchine representation is 

a2 u2 
log(cp(u))  =  J=T au- - 2 -

+ { 

liR\{0} 

(eRux- 1- J=T u x(x))  AL(dx), 

u  E  R, 

(2.85) 

where x (y)  =  -1c-oo,1J(Y) + y 1(-l,l)(Y) + 1[l,oo)(Y)  and AL  is a Levy mea-
sure, that is, a measure defined on lR \ {0}  such that fiR\{O} (y 2 1\ 1) AL(dy) <  oo 
([66], Theorem 13, p. 299). 

Example 2.58:  The characteristic functions of the Gaussian,  Poisson,  and com-
pound Poisson random variables are special cases of the Levy-Khinchine repre-
sentation given by Eq. 2.85. <> 
Proof:  The Uvy-Khinchine representation in Eq. 2.85 with A£  =  0 gives the characteristic 
function  of a Gaussian  variable  (Eq.  2.70).  The characteristic  function  in Eq.  2.85  with 
r> 2 =  0 and AL(B) =A 1rn(B) 

E R \  {0}, A> 0, and BE B, is 

log(rp(u))  =  J=1 u (a- A xCm +A (eH u 

- 1) 

2.10.  Random variables 

57 

and has the form of the characteristic function for a Poisson variable (Eq. 2. 73). If a2 = 0 
and AL(dx) =A dF(x), A >  0, Eq. 2.85 becomes 

log(rp(u))  =  R  au+).  [ 

JlR'.\(0} 

(eRux- 1- R  u x(x))  dF(x) 

=.J=lau-.J=l).u  [ 

JlR'.\ {0} 

x(x)dF(x)+A  [ 

JJR>.\ {0} 

(eRux_l)dF(x) 

and resembles the characteristic function of a compound Poisson variable (Eq. 2.76).  • 

2.10.3.3  a-Stable random variable 

A random variable X is a -stable if, for any a i  >  0 and independent copies Xi, 
i  =  1 , 2, of X, there exist c  >  0 and b such that 

(2.86) 

that is, c (a1  X 1 + az Xz) + b and X have the same distribution. 
Note:  Because a1  X1 + az Xz and (X- b)jc have the same distribution, Xb k  =  1, 2,  are 
independent copies of X,  and rp(u)  =  E[exp(.J=-1 u X)]  is the characteristic function  of 
X, Eq. 2.86 gives rp(a1  u) cp(az u) = cp(ujc) exp( -Au bjc). 
There are alternatives to the definition in Eq. 2.86.  For example, X  has an a-stable 
distribution if for each n  :::  2 there are two real numbers, en  >  0 and dn, such that L? = 1 Xi 
and en  X+ dn  have the same distribution,  where Xi  are independent copies of X  ([162], 
Definition 1.1.4, p. 3).  A 

We  give here two properties of a-stable random variables that are particu-
larly useful for calculations. An extensive discussion on a-stable random variables 
is in [161,  162]. 

The characteristic function of an a-stable variable is infinitely divisible. 

Proof: Let cp  denote the characteristic function of an a-stable variable X and let X 1, ... , Xn 
denote independent copies of this random variable.  Because X  is an a-stable variable, we 
have L?=1 Xi  if:.  en  X+ dn,  where en  >  0 and dn  are real numbers.  This equality gives 
[rp(u)]n = cp(cn u) eH u dn  or 

rp(u)  =  [cp(ufcn)r e-R u dn/cn 

if we  replace  u  with  ufcn.  We  have  'Pn(u)  =  cp(ufcn)eHudn/(ncn)  and  rp(u)  = 
[ 'Pn (u) ]n.  Hence, cp  is an i.d. characteristic function.  • 

This property shows that the class of a-stable variables is  a subset of the 
class of random variables with i.d. characteristic functions.  Hence, a-stable vari-
ables have all the properties of random variables with i.d. characteristic functions. 
For example, the characteristic functions of a-stable variables have no real zeros. 

58 

Chapter 2.  Probability Theory 

The characteristic function of any a-stable variable has the form 

rp(u)  =  exp{ H 

f.L u- aa /u/a  [1 + R 

{3  sign(u) w(/u/, a)]}, 

(2.87) 

where  w(/u/, a)= 

{  - tan(Jra/2),  a  -::j:.  1, 
(2/.7r) log /u/,  a= 1, 

(2.88) 

f.L,  a 

0, /{3/  ::::  1, 0  <a ::::  2 are real constants ([124], Theorem 5.7.3, p.  102). 

Note:  The characteristic  function  of an  a-stable  random  variable  can be  obtained  from 
Eqs. 2.83 and 2.84 with 

= { Ct  lxl-a 
-c21x1-a 

for x  <  0, 
for x  <  0, 

where ct, c2  2:::  0 are real numbers such that ct  +  c2  >  0 ([124], Theorem 5.7.2, p.  101). 
The integrals 

-oo 

1° (eAux -1- J=I ux)  ___:!:___ 
{ 00  (  Aux  1  J=I ux)  dx 
Jo 

1 +  x2 

lxla+l 

lxla+l 

e 

-

-

1 +x2 

and 

can be calculated for a  <  1, a = 1, and a  >  1 and give Eqs. 2.87 and 2.88. 

The parameters a, f3, a, and !J,,  referred to as stability index, skewness, scale, and 
shift or location, respectively, control the distribution type, the departure from a symmet-
ric  distribution about  !J,,  the  range  of likely values,  and the shift from  zero.  We  use  the 
notation X 
Sa (a, {3,  !J,) to indicate that X is a real-valued a-stable random variable with 
parameters (a, a, {3,  !J,).  The density of an a-stable variable with f3  = 0 is symmetric about 
its location parameter !J,.  6 

Example 2.59:  The  characteristic  functions  of Gaussian  and Cauchy variables 
with parameters S2(1, 0, 0) and St (1, 0, 0) are shown in the left graph of Fig. 2.6. 
The imaginary parts of these characteristic functions are zero.  The right graph in 
the figure shows the real and imaginary parts of the characteristic function, 

1p(u)  =  exp [-lui  ( 1-2 .J=I sign(u) log lu//.7r) J, 

of the Cauchy random variable S 1 ( 1, -1, 0). This characteristic function is comp-
lex-valued since {3  -::j:.  0. ¢ 

2.11  Random vectors 

Let (Q, :F, P) be a probability space and 

(2.89) 

Figure 2.6. Characteristic function of some a-stable random variables 

be a measurable function, that is, x-1(B)  E  :F for every Borel set B  E  Bd. This 
function, called a random vector in !Rd  or IRd -valued random variable, induces 
the probability measure  Q(B)  =  P(X  E  B)  =  P(X- 1(B)),  B  E  Bd,  on the 
measurable space (JRd,  Bd). 

2.11.1  Joint distribution and density functions 

Let B  =  xf+1 ( -oo, xi] be a rectangle in JRd  for Xi  E  R i  =  1, ... , d.  This 

rectangle is in Bd so that x- 1 (B)  E  :F because X  is measurable. 

The joint distribution function of X  is 

F(x) =  P(nf=1 {Xi  :S  xi}),  X=  (x1, ... , Xd)  E 

(2.90) 

The domain and the range of this function are JRd  and [0,  1], respectively. 

The following properties ofF result directly from its definition in Eq. 2.90. 

•  Iimxk--+oo  F(x),  1  :::;  k  :::;  d,  is the joint density of the  JRd- 1-valued random 
variable (X1, ... , Xk-1, Xk+1, ... , Xd). 
elimxk--+-oo F(x) =  0 fork  E  {1,  ... , d}. 
•  The function x k  1-+  F (x) is increasing for each k  E  { 1, ... , d}. 
•  The function Xk  1-+  F(x) is right continuous for each k  E  {1,  ... , d}. 

If F  is such that 

exists, then f  is called the joint density function of X. 

f(x) = 

ad F(x) 

ax1  ... axd 

(2.91) 

60 

Chapter 2.  Probability Theory 

Note:  X  takes values  in the infinitesimal rectangle  xf=l (xi, Xi  + dxi]  with probability 
P ( nf=l {Xi  E (xi, Xi  + dxj]}) 
f(x) dx.  The distribution of one or more coordinates 
of X  can be obtained from the joint distribution or the joint density of X. For example, the 
marginal distribution and marginal density of Xt are  Ft (xt) =  F(xt. oo, ... , oo) and 
ft (xt) = fJRd-1  f(x) dx2 · · · dxa or ft (xt) = dFt (xt)fdxt. respectively. 

Suppose that the last d2  <  d  coordinates of a random vector X  have been 
measured and are equal to z =  (zt •... , za2 ).  Let x<l)  and x<2)  be vectors con-
sisting of the first dt  =  d- d2 and the last d2  coordinates of X. 
The conditional density j012)  of x<l) given x<2)  =  z is 

/ (112)(  (1)  I  ) =  f(x<l),z) 
f<2)(z) 
, 

x 

z 

(2.92) 

where t<i)  denotes the density of X (i), i  = 1, 2, and x (1)  = (xt •... , xa1 ). 
Note:  The definition of the conditional probability P(A I B) in Eq. 2.16 with A= {Xt  E 
(xt, x1 +dxt ], ... , Xa1 E  (xa1, xa1 +dxa1]} and B = {Xa1 +1  E  (zt. Zl +dzt], ... , X a  E 
(za2 , za2 + dza2 ]} provides a heuristic justification for Eq. 2.92. We can view P(A I B) as 
[(f(x<l), z)/ j<2)(z))] dx<1) and gives the probability content of the infinitesimal rectangle 
(X}, X}  + dxt]  X  •••  X  (xaJ. xaJ  + dxaJ]  under the condition x<2)  = z.  For a rigorous 
discussion, see [66] (Section 21.3, pp. 416-417). 

If X  and  Y  are  Jlld -valued random variables  and there is  a  one-to-one corre-
spondence between these variables given by y  = g(x) and x  = h(y), then the 
densities  fx  and /y  of X  and Y are related by 
I ax· I 

/y(Y) = fx(h(y)) 

,  x,yer. 

(2.93) 

Proof: The postulated correspondence implies that the Jacobian 
¥v; 
Yd 

9 
ay1 

a(xt •...• xa) 
o(Yl• · · ·, Yd) 

W, 
Yl 

OXd 
ayd 

is non-zero and finite everywhere. The Jacobian of the inverse transformation has the same 
properties since  iJ(xJ , ... ,xd)  a  J, ... ,  d)  = 1.  Let Dx  be a  neighborhood  of x  E  Ri  and 
Dy  = {q  E  JRd  : 11  = 
y  = g(x).  The equality  P(X  E  Dx)  = P(Y  E  Dy)  can be written as  fvx 
fv  /y(q)dq, and implies 

E  Dx} denote the image of Dx  by the transformation x 

iJ(yJ, ... ,yd)  a XJ, ... ,Xd) 

= 

y 

fx(h(q)) 

{ 
lvy 

171,  ..•• TJd 

dq=  { 
lvy 

/y(q)dq 

2.11.  Random vectors 

61 

by change of variables. The last equality gives Eq.  2.93. 

Suppose now that the mapping y 

x  = h (y) does not have a unique solution. Let 
xis unique in each Av.  The 
{Av} be a partition of the x-space so that the mapping  y 
probability mass of Dy  is equal to the sum Lv fv llvl of the corresponding contributions 
in  the  subsets  A v  of the  x -space,  where  each  term  fv I J v I is  equal  to  the  right  side  of 
Eq. 2.93 for the restriction of the mapping y 

x  = h(y) to Av. • 

Example 2.60:  Let X be a real-valued random variable with a continuous density 
fx  and define Y  =  X2.  The density of Y  is 

/y(y) =  (fx(Y1/2) + fx(-y1f2)) /(ly1f2) 

for y  >  0.  <> 
Proof:  The  mapping  from  y  to  x  is unique  on  A1  =  ( -oo, 0)  and  A2  =  (0, oo)  and 
x  =  h(y)  =  y 112, respectively.  The 
is  given by  y 
contribution of y 
y) = P(-y1f2  <X:::; y1f2) .• 

This result can also be obtained by direct calculations from the relationship P(Y :S 

x  =  -y 112 to  /y is  fx(-y 112) ld(-y 112)jdyl (Eq. 2.93). 

x  =  h(y)  =  -y112  and  y 

Example 2.61:  Let X 1 and X2 be real-valued random variables and define Y  = 
X1  + X2. The density of Y is  /y(y) = fJR  fx(IJ,  y- IJ) d!J.  <> 
Proof: It is convenient to  augment Y  to a vector Y E  JR.d,  which is related to  X  by a one-
to-one mapping.  We take  Y1  =  X1  and Y2  =  Y  =  X1  + X2  so that  13xif3Yjl  =  1 and 
!y Ch Y2)  = fx (Yb 5'2  - Y1 ). The result follows by integration. 

Direct calculations can also be used for solution. From 

we can calculate /y  by differentiation.  • 

2.11.2  Independence 

Consider a family of random variables X;,  i  E  I, defined on a probability 
space  (Q, :F,  P),  where the index set  I  is  finite  or infinite.  We  say that X;  are 
independent random variables  if the a-fields  a (X;)  generated by these random 
variables are independent (Section 2.7.3). 

Example 2.62:  Let X 1 and X 2 be random variables defined on a probability space 
(Q, :F,  P).  Denote by  F  and  F;  the joint distribution of (X 1,  X2)  and the dis-
tribution of X;,  respectively.  If X 1  and X 2  are  independent,  then  F (x 1, x2)  = 
F1 (x1) F2 (x2) for all x1, x2  E R  <> 
Note:  The independence  of X1  and  X2  implies that the a-fields cr(X1)  and cr(X2)  gen-
erated  by  X1  and  X2  are  independent.  Hence,  P(A1  n  A2)  =  P(A1) P(A2)  for  any 
A;  E  cr(X;),  i  =  1, 2.  This  property  implies  F(x1, x2)  =  F1 (x1) F2(x2)  if we  take 
A;= Xl 1((-oo, x;])  E  :F, i  =  1, 2.  _. 

62 

Chapter 2.  Probability Theory 

The following equation gives an alternative definition of independence for 
random variables.  This new definition is equivalent with the above definition of 
independence based  on  the  a-fields  generated by the  coordinates of X  ([151], 
Corollary 4.2.2, p. 94). 

A family of random variables  Xi, i  E  I, is  independent if and only if for all 
finite  J  c  I  ([151], Theorem 4.2.1, p. 94) 

P(Xi  :::;:  Xi, i  E  1) = n P(Xi  :::;:  Xi), 

ieJ 

Xi  E  R 

(2.94) 

Note: If I  = {1, ... , d} is finite, the condition in Eq. 2.94 becomes P(N/=1 {Xi  :::::Xi})  = 
flf=1 P(Xi  :::::Xi), Xi  E R,  or F(x) = flf=t  Fi(Xi), where x  = (x1, ... , Xd),  F  denotes 
the joint distribution of X  = (X 1, ... , Xd), and Fi  is the distribution of Xi.  The indepen-
dence condition F(x) = flf=1 Fi (xi) is also satisfied by all subsets of I  = {1, ... , d}.  For 
example, if we set Xd  = oo, this condition applies to the first d - 1 coordinates of X. If the 
distributions F and Fi  have densities  f  and fi, Eq. 2.94 implies f(x) = flfeJ  fi(xi) . .l 

2.11.3  Characteristic function 

Consider a Borel measurable function  g  :  (JRd, Bd) 

(JRtl,  Bq)  and an 
JRd -valued random variable  X  = (X 1 •... , X d)  defined on a probability space 
(Q, :F, P).  The function g(X) is  measurable from  (Q, :F)  to  (JRq, Bq)  and its 
expectation can be calculated from the following formulas. 

E[g(X]) = l g(X(w)) P(dw)  and 

(2.95) 

E[g(X)] =  {  g(x) Q(dx) =  {  g(x) dF(x) =  {  g(x) f(x) dx.  (2.96) 

Note:  That Eqs.  2.95  and  2.96  give  the  same result can be  shown  by extending  the  ar-
guments used to prove the equivalence of Eqs. 2.62 and 2.63.  The chain of equalities in 
Eq.  2.96 holds  because  Q(dx)  = dF(x)  =  f(x)dx.  If q  = 1,  lli  denote  some  con-
stants, and g(x)  =  "L,f=1 ai xi, then the expectation of g(X) is "L,f=t ai E[Xj] showing 
that expectation is a linear operator.  .l 

The formulas  in Eqs.  2.95  and  2.96 can be extended to  complex-valued 
continuous functions of X, for example, we can take g(X)  =  exp( .J=T uT X), 
where U  = (u 1,  ... , Ud)  E  JRd  and UT denotes the transpose of U. 
The joint characteristic function of X  is 

cp(u)  =  E [e,;=IuT X]  = kd e,;=IuT x dF(x) = Ld e,;=IuT x  f(x) dx. 

(2.97) 

2.11.  Random vectors 

63 

The following properties of cp  are useful for calculations. 

•lcp(u)l:::::  1 for all u  E  JRd. 
•  The joint characteristic and the joint density functions are Fourier pairs . 
• If X  has independent coordinates, cp(u)  =  n%=1 cpk(Uk), where cpk  is the 
characteristic function of X k. 
•  cp  is uniformly continuous. 

Proof: The first property results from the definition of the characteristic function since 

The characteristic and the density functions of X are Fourier pairs related by Eq. 2.97 

and ([62], p. 524) 

f(x) = _1_  {  e-Rurx rp(u)du. 

(27l')d  ]n:(cid:0)_d 

(2.98) 

If the coordinates of the random vector X  are independent, the characteristic func-

tion becomes (Eq. 2.97) 

rp(u) = E [eR uT XJ  =  { d n (eR Uk  Xk  fk(xk) dxk) 

d 

d 

= n E[eRukXk] = n rpk(uk), 

k=l 

ln:(cid:0).  k=l 
d 

k=l 

where rpk(uk)  = E[eR uk xk] is the characteristic function of the coordinate k of X. The 
Fourier transform of rp(u)  shows that the density of X  is equal to the product of the densi-
ties of its coordinates.  Hence, the above equality provides an alternative way of checking 
whether a random vector has independent coordinates. 

For the last property we need to show  that for  any e  >  0 there is 8  >  0  such that 
II  h  II< 8 implies  lrp(u +h) - rp(u)l  <  e, where  II  ·  II  denotes the usual norm in JRd.  The 
increment of the characteristic function from u to u + h is 
lrp(u +h)- rp(u)l  = IE [eR (u+h)T X  - eR uT XJ I 

:S  E  [lepur X  (eRhT X  -1)1] :S  E  [leyCihT X_ 1IJ 
= Lc leRhT x- 11  dF(x) + fv leRhT x- 11  dF(x), 

where  D  =  xf=l [-a, a]  and 0  <  a  <  oo.  The integral on Dc  is smaller than 2 P(X  E 
Dc) so that it can be made smaller than e/2 for a sufficiently large a.  For this value of a, 
the integral on  D  can also be made smaller than e /2 by choosing  an adequate value of 8 
since maxxED I exp(.J=T hT x)- 11  converges to zero as  II  h  II->- 0.  • 

64 

2.11.4  Moments 

Chapter 2.  Probability Theory 

Let X  be an 

and consider the function g(x) = Tif=l xt;, where s; 
is continuous, g(X) is a real-valued random variable. 

-valued random variable on a probability space  (Q, :F,  P) 
0 are integers. Because g 

If X  ""  L 8 ,  that is,  X;  ""  Ls  for each i  =  1, ... , d,  the  moments of order 
s =  "£1=1 s;  of X  exist, are finite, and are given by 

{L(SJ,  ... , Sd)  =  E[g(X)] =  E [fr x:;]. 

z=I 

(2.99) 

Note:  The  characteristic  function  can be used  to  calculate  moments  of any  order of X 
provided that they exist.  For example, 

If the coordinates of X  are independent random variables, the moments of X  can be 

calculated from JL(SJ'  ... 'Sd) = rrt=l E[x:i ].  A 

Moments of any order of a random vector X can be obtained from Eq. 2.99 

by selecting adequate values for the exponents s;. For example, 

(2.100) 

•  Mean of X;: fLi  =  E[Xi] =  fL(SJ,  ... , sd), 
•  Correlationof(X;,Xj)  :r;,J  =E[X;Xj] ={L(SJ, ... ,sd), 
for s i  =  s i  =  1 , Sk  =  0, k =f.  i,  j. 

for s;  =  1, SJ  =  0,  j  =f.  i. 

•  Covariance of (X;, Xj): c;,J  =  E[(X;- {L;)(Xj- Jlj)] =  r;,J  -

fLi  fLJ· 
(2.101) 

Note:  The relationship between c;,j  and r;,j  holds by the linearity of the expectation op-
erator.  If c;,j  = 0 fori  f:.  j, then X;  and  Xi are said to be uncorrelated.  If r;,j  = 0 for 
i  f:.  j, then X;  and Xi are said to be orthogonal. If Jli  = tL i  = 0, the coordinates X;  and 
Xi of X  are uncorrelated if and only if they are orthogonal.  A 

It is common to list the means,  correlations, and covariances of the coor-
dinates of X  in vectors and matrices.  We view all vectors as  column vectors and 
denote  the  transpose  of a  vector a  by aT.  The  mean  vector,  the  correlation 
matrix, and the covariance matrix of X  are, respectively, 

/L  =  {tL;}  =  E[X], 
c =  {ci,J} =  E[(X- /L)(X- /L)T]. 

r  =  {ri,J}  =  E[X XT], 

and 

(2.102) 

2.11.  Random vectors 

65 

The pair (JL,  r) or  (JL,  c)  gives the second moment properties of X.  A  short 
hand notation for these properties is X 
(JL,  r) or X 
(JL,  c). The information 
content of (JL,  r) and (JL,  c) is equivalent (Eq. 2.101). 

The correlation coefficient of Xi and X 1 is 

(2.103) 

The correlation coefficient Pi,J  has the following remarkable properties. 

•IPi,JI:::::  1. 
•  Pi, 1 =  ± 1 if and only if Xi and X 1 are linearly related. 
• If Xi  and X 1 are independent, Pi,J  =  0.  The converse is not generally true. 

Proof:  These properties can be obtained from classical inequalities discussed later in this 
chapter or by direct calculations as  shown here.  Let Xi  = (Xi  - Mi)/ui denote a scaled 
version of X; with mean zero and variance one.  Because E[(Xi ±X j )2]  = 2 (1 ±Pi,}) 
0, 
we have  IPi,J I ::::  1. 

If a, b are  constants  and  Xi  = a X 1 + b,  then Pi,}  =  ±1 results by direct calcu-
lations.  If Pi,}  =  ±1, we have  E[(Xi =F  X 1 )2]  =  0.  One of the inequalities in the next 
section shows that the last equality implies that xi - X j  = 0 a.s.  so that xi  and  X j  are 
linearly related a.s. (Example 2.65). 

If Xi  and X 1 are independent, we have 

E[(Xi-Mi)(Xj-Mj)]=  { 1JR2 

= E[Xi- p.,;] E[Xj- Mj] = 0, 

because the joint density f  of (Xi, X J) is equal to the product of the densities of Xi  and 
X J.  Generally, the converse of this property is not true.  For example, let Xi be a Gaussian 
random variable with mean zero and variance one and let Xj  = xf.  These variables are 
uncorrelated because E[Xi (Xj- 1)]  =  E[Xf- X;]= 0 and  Xi  has zero odd moments. 
However,  X;  and Xi are not independent since x1 is perfectly known if X; is specified.  • 

2.11.5  Gaussian vector 

Let X  be an JRd -valued random variable with mean JL  and covariance matrix 
c.  This vector is Gaussian with mean JL  and covariance matrix c if its density and 
characteristic functions are given by Eqs. 2.104 and 2.105, respectively. 

66 

Chapter 2.  Probability Theory 

f(x) =  [(2:n')d det(c)r112 exp [ 

/L)T c-1 (x- /L) J  and 

<p(u)  =  exp (RuT /L-

c u). 

(2.104) 

(2.105) 

Note:  The functions f  and rp  are defined on JRlf  and are real and complex-valued, respec-
tively. If the covariance matrix c is diagonal, the coordinates of X are not only uncorrelated 
but also independent because the joint density of X  is equal to the product of the marginal 
densities of this vector. Hence, the independence and the lack of correlation are equivalent 
concepts for Gaussian vectors. 

To indicate that X  is an !Rd -valued Gaussian variable with second moment proper-
N(p,, c) if there can be no confusion about 

ties (p,, c), we write X  Nd(/L, c) or just X 
the dimension of X.  A 
Example 2.63:  If d  =  1,  1-L  =  0,  and c  =  1,  X  =  X  is called the standard 
Gaussian variable. The density and the distribution of this variable are 

¢(x) =  - - exp  - -
2 

..ffii 

(  x2) 

1 

and  <l>(x)  = 

¢(y) dy. 

(2.106) 

The standard bivariate Gaussian vector corresponding to d =  2, /L  =  0, c 1,1  = 
c2,2  =  1, and ct,2 =  c2,1  =  p has the density 

¢(xt,x2;p)= 2:rrJ1 -p2 exp 

1 

[  Xf  - 2 p XI X2 + xi] 

2(1 -p2) 

(2.107) 

and the characteristic function 

<p(ut,u2;p)=exp  -

. 

(2.108) 

( ui + 2 p u 1 u2 + 

2 

Figure 2.7  shows the density and the characteristic functions  in Eqs.  2.107 and 
2.108 for p =  ±0.8. ¢ 

We  give  two  essential properties  satisfied  by  any  Gaussian  vector  X 

,...., 
N(/L, c).  One of these properties uses  the notations  x<1> and x<2> for  the  first 
dt  <  d  and  the  last  d2  =  d  - dt  coordinates  of X,  /L (p)  =  E[X<P>],  and 
c(p,q)  = E[(X(p)  -

/L(P))T],  p, q = 1, 2. 

/L(P))(X(P)  -

•  Linear transformations of a Gaussian vector are Gaussian vectors. 
•  The conditional vector  X = x<1>  1  (X<2> = z)  is  an JRd' -valued Gaussian 
variable with mean and covariance matrices 

jl =  /L(l) + c<I,2)  (c(2,2))-l(z _  /L(2)) 
c = c(l,l)  _  c(l,2) (c(2,2))-l c<2,1). 

and 

(2.109) 

2.11.  Random vectors 

67 

Density 

Density 

0.4 

0.2 

Characteristic function 

Characteristic function 

p = -0.8 

0.5 

0 
5 

5 

5 

-5  -5 

-5  -5 

Figure 2.7. The density and the characteristic function of the standard bivariate 
Gaussian vector with p = 0.8 and p = -0.8 

Proof: Let Y  =a X +b, where a and bare real-valued (q, d) and (q,  1) constant matrices. 
The characteristic function of Y at v E  JR.q  is 

The first term is the characteristic function of X  for u =aT v so that (Eq. 2.105) 

E [eR vT  YJ  = exp ( .J=l(aT v)T JL-
= exp ( .J=l vT (ap,+b)-

v)T c (aT v))  exp(.J=l vT b) 

(aT ca)v). 

Hence, Y  is a Gaussian vector with mean JLy  = a JL + b and covariance cy  = aT ca. 

The properties of X can be obtained by direct calculations based on the density of 
X  in Eq.  2.104  and  the  definition of the  conditional  density  (Eq.  2.92).  If dt  =  d2  = 
1,  JL  =  0,  q  1  =  c2 2  =  1,  and  c1  2  =  c2  1  =  p,  then  X =  X1  I  (X2  =  z)  is 
c =  1 - p2.  If p  = 0,  that is, 
a Gaussian 
X 1  and  X 2  are  independent,  X and  X 1  have  the  same  distribution.  Otherwise,  X has 
a smaller variance than  X I·  The probabilistic characteristics of the  conditional vector X 
have useful applications in reliability studies.  For example, suppose that X 1 and X 2 control 
the performance of a system and we can measure only X2.  If the correlation coefficient p 
is not zero, the measured value of X 2 can be used to reduce the uncertainty in X 1 .  • 

with  mean  fl  = ; z and 

68 

Chapter 2.  Probability Theory 

Example 2.64:  Let X  be an 
random variable with mean vector p,  = 
(J.q, f.L2)  and covariance matrix c with entries c1,1  =a}, c1,2  =  c2,1  =  p a1 a2, 
and c2,2  =a£. The random variable, 

X1  =pal (X2- f.L2)  + 

02 

is the optimal, mean square, linear estimator of X 1 corresponding to an observa-
tion of X2. <> 
Proof:  Let Z  = a X 2 +  b, a, b  E  R,  be a linear estimator of X 1·  We require that the esti-
mator is unbiased and minimizes the mean square error E[(Z- X1)2].  The first condition 
implies E[Z] =ILl so that ILl  =a IL2  +band Z  =a (X2  - IL2)  +ILl· The mean square 
error of the estimator Z  of X 1 is 

E[(Z- X1)2] = E[(a (X2- IL2)- (X1- IL1))2] = a2 a-i +a[- 2a pal a2, 

and takes its minimum value  at a  = p a1fa2.  This optimal value of a  is the  solution of 
oE[(Z- x 1)2]/aa = o.  • 

2.12  Useful inequalities 

The Chebyshev, Cauchy-Schwarz, HOlder, and Jenssen inequalities are use-
ful  for both applications  and theoretical considerations.  These inequalities  are 
stated and proved.  Let X  and  Y  be random variables  defined on a  probability 
space (Q, F, P). 

Chebyshev's inequality. If r : 
that increases in (0, oo) and E[r(X)] <  oo, then 

--+  (0, oo) is a strictly positive, even function 

P(IXI >  a) ::::; 

a  >  0. 

(2.110) 

Proof: The function r(X) is a random variable because {w: r(X(w)) 
to {w: X(w)  E  [-r-1(y), ,-1(y)]} and X is a random variable.  We have 

y}, y 

0, is equal 

E[r(X)] = { r(X)dP  i  r(X)dP 

Jn 
because r  >  0 andr(x) 
r(a) for lxl 
corresponds to r (x) = lx iP, where p 

r(a) P(IXI  >a) 

IXI::a 
The common form of the Chebyshev inequality 

1 is an integer.  • 

Jensen's inequality.  If g  : 
--+ 
integrable random variables, then 

a convex function and X  and g(X) are 

g(E[X]) ::::;  E[g(X)]. 

(2.111) 

2.12.  Useful inequalities 

69 

Proof:  We use two facts to prove Eq. 2.111. First, convex functions are continuous so that 
g(X) is a random variable.  Second, a convex function g has the property 

g(x) = sup{l(x)  : l(u)  ::=:  g(u), VuE IR}, 

where l denotes a linear function.  We have 

E[g(X)] = E[sup{l(X)}]:;:::  sup{E[l(X)]} = sup{l(E[X])} = g(E[X]), 

where the above inequality and the above last equality hold by Eq. 2.50 and the linearity of 
the expectation operator, respectively. 

The inequalities, 

IE[ X] I ::::  E[IXI]  and  (E[X]) 2q  ::::  E[X2q] 

for an integer q  >  0, 

follow from Eq. 2.111  with g(x) = lxl  and g(x) = x2 q, respectively.  • 

Cauchy-Schwarz's inequality  .  If E[X 2]  and  E[Y 2]  are  finite,  then  E[X Y] 
exists and 

(2.112) 

Proof:  The expectation E[(X +A Y)2] = E[Y2] A 2 +  2 E[X Y] A+ E[X2] is positive for 
any A E I!t Hence, the polynomial of A has no real roots so that we must have (E[X YlP-
E[X2] E[Y2]  :S  0 .• 

HOlder's  inequality.  If 1  <  p  <  oo  and  q  is  given  by  1 I p  + 1 I q 
E[IXIP]  <  oo, and E[IYiq]  <  oo, then 

1, 

(2.113) 

Proof: The inequality Ia bl  ::=:  la!P / p + lblq jq holds for a, bE lR and p, q as in Eq. 2.113. 
The expectation of this  inequality with a  = X/(E[IXIP]) 11P  and b  =  Yj(E[iYiq])lfq 
gives Eq.  2.113.  The HOlder inequality  gives  E[IXI]  ::=:  E[IXIP] 11P  for  Y  = 1 and the 
Cauchy-Schwarz inequality for p = q = 2. 

The inequality E[IXI]  ::=:  E[IXIP] 11P  shows that 

Lp implies 

Lt. where 

p  >  1 is an integer.  • 

Minkowski's inequality. If 1 :=::  p  <  oo and X, YELp, then X+ YELp and 

(2.114) 

Proof: That X,  Y  E L p  implies X + Y  E L P follows from the inequality 

70 

Chapter 2.  Probability Theory 

If p  = 1, the inequality in Eq. 2.114 is trivial. If p  >  1, the expectation of 

IX+ YIP  = IX+ YIIX + Ylp-l ::::  (lXI + IYI) IX+ Ylp-l 
E[IX +YIP]:::: E[IXIIX + YIP- 1] + E[IYIIX + YIP- 1]. 

is 

The Holder inequality gives the upper bounds 

E[IXIP]lfp E[IX + Yl(p-l)q]lfq  and  E[IYIP]lfp E[IX + Yl(p-l)q]lfq 

on the right side terms of the above inequality, where 1 1 p + 1 I q  =  1, so that we have 

E[IX +YIP] :::5  (E[IXIP]lfp + E[IYIP] 11P) E[IX + Yl(p-l)q]lfq. 
Eq. 2.114results by division with E[IX + Yl(p-l)q]lfq since (p -1)q = p.  • 

Example 2.65:  Consider an JR2 -valued random variable X  =  (X 1,  X2)  with the 
second moment properties 

JL=  [  f..tl  J  and  c= [  af 

f..t2 

pa1a2  ]· 

pal a2  a:} 

The above inequalities can be used to prove that the correlation coefficient p takes 
values in [ -1, 1] and p  =  ± 1 if and only if X 1 and X 2 are linearly related. <> 
Proof:  Set X;  = (X;  - JL;)IO'i 
(0, 1).  The Cauchy-Schwarz inequality applied to the 
random variables XI  and x2 gives  lpl2 ::::  1.  If xl =a x2 + b,  then p =ale so that 
p  =  ±1. If p  =  1, the expectation of [XI- X2J2 is zero so that P(IXI- X2l  >e)= 0, 
V e >  0, by the Chebyshev inequality. Hence, X 1 = X 2 a.s. or X 1 = a X 2 + b a.s.  • 

2.13  Convergence of random variables 

Let X  and Xn,  n  =  1, 2, ... , be real-valued random variables defined on a 
probability space  (Q, F, P).  The distribution functions of X  and X n  are  F  and 
Fn, respectively. The convergence of the sequence X n to X has various definitions 
depending on the way  in which the difference between  X n  and X  is  measured. 
We  now  define  the  almost sure  convergence (X n 
X),  the  convergence in 
probability (X n 
X),  and the 
convergence in  Lp  or the  Lp  convergence  (Xn 
X),  where  p  :::  1 is  an 
integer.  The L P  convergence for p  =  2, called convergence in mean square , is 
denoted by Xn 

X),  the convergence in distribution (X n 

X  or l.i.m. n-+ooXn  =X. 

•  Xn 
•  Xn 

•  Xn 
•  Xn 

iflimn-+oo Xn(w)  =  X(w), Yw  E  Q  \  N,  P(N) =  0. 

X  iflimn-+oo  P(IXn -XI >  e)  =  0, Ve  >  0. 

iflimn-+oo Fn(X)  =  F(x), Yx  E  JR. 

X  if limn-+oo  E[IXn  - XiP]  =  0. 

2.13.  Convergence of random variables 

71 

Note: The a.s. convergence has some equivalent definitions.  For example, it can be shown 
that Xn 

X  if and only if for any e  >  0 we have 

lim  P(IXn -XI :::;  e  for all n  0:::  m) = I  or 
m-+oo 
lim  P(IXn  -XI >  e  for some n  0:::  m) = 0. 
m-+oo 

An  alternative  form  of the  latter condition  is  P(IXn  - XI  >  e  i.o.)  = 0  since 

{I X n  - X I >  e}, Ve  >  0, is a decreasing sequence of events, so that 

Am (e) = 

lim  P(Am(e)) = P(  lim  Am(e)) = P(limsup{IXn- XI> e}) 
m-+oo 

m-+oo 

n-+oo 

= P({IXn- XI> e} i.o.), 

where the last equality holds by Eq. 2.21.  & 

We  summarize  some useful properties of convergent sequences of ran-
dom variables and the relationships between different types of convergence ([151], 
Section 6.3). These relationships are illustrated in Fig. 2.8. 

i 

, , 
, , 
, , 
, , 
, 
, , 
, 
, 
, 
, 

n 

If X  is dominated 

by some YE  L 
p 

a.s. 

b  X 

X 

n  • 

I 

On a 
subsequence 
of every 
subsequence 

pr 

X 
n 

! 

d 

X 
n 

X 

X 

Figure 2.8. Types of convergence for random sequences and their relationship 

72 

Chapter 2.  Probability Theory 

The convergence X n 
•  X is unique with probability one. 
•  Xn  is Cauchy in probability. The converse is also true. 

X implies: 

d 

•  Xn 
exists YELp and  IXnl  :5  Y a.s. for n  ::=:  1. 

if Xn  is dominated by a random variable in L P• that is, there 

Note: A sequence of random variables Xn  is Cauchy in probability if for arbitrary 8  >  0 
and 11  >  0 there exists n(e, 11)  such that P(IXm- Xnl  >  8)  <  11  form, n 

n(8, Tj). 

The limits of sequences of random variables have similar properties as the limits 
Y  imply a Xn  + 
of numerical series.  For example,  Xn 
fJ  Yn 

X+ fJ  Y, where a, fJ  E 

X  and  Yn 

Xn  Yn 

Y. 

If Xn 
n, then lXI  :5  Y  a.s. 

X  andY  ::::  0 is a random variable such that  IXnl  <  Y  a.s. for each 

X  if and only  if each  subsequence  {Xnk}  of {Xn}  contains  a subse-

Xn 
quence{Xnk;}suchthatXnk; 
I Xn 
I X  m.p.  X  · 
Note:  Proofs of the above statements can be found,  for example, in [40]  (Chapter 4) and 
[150] (Section 6.3).  A 

implies Xn 

Imp  es Xn 

X  an  Xn 

m.r.  X  "f 

1  r  <  p. 

n 

li 

pr 

d 

Example 2.66:  Let  ([0, 1], 8([0, 1]), P) be  a probability space  with  P(dw)  = 
dw and let Xn  = 2n  1(0,1/n)  be a sequence of random variables defined on this 
space.  The sequence X n  converges to zero in probability as n --+  oo but does not 
converge in L P• p  ::::  1.  ¢ 
Proof:  For any  8  >  0,  we have  P(IXnl  >  8)  = P((O, 1/n)) = 1/n 
Hence, Xn  converges in probability to zero.  On the other hand, 

0 as n 

oo. 

E[iXniP] = (2n) P((O, 1/n)) = 2n /n 

oo  as n 

oo. 

Hence, convergence in probability does not imply Lp convergence ([151], p.  182). • 

Example 2.67:  Consider a sequence of random variables X n  defined on the prob-
ability space ([0, 1], 8([0, 1]), A.)  by X 1 = 1[0.1/21•  X2  = 1[1f2,1J,  X3  = 1[1,1/31• 
X4  =  1[1/3,2/3], Xs  =  1[2/3,1], and so on, where A.  is the Lebesgue measure. This 
sequence converges in L P  to zero but does not converge a.s. to zero.  ¢ 

2.13.  Convergence of random variables 

73 

Proof: The sequence converges to zero in Lp. p  >  0, since 

so  that  E[IXnJP]  -+- 0  as  n  -+- oo.  However,  the numerical  sequence  Xn(w)  does  not 
converge to zero ([151], p.  182).  • 

Example 2.68:  If X n  is a sequence of uncorrelated random variables with finite 
mean f..t  and variance a 2, then 
Sn  =  L 

n  Xn- f..t 

pr 
----+  0, 

k=1 

n 

n --*  00. 

(2.115) 

This result is referred to as the weak law of large numbers ([106], p. 36). ¢ 
Proof:  The mean  and  variance  of Sn  are  J.Ln  =  0  and  u;  =  u 2jn.  The  Chebyshev 
inequality (Eq.  2.110) gives  P(ISn I >  e)  :::;  u; je2  =  u 2 f(n e2)  for arbitrary e  >  0 and 
each n  2::  1.  Hence,  P(ISnl  >  e)  -+- 0 as n  -+- oo so that Sn  L  0.  This convergence 
indicates that most of the probability mass of Sn  is concentrated in a small vicinity of zero 
for a sufficiently large n.  The convergence  Sn  L  0 does  not provide  any information 
on the behavior of the numerical sequence  Sn(w)  for an arbitrary but fixed we n.  Other 
versions of the weak law of large numbers can be found in [151] (Section 7.2).  • 

Example 2.69:  If Xn is a sequence of independent identically distributed random 
variables such that E[JX 111  exists and is finite, then 

1  n -L:xk 

n k=1 

E[XI],  n--* oo. 

(2.116) 

This  result is  known as  the  strong law of large numbers  [151]  (Sections 7.4 
and 7.5). Figure 2.9 shows five samples of (1/n) E/:=1 Xk. where Xk are indepen-
dent Gaussian variables with mean zero and variance one.  All samples approach 
the mean of X 1 as n increases in agreement with Eq. 2.116. ¢ 

Note:  The strong law  of large  numbers  characterizes  the  behavior of the numerical  se-
quence (1/n) I:/:=1 Xk(w). The a.s. convergence of(l/n) I:Z=1 Xk top,= E[XI] means 
that the numerical sequence (1 In) Lk= 1 Xk (w) converges to p, for each w  E n \ N, where 
N  E  F  and P(N) =  0.  • 

Example 2.70:  If Xk, k  = 1, 2, ... , is  a sequence of iid random variables with 
finite mean f..t  =  E [X I] and variance a 2 , then 

* 
Sn  = 

1 
r;; 
vn k=1 

Xk- f..t 

a 

d 

----+  N(O,  1), 

n--* oo. 

(2.117) 

This result is known as the central limit theorem ([151], Section 8.2). ¢ 

74 

Chapter 2.  Probability Theory 

-1.5'---'---'---'---'-----'----'----'-----'-----'---___j 
21 

19 

17 

13 

15 

1 

11 
n 

Figure 2.9. Five sample paths of (1/n) Lk=l xk for xk ""'N(O, 1) 

are  zero  and one for  each n  so  that this  sequence 
Proof:  The mean  and variance  of 
has the required second moment properties. We show that the characteristic function of .s;:' 
approaches the corresponding function of the standard Gaussian variable as n  -+ oo.  The 
characteristic function of 

is 

rfJn (u)  =  exp [ -.J=l u J.t ./fila J rp(u/(../fi a))n, 

where rp  denotes the characteristic function of X 1· An alternative form of this characteristic 
function is 

r{Jn(u)=exp  -v-lutt-+n  v-lu  '- + 

[  ,-, 

,-, 

J.t 

{ 

../fi 
a 

(J=Tu)2 

2na 

2  +O(n-

3/2  ]} 

) 

-vna 

and results  from  rp(u/(../fi a))n  =  exp [ln (rp(u/(../fi a))n)]  by expanding  the  function 
1n (rp(u/(../fi a))n) in a Taylor series ([79], p. 376). The limit of the characteristicfunction 
as n -+ oo is equal to exp( -u2 /2) which is the characteristic function of the standard 
of 
Gaussian variable.  • 

Example 2.71:  Consider a sequence of Bernoulli variables X n  taking the values 
one and zero with probabilities  P(Xn  = 1)  = Pn  and  P(Xn  = 0)  = 1 - Pn. 
Pn  E  (0, 1). If 
Proof:  The  assumption 
Pn  = 
lemma yield P((Xn =  1) i.o.)  =  0 or 

Pn  <  00, then P(lirnn-+oo Xn  =  0) =  1. ¢ 

P(Xn  =  1)  <  oo  and  the Borel-Cantelli 

1 =  P({(Xn  =  1) i.o.}c)  =  P({limsup(Xn  =  1W) =  P(liminf(Xn =  0)), 

n-+oo 

n-+oo 

as stated ([151], Example 4.5.1, p. 103). • 

2.14.  Random walk 

2.14  Random walk 

75 

Let X  =  (X 1 , X 2, ... )  be a  sequence of iid random variables defined on 
a  probability  space  (Q, :F,  P)  with values  in  a  measurable  space  (W, Q).  The 
sequenceR= (Ro,  Rt, ... ) defined by 

n 

Rn=LXi,  n=1,2, ... , 

and  Ro=O 

(2.118) 

i=l 

is called a random walk. 

The random variables (Rt, ... , Rn) and (X 1, ... , Xn) are related by a mea-
surable mapping for each n  2::  1 so that (Rt, ... , Rn) is a(XI, ... , Xn)-measur-
able. The random variables (Ro, Rt, ... , Rn) are also a(X 1, ... , Xn)-measurable 
because the a-field {0, Q} generated by the random variable Ro  :  Q 
lR  is in-
cluded in a(Xt, ... , Xn)  for each n  >  1.  We  will think of the index n  of the 
random walk as time. 

Example 2.72:  Suppose that the random variables Xi in Eq. 2.118 are real-valued 
with finite mean p., and variance a 2 and that the measurable space (W, Q) is (lR, B). 
The mean,  variance,  and coefficient of variation of the  random walk  R n  corre-
sponding to these random variables are 

and  c.o.v.[Rnl  = 

y'Var[Rn] 

E[Rn] 

= 

v 
r.;;' 
vn 

where v =  a/ p.,  and c.o.v.[Rn] are defined if p.,  -=/=  0. 

The variance of the random walk increases linearly with the index n, a prop-
erty shared by the Brownian motion process (Section 3.13). If p.,  =  0, the random 
walk has  mean zero  and oscillates  about its  mean value  with an  amplitude that 
increases with n.  If p.,  -=/=  0 and n 
oo, the average and the coefficient of varia-
tion of Rn  approach ±oo depending on the sign of p.,  and zero, respectively. This 
observation suggests that Rn  approaches +oo or -oo as time n increases. <> 

The heuristic considerations in Example 2. 72 are correct in the sense of the 

following two results, which are stated without proof. 

If P(X 1  =  0)  <  1,  the asymptotic behavior of the random walk as n 
one and only one of the following ([150], Proposition 7.2.2, p. 562): 

oo is 

+oo  a.s., 
-oo  a.s., 

•  Rn 
•  Rn 
•  - oo  =  liminf Rn  <lim sup Rn  =  +oo  a.s. 

or 

(2.119) 

76 

Chapter 2.  Probability Theory 

If P(X 1 =  0)  <  1 and E[IX 1ll  <  oo, the asymptotic behavior of the random 
walk Rn  as n 

oo is ([150], Proposition 7.2.3, p. 563): 

•  If E[X I] >  0,  Rn 
•  If E[Xt] <  0,  Rn 
•  If E[Xt] =  0, 

+oo  a.s. 
-oo  a.s. 

-oo =  liminfRn  <  limsupRn  =  +oo. 

(2.120) 

Note:  Eq. 2.119 shows that Rn  converges to an infinity or oscillates between -oo and +oo 
as n --+  oo. The additional information on the mean of X1  in Eq. 2.120 allows us to predict 
the behavior of the random walk more precisely than in Eq.  2.119.  For example,  if the 
random variables  Xk  take the values  one and zero with probabilities p, 0  <  p  <  1,  and 
1- p, the corresponding random walk Rn  converges to +oo a.s. since E[XI] = p. 
Example 2.73:  Let X 1,  X2, ... be a sequence of iid Gaussian random variables 
with mean J.t  and standard deviation u. Figure 2.10 shows samples of the random 
walk Rn  in Eq. 2.118 for X 1 ""N(J.t, u 2), where J.t  = 1, J.t  = 0, and J.t  = -1 and 

1500.--.--,----,----,-----,----,----,----,----,---------, 

-1000 '-----'-----'-----'-----'-----'------'------'------'------'----.-J 

600 

700 

800 

900 

1000 

0 

100 

200 

300 

400 

500 
n 

Figure 2.10. Sample paths of the random walk for X k  ""N(J.t, 102)  with J.t  =  1, 
J.t  =  0, and J.t  =  -1 
u  = 10.  The samples corresponding to J.t  = 1 and J.t  = -1 exhibit an increasing 
and decreasing trend, respectively, while the  samples for J.t  =  0 oscillate about 
zero in agreement with Eq. 2.120. <> 
Example 2.74:  Consider a sequence of iid random variables  An. n  = 1, 2, ... , 
defined on a probability space  (Q, :F,  P).  Let Xn  be another sequence of ran-
dom variables defined on the same probability space generated by the recurrence 

2.14.  Random walk 

77 

formula Xn  =An Xn-1,  n  =  1, 2, ... , with  Xo  =  x  E  lR  \  {0}.  Ifln/A1/  "' 
L1 (Q., :F, P) and E[ln /A1/l  <  0, then Xn  converges to zero a.s.  as n 
oo.  The 
limit 

ALE=  lim  - 2)n/Ak/ =  E[ln/A1/l 

1  n 
n-+oo n  k=1 

is called the Lyapunov exponent in the analysis of dynamic systems (Section 8. 7). 
The solution Xn  is stable a.s., that is, it converges a.s. to zero, if ALE  <  0 and di-
verges if ALE  >  0.  <> 
Proof:  The recurrence formula for  Xn  yields  Xn/x  =  0k=1 Ak for Xo  =  x  so that we 
have ln IXn/xl  = Lk=1 ln IAkl·  It follows  that ln IXn/xl  is a random walk since ln IAkl 
are iid random variables  (Eq.  2.118).  If E[ln IA1IJ  <  0,  the random walk ln IXn/xl  con-
verges to -oo a.s. as n  -+ oo (Eq. 2.120) so that the solution IXn/xl = exp (Lk=1 ln IAk I) 
converges to zero  a.s.  If E[ln IA1Il  >  0, ln IXn/xl  tends  to +oo a.s.  as  n  -+  oo so that 
IXnfxl = exp (Lk=1 ln IAkl)  approaches +oo a.s.  • 

Example 2.75:  Suppose that the random variables An in Example 2.74 are expo-
nential with distribution F (x)  =  1 - exp(- p x ), p  >  0, x  ::::  0.  The solution X n 
is stable a.s. for p  >  p*  ::: 0.56, that is, Xn 
oo.  Figure 2.11 shows 
the dependence of the Lyapunov exponent ALE on p in the range [0.4, 0. 7]. <> 

0 as n 

0.3 

0.2 

0.1 
'A  o 
-0.1 

-0.2 

-0.3 

-

-

-

-

-

-

-

-

-

I 

I  . 

tp 

0.4 

0.45 

0.5 

0.6 

0.65 

0.7 

0.55 
p 

Figure 2.11. Stability condition for Xn  =An Xn-1  with An  iid exponential vari-
ables 

Proof: The mean of ln IAk I = ln(Ak) is finite and can be calculated from 

ALE=  { 00 ln(u)pexp(-pu)du = -p1 00 

-00 

h 

by numerical integration.  The Lyapunov exponent ALE= E[ln IA1IJ  decreases with p and 
is negative for p  >  p*  ::: 0.56.  • 

78 

2.15  Filtration 

Chapter 2.  Probability Theory 

Let  (Q, F)  be  a  measurable  space.  An  increasing  collection  Fo  !:;  FI  !:; 
· · · Fn  !:;  · · · !:;  F  of sub-a-fields ofF is said to be a filtration in ( n, F). 
A probability space (Q, F, P)  endowed with a filtration  (Fnk::o is called a fil-
tered probability space and is denoted by (Q, F, 
P).  We assume that 
Fo contains all the P-null sets of F. 

Let (Q, F) and  (\11,  Q)  be measurable spaces,  (Fn)n:::o  denote a filtration 
on (Q, F), and X  =  (Xo, XI, ... )  be a sequence of measurable functions  from 
(n, F) to (\11, 9). 

The sequence X  is said to be adapted to the filtration (Fn)n:::o  or Fn-adapted 
if Xn  is  Fn-measurable for each n  :::::  0.  The minimal or natural filtration 
of X  = (Xo, XI, ... ),  that is,  the smallest a-field with respect to which X  is 
adapted, is a(Xo, XI. ... , Xn). 

Example 2.76:  Let X  =  (X I, Xz, ... ) be outcomes of a sequence of coin tosses. 
The a -field Fn  =  a (X I, ... , Xn)  represents the knowledge at time n  :::::  1.  The 
information content of F n  is sufficient to decide whether an event related to the 
first n tosses has or has not occurred. For example, the event 

A =  {at least 2 heads in the first five tosses} 

is Fs-measurable because we can decide after five tosses whether A has or has not 
occurred.  If {tail,  tail,  head,  tail}  is  a  sample  (XI(w), Xz(w), X3(w), X4(w)) 
of the  first  four  tosses,  the  event  A  remains  undecided  so  that  A  ¢  F 4·  If 
(XI(W), Xz(w), X3(w), X4(w))  is  {tail,  head,  head,  tail},  A  has been observed 
in the  first  four  tosses  for  this  sample irrespective of the  fifth  outcome.  How-
ever, we cannot conclude that A  E  F4.  This conclusion would be correct if we 
could tell whether or not A has occurred by watching only the first four outcomes 
irrespective of the particular sample of (X I. Xz, X3, X4). <> 
Example 2.77:  Let Fn  = a(RI, ... , Rn). n  :::::  1, and Fo  = {0, n} be the natu-
ral filtration of the random walk sequence R  =  (Ro, RI, ... ) in Eq.  2.118.  The 
sequenceR is Fn-adapted. <> 
Note: The sequence of a-fields :Fn  contains the information accumulated by observing the 
random walk Rn  up to and including time n 
0.  The a-field :Fn+I  includes :Fn  and other 
sets  such that Rn+l  = Rn  + Xn+I  is measurable.  Hence, the sequence of sub-a-fields 
:Fn  = a(Ro, R1, ... , Rn) is a filtration in (Q, :F) and R is :Fn-adapted.  A 

2.16  Stopping time 

In a game of chance we may decide to quit or continue to play after each 
round depending on what happened up to that point and on the available resources, 

2.16.  Stopping time 

79 

for  example,  we  may be  out  of money.  Hence,  the  time  T  at which  we  stop 
playing the game is a random variable that takes values in {1, 2, ... } and depends 
on the entire game history.  Let :Fn  represent the knowledge accumulated at time 
n  2:  1.  The event { T  =  n}  to quit the game after n rounds should be in :F n.  A 
similar "game" can be envisioned between a physical or biological system and the 
environment. The system quits the game when its damage state reaches a critical 
level, which is the analogue to running out of cash.  Depending on the situation, 
the time T  at which such a system quits the game may be called failure time or 
death time. 

We define in this section stopping times and prove some of their properties. 
Additional information on stopping times  can be found in [59]  (Chapter 2)  and 
[151] (Section 10.7). 

Let  (Q, :F)  be  a  measurable  space  and  (:Fnk::O  be  a  filtration  of :F.  A 
{0,  1, 2, ... , oo}-valued random variable  T  defined  on  (Q, :F)  is  a  stopping 
time with respect to (:Fn)n:;::o  or an :Fn-stopping time if {w : T(w)  ::::  n}  E  :Fn 
for each n  2:  0. 

Note:  This  definition  states that  T  is  an  Fn-stopping  time if Fn  contains  sufficient in-
formation  to determine whether  T  is smaller or larger than n  for each time n  :=:::  0.  For 
example, T  = inf{n  :=:::  0  : \Rn I :=:::  a}, a  >  0, gives the first time when the random walk R 
in Eq. 2.118 exits (-a, a).  We can determine whether T:::;  nor T  >  n by observing the 
random walk up to time n. 

We also note that a constant random variable t  E  {0, 1, ... } is a stopping time since 
{w  : t  :::;  n}  is either 0 or Q  so that the event {t  :::;  n}  is in Fn  for each n  :=:::  0.  If Tis an 
Fn-stopping time so is T + t since {w: T(w) + t:::; n} = {w: T(w)  :::;  n- t}  E  F(n-t)vO 
and F(n-t)vO C Fn  fort  :=:::  0.  A 

IT is a stopping time if and only if {T = n}  E  :Fn  for each n  2:  0. 
Proof: If Tis a stopping time, we have {T:::; n}  E  Fn  and {T:::; n- l}c  E  Fn-1  Fn. 
Hence, {T = n}  = {T  :::;  n}  n {T  :::;  n -
form:::; nand {T:::; n}  = U:!t=0{T = m}, we have {T:::; n}  E Fn.  • 

Suppose now that {T  = n}  E  Fn  for each n  :=:::  0.  Because {T  = m}  E  Fm 

l}c  E  Fn  since Fn  is a a-field. 

Fn 

If Tis an :Fn-stopping time, 

:Fr  ={A E  :F: An {T:::; n}  E  :Fn  foralln  2:  0} 
={A E  :F: An {T  =  n}  E  :Fn  foralln 2:  0}, 

(2.121) 

is a sub-a-field of :F including events in :F that "occur up to timeT". 

Proof: We show first that the collection of sets in the second definition of Fr is a a-field, 
and then that the above two definitions of Fr are equivalent. 
We have (1) Q n  {T = n}  = {T = n}  E  Fn  since Tis a stopping time so that Q  E 
Fr. (2) A  E  Fr implies AcE Fr since Acn{T = n}  = {T = n}n(A n  {T = n})c  E  Fn, 

80 

Chapter 2.  Probability Theory 

and (3)  Ai  E  :FT, i  = 1, 2, ... , implies 

Ai  E :FT  since 

Ai) n {T =  n}  = 

(Ai n {T =  n})  E  :Fn. 

Hence, the collection of sets in the second definition of :FT  is a cr-field. 

We  show  now  that the  above  two  definitions  of :FT  coincide.  Take  A  E  :F  and 
0.  Hence, An {T:::; n}  =  Uk=I (An {T =  k}) 
0  implies  An {T  = 
0.  This follows from the equality An {T  =  n}  =  (An {T:::: n}) n 

assume that An {T =  n}  E  :Fn  for all n 
is in :Fn.  It remains to  show  that An {T  :::;  n}  E  :Fn  for all n 
n}  E  :Fn  for all n 
(An {T:::; n- 1))C  since An {T:::; n}  E :Fn  and An {T:::: n- 1}  E  Fn-I  £ :Fn.  • 

If X  = (Xo, XI, ... )  is  a  sequence of functions  measurable from  (Q, :F)  to 
(\11, g) and :Fn = cr(Xo, XI, ... , Xn), then the hitting time 
T(w)  =  inf{n  2:  0: Xn(w)  E  B},  B  E  g, 

(2.122) 

is an :Fn -stopping time. 
Proof:  Take  B  E  Q.  The random variable T(w)  = inf{n 
0  : Xn(w)  E  B}  satisfies the 
condition {T:::; n}  if at least one of the events {Xo  E  B}, {Xo  ¢:.  B, ... , Xk-I  ¢:.  B, Xk  E 
B}, k = 1, ... , n, occurs, that is, 

{T:::;  n}  = {Xo  E  B} U (uk=I {Xo  ¢:.  B, ... , Xk-I  ¢:.  B, Xk  E  B}) 

so that { T  :::;  n}  E  :Fn  because it consists of finite intersections and unions of events in :Fk 
and :Fk  £ :Fn  fork:::; n.  • 
I A stopping timeT is FT-measurable. 
Proof:  We need to show that {T  :::;  m}  is in :FT  for each m 
n}  E  :Fn  for all n 
m 1\ n} and {T:::; m 1\ n}  E  :FmAn  £  :Fn.  • 

0, that is, {T  :::;  m} n {T  :::; 
0.  This condition is satisfied because {T  :::;  m}  n {T  :::;  n}  = {T  :::; 

I If S and T are Fn-stopping times such that S  ::::;  T, then :F s 
Proof:  If A  E  :Fs,  then  A  n {S  :::;  n}  E  :Fn  for  all  n 
0.  We  need  to  show  that 
An {S:::; n}  E  :Fn  implies An {T:::; n}  E  :Fn  for all n 
0.  This implication is true since 
the sets An {S:::; n} and {T:::; n} are in :Fn, and An {T:::; n}  =(An {S:::; n}) n {T:::; n} 
holds if S:::;  T.  • 

:FT. 

I If SandT are Fn-stopping times, then S 1\ T  and S v  T  are stopping times. 

Proof: We have 

{S 1\ T  :::;  n}  = {S:::; n}  U {T:::; n} 

and  {S v T:::; n} = {S:::; n} n {T:::; n} 

so that the events {S 1\ T:::;  n} and {S v T:::;  n} are in :Fn  for each n 
stopping times.  • 

0 since SandT are 

2.16.  Stopping time 

81 

I If SandT are Fn-stopping times, then Fsl\r =  Fs n Fr. 
Proof:  Because S 1\ T  ::::  S, T, we have :Fsl\r  c  :Fs, :Fr by one of the above properties 
so that :Fsl\r  c  :Fs n :Fr. To prove the opposite inclusion, take A  E  :Fs n :Fr and note 
that, if A  E  :Fs n :Fr, then 

An {S 1\ T  :::;:  n}  =An ({S:::: n}  U {T:::: n})  =(An {S::::  n}) U (An {T:::: n}) 

belongs to :Fn  so that A  E  :FsAr· • 

If X  =  (Xo, X1,  ... )  is  a  sequence of functions  measurable from  (Q, F)  to 
(\11,  9), Fn  =  a(Xo, X1,  ... , Xn). and T denotes anFn-stoppingtime, thenXr 
is Fr-measurable. 
Proof:  Take B  E  9. Then 

{Xr  E  B} = 

=  k} n  {Xr  E  B} = 

=  k} n  {Xk  E  B} E  :F 

since  {T  = k}  E  :Fk  C  :F and  {Xk  E  B}  E  :F.  It remains  to  show  that  Xr  is  :Fr-
measurable, that is, that A  =  {X r  E  B}  E  :Fr for each B  E  9 or A n {T ::::  n}  is in :Fn  for 
all n ::::  0.  We have 

An {T:::;:  n} =  {Xr  E  B} n  {T  :::;:  n} =  Uk=O{T  =  k} n  {Xr  E  B} 

= Uk=O{T = k} n {Xk  E  B}  E  :Fn 

since :Fn  is a filtration on :F, X is :Fn -adapted, and :Fk  s;  :Fn  fork ::::  n.  • 

If (1)  X  =  (X 1,  Xz, ... )  is  a sequence of functions  measurable from  (Q, F) 
to  (\II, 9) that are iid,  (2)  P  is  the  probability measure  on  (Q, F), and  (3)  T 
is an a.s.  finite  Fn  =  a(X1, ... , Xn)-stopping time, n  2:  1,  then the sequence 
Y  =  (Y1,  Yz,  .. . ), where 

Yn(w)  =  Xr(w)+n(w), 

n  2:  1, 

(2.123) 

is independent of Fr and has the same distribution as X. 
Proof: Because Xk are independent random variables, (Xn+l• Xn+2· .. . ), n::::  1, obtained 
from  X  by translating the time with n units,  is independent of the past history,  that is,  of 
the a-fields :Fm, m  ::::  n.  We show that this property is preserved even if time is translated 
by a random amount T, provided that Tis a finite stopping time, that is, that the sequence 
Y = (Xr+l• Xr+2• .. . ) is independent of the a-field :Fr. The Brownian motion and other 
processes considered in this book have this property, called the strong Markov property. 
We show first that the measurable functions  X, Y : (Q, :F)  -+  (\1100 ,  900 )  have the 

same distribution.  For B  E  goo, we have 

P(Y E  B)= P((Xr+l• Xr+2• .. . )  E  B) 

00 

=  L  P((Xk+I, xk+z, .. . )  E  B) P(T =  k) 

=  L P((X1, Xz, .. . )  E  B) P(T =  k)  =  P(X E  B). 

k=l 
00 

k=l 

82 

Chapter 2.  Probability Theory 

To show that Y is independent of Fy, we need to prove that P(An{Y E  B}) = P(A) P(Y  E 
B), where A E  Fr and B  E  goo.  We have 

00 

k=l 
00 

P(A n {Y  E  B}) = L P(A n {Y  E  B}  1  T  = k) P(T = k) 
= L P(Ak n {(Xk+t· xk+2, .. . )  E  B}) 
= L P(Ak) P((Xk+t· xk+2, .. . )  E  B)= P(A) P(Y E  B) 

k=l 
00 

k=l 

because the events Ak =  An{T =  k} and (Xk+l, xk+2· .. . )  E  Bare independent for each 
k  and the sequences  X  and Y  have the same distribution.  Since A is an arbitrary member 
of Fr, we conclude that Y is independent of Fr. • 

Example 2.78:  Let R be the random walkinEq. 2.118, where Xi areiid Gaussian 
random variables with mean f1- and standard deviation a  >  0.  LetT =  inf{n  :::: 
0  :  Rn  tj.  (-a, a)} be the  first timeR leaves  (-a, a), a  >  0.  Figure 2.12 shows 
1000 samples of the  stopping time  T  and the  corresponding histogram of these 
samples for f1- =  0.2, a  =  1, and a =  5. <> 

Histogram ofT 

0.04 

0.03 

0.02 

0.01 

1000 

20 

400 

800 
200 
Sample number 

600 

40 

60 

Stopping time 

80 

100 

Figure2.12. SamplesandahistogramofT for Rn  =  L7=t xi, Xt  N(0.2, 1), 
and a= 5 

2.17  Conditional expectation 

We  have  defined  the  conditional  density  jCl12l  of a random  vector  x<ll 
given that another vector X <2l has a known value z (Eq.  2.92).  This density can 
be used to calculate the expectation 

(2.124) 

2.17.  Conditional expectation 

83 

oftheconditional vector x<I)  I cx<2) = z), that is, the expectation of x<l) given 
the information x<2)  =  z. 
We extend the definition of the conditional expectation E[X (1)  I x<2)] in 
Eq. 2.124 by considering information more general than X  <2)  = z.  This section 
defines  the conditional expectation E[·  I Q],  where  (Q, :F,  P)  is  a probability 
space and Q is a sub-a-field of :F. The conditional expectation E[· I Q] is needed 
in many applications involving stochastic processes, as we will see in this and the 
subsequent chapters. 

Example 2.79:  Consider the experiment of rolling two dice.  The sample space, 
a-field, and probability measure for this experiment are Q = {w = (i, j) : i, j  = 
1, ... , 6},  all subsets of n, and P({w})  = 1/36 for w  e  Q, respectively.  Define 
the random variables X ( w) = i + j  and Z ( w) = i 1\ j. The expected value of X 
is E[X] = (1/36)[(1 + 1) + (1 + 2) + · · · + (6 + 6)] = 7. 
Suppose we are told the value of Z  and asked to determine the expectation 
of X  given Z, that is,  the expectation of the conditional variable X  I Z  denoted 
by E[X I Z]. The conditional expectation E[X I Z] is a simple random variable 
with density in Fig. 2.13 so that 

E{E[X I Z]} = L E[X I Z = z] P(Z = z) = (12)P(Z = 6) 

z 

+ (32j3)P(Z =  5) + · · · + (52/ll)P(Z = 1) = 7 = E[X]. 

is the expected value of E[X I Z]. <> 

0.4 

0.35 

0.3 

0.25 

0.2 

0.15 

0.1 

0.05 

P(Z=l) 

P(Z=2) 

P(Z=3) 

P(Z=4) 

P(Z=5) 

03 

4 

5 

a 

7 

a 

9 

10 

11 

X 

P(Z=6) 

I 
12 

13 

Figure 2.13. The density of E[X I Z] 

Proof:  If Z  = i  1\  j  = min(i, j) = 6, there is a single outcome  (6, 6)  so that X  I (Z = 
6)  = 6 + 6  =  12.  The density  and  the expectation of the conditional random variable 

84 

Chapter 2.  Probability Theory 

X  I (Z =  6)  are  J012)(x) =  fx1z(x  I 6)  =  8(x- 12) and E[X I Z  =  6]  =  12, where 8 
denotes the Dirac delta function.  The probability of the event {Z = 6}  is 1/36.  If Z  = 5, 
there are three equally likely outcomes,  (6, 5},  (5, 5), and  (5, 6},  so that fx1z(x  I 5)  = 
(1/3)8(x - 10) + (2/3)8(x - 11) and E[X I Z  =  5]  =  (10)(1/3) + (11)(2/3)  =  32/3. 
The probability of the event {Z =  5} is 3/36. 

Note that the random variable E[X I Z] does not have a density.  The above expres-
sions of f(l/Z) are formal.  They are used here and in some of the following  examples for 
simplicity.  • 

2.17.1  a-field generated by a countable partition of Q 

Let (n, :F, P) be a probability space and let An be a countable collection 
of measurable sets that partition n, that is, UnAn = n, Ann An' = 0 for n f. n', 
and An  E  F.  Denote by g the a-field generated by {An}.  The members of Q 
are unions of sub-collections of {An}. Let X be an integrable random variable on 
(n, :F,  P). 
If P(An) >  0, define the function E[X I Q]  : n 

R by 

E[X I Q](w) =  L E[X I An] 1An (w),  where 
E[X I An]=  {  X(w) PAn(dw) = - (1  )  {  X(w) P(dw). 

n 

Ja 

P  An  JAn 

(2.125) 

(2.126) 

Note:  E[X I An] is the conditional expectation of X  with respect to  An  and  PAn (A)  = 
P(A I An) =  P(A nAn)/ P(An) . .l 
The function E[X I Q]: n 
•  E[X I Q] is (}-measurable. 
•  E[X I Q] can be viewed as an approximation of X. 
•  E[X I Q]  satisfies the defining relation 

R has thefollowing properties. 

iXdP=iE[XIQ]dP,  VAeQ. 

(2.127) 

Proof:  Since  1An  e  9 and E[X I An] are some constants, the conditional expectation in 
Eqs. 2.125 and 2.126 is a {;-measurable function.  We also note that E[X I 9] is a discrete 
random variable on (Q, 9) whose probability density function is f (x)  =  Ln P (An) 8 (x-
E[X I AnD· 
Since  E[X  I  An]  can  be  viewed  as  a  local  average  of X  over  the  subset  An. 
E[X  I 9] provides  an  approximation for  the random variable  X.  The  accuracy  of this 
approximation depends on the refinement of the partition An.  If the partition has a single 
element that necessarily coincides with the sample space,  E[X  I 9] is equal to E[X].  If 

2.17.  Conditional expectation 

85 

the sample space is countable and the partition is given by the elements { w} of the sample 
space, E[X I Q] is equal to X. 

It remains to prove Eq. 2.127. If A coincides with the sample space n, then 

{  E[X I Q] dP =  E{E[X I Q]}  =  L  E[X I An] P(An) =  {  X dP =  E[X] 
ln 

ln 

n 

because E[X I Q] is equal to E[X I An] on the atoms An  of g with probabilities P(An). 
If A  is  an  arbitrary element of g,  that is,  A  = UkeJ Ak  is  a union of some  of the  sets 
partitioning n, we have (Eqs. 2.44 and 2.126) 

1 X dP = L  1 X dP = L  E[X I Ak] P(Ak)  and 

A 

keJ  Ak 

keJ 

{  E[XIQ]dP=L  {  E[XIQ]dP=L  {  LE[XIAn]1An(w)P(dw) 
h 

keJhk  n 

keJhk 

=  L  L 

{ 

keJ  n  JAknAn 

E[X I An] P(dw)  =  L 

{  E[X I Ak] P(dw) 

keJ}Ak 

= L  E[X I Ak] P(Ak)· 

keJ 

The above chain of equalities is based on properties of integrals of random variables and 
Eqs. 2.125 and 2.126.  • 
Example 2.80:  Let (0, :F,  P) be a probability space,  where  n  = [0, 1],  :F  = 
B([O,  1]), and P(dw) = dw. Consider a random variable X(w) = 2 + sin(2n w), 
w  E  n, defined on this  space.  Let  At  =  [0,  1/4),  A2  =  [1/4, 3/4),  A3  = 
[3/4, 1), and A4  =  {1} be a partition of nand denote by g the a-field generated 
by this partition. We have 

where x  can be any real number.  The lack of uniqueness is of no concern since 
P(A4) =  0. The conditional expectation will be defined as a class of random vari-
ables that are equal a.s.  (Eq. 2.128).  Figure 2.14 shows the measurable functions 
X  and E[X I Q]  for x  = 3.  The conditional expectation E[X I Q]  represents an 
approximation of X  whose accuracy depends on the partition {An} of Q. 0 

Proof:  The conditional expectation  E[X  I  Q]  is given by Eq.  2.125  with E[X  1  An] in 

Eq. 2.126.  For example, we have E[X I At] = m Jd/4[2 + sin(2n w)] dw = 2(1 + 1/n) 

for A1.  • 

The defining relation (Eq.  2.127) is essential for calculations and reveals 

some useful properties of the conditional expectation. 

86 

Chapter 2.  Probability Theory 

2. 

1.8 

1.6 

1.4 

1.2 

1 
0 

E[X IO](ro) 

X(ro) 

0.2 

0.4 

0.6 

0) 

Figure 2.14. The conditional expectation E[X I Q] of X(w) =  2 + sin(2Jr w) for 
At = [0, 1/4), Az = [1/4, 3/4), A3  = [3/4, 1), and A4 = {1} 

The integrals fA  X dP and fA  E[X I Q] dP are equal for every A  E  Q although 
their integrands, X  and E[X I Q], are F-measurable and Q-measurable, respec-
tively.  These integrals represent local averages of the random variables X  and 
E[X I Q] over A. 
I E[X I Q] is integrable because X  is an integrable random variable. 
I E[X I Q] is unique up to an equivalence. 
Proof:  Let hi, i  = 1, 2,  be two 9-measurable functions  satisfying the  defining  relation 
fA  X dP  = fA  hi dP, VA  E  9.  Hence,  ht  and hz  are  two  versions of the conditional 
expectation.  The subset A'  =  {w: ht (w)  >  hz(w)} is in 9 since the functions  hi  are 9-
measurable.  The integral fA' (h 1 - hz) d P  is zero by hypothesis so that P(A1)  = 0 since 
ht- hz  >  0 on A'.  Similar arguments show that the subset A"= {w: ht(w)  <  hz(w)} 
has probability zero  so  that  P({w  :  ht (w)  =I=  hz(w)})  = 0  or ht  = hz  a.s.,  that is,  ht 
and hz  can  differ only on a  set of probability  zero  ([40],  Section 9.1).  The conditional 
expectation E[X  I 9] is represented by all9-measurable random variables satisfying the 
defining relation in Eq. 2.127. The random variables in this class are equal a.s. and represent 
versions of the conditional expectation.  • 
Example 2.81:  Let An = {Z = n}, n = 1, ... , 6, be subsets of the sample space 
n of the experiment in Example 2. 79.  The a -field g = a (Z) consists of unions 
of An's.  The conditional expectation, E[X I Z], calculated previously coincides 
with E[X I Q] in Eq. 2.125, where X(w) =  i + j. 0 
Proof: The conditional expectation E[X I 9] is constant on An  and is equal to 
E[X I Anl·  For example,  E[X I A6] is equal to (11(1136))(12)(1136)=12 and E[X I As] 
is  (11(3/36))(11+10+11)(1136)=3213.  Hence,  the conditional expectations  E[X  I Z]  and 
E[X I cr(Z)] coincide.  • 

